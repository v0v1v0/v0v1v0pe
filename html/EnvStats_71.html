<div class="container">

<table style="width: 100%;"><tr>
<td>distChoose</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Choose Best Fitting Distribution Based on Goodness-of-Fit Tests
</h2>

<h3>Description</h3>

<p>Perform a series of goodness-of-fit tests from a (possibly user-specified)
set of candidate probability distributions to determine which
probability distribution provides the best fit for a data set.
</p>


<h3>Usage</h3>

<pre><code class="language-R">distChoose(y, ...)

## S3 method for class 'formula'
distChoose(y, data = NULL, subset,
  na.action = na.pass, ...)

## Default S3 method:
distChoose(y, alpha = 0.05, method = "sw",
    choices = c("norm", "gamma", "lnorm"), est.arg.list = NULL,
    warn = TRUE, keep.data = TRUE, data.name = NULL,
    parent.of.data = NULL, subset.expression = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>an object containing data for the goodness-of-fit tests.  In the default
method, the argument <code>y</code> must be numeric vector of observations.
In the formula method, <code>y</code> must be a formula of the form <code>y ~ 1</code>.
Missing (<code>NA</code>), undefined (<code>NaN</code>), and
infinite (<code>Inf</code>, <code>-Inf</code>) values are allowed but will be
removed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>specifies an optional data frame, list or environment (or object coercible
by <code>as.data.frame</code> to a data frame) containing the variables in the
model.  If not found in <code>data</code>, the variables are taken from
<code>environment(formula)</code>, typically the environment from which
<code>distChoose</code> is called.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>specifies an optional vector specifying a subset of observations to be used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>

<p>specifies a function which indicates what should happen when the data contain <code>NA</code>s.
The default is <code>na.pass</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>numeric scalar between 0 and 1 specifying the Type I error associated with each
goodness-of-fit test.  When <code>method="proucl"</code> the only allowed values for
<code>alpha</code> are 0.01, 0.05, and 0.1.  The default value is <code>alpha=0.05</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>character string defining which method to use.  Possible values are:
</p>

<ul>
<li> <p><code>"sw"</code>. Shapiro-Wilk; the default.
</p>
</li>
<li> <p><code>"sf"</code>. Shapiro-Francia.
</p>
</li>
<li> <p><code>"ppcc"</code>. Probability Plot Correlation Coefficient.
</p>
</li>
<li> <p><code>"proucl"</code>.  ProUCL.
</p>
</li>
</ul>
<p>See the DETAILS section below.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>choices</code></td>
<td>

<p>a character vector denoting the distribution abbreviations of the candidate
distributions.  See the help file for <code>Distribution.df</code> for a list
of distributions and their abbreviations.
The default value is <code>choices=c("norm", "gamma", "lnorm")</code>,
indicating the Normal, Gamma,  and Lognormal distributions.
</p>
<p>This argument is ignored when <code>method="proucl"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est.arg.list</code></td>
<td>

<p>a list containing one or more lists of arguments to be passed to the
function(s) estimating the distribution parameters.  The name(s) of
the components of the list must be equal to or a subset of the values of the
argument <code>choices</code>.  For example, if
<code>choices=c("norm", "gamma", "lnorm")</code>, setting <br><code>est.arg.list=list(gamma = list(method="bcmle"))</code> indicates
using the bias-corrected maximum-likelihood estimators of shape and scale
for the  gamma distribution (see the help file for <code>egamma</code>).
See the help file Estimating Distribution Parameters for a list of
estimating functions.
The default value is <code>est.arg.list=NULL</code> so that all default values for the
estimating functions are used.
</p>
<p>When testing for some form of normality (i.e., Normal, Lognormal,
Three-Parameter Lognormal,
Zero-Modified Normal, or
Zero-Modified Lognormal (Delta)),
the estimated parameters are provided in the output merely for
information, and the choice of the method of estimation has no effect
on the goodness-of-fit test statistics or p-values.
</p>
<p>This argument is ignored when <code>method="proucl"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>

<p>logical scalar indicating whether to print a warning message when
observations with <code>NA</code>s, <code>NaN</code>s, or <code>Inf</code>s in
<code>y</code> are removed.  The default value is <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.data</code></td>
<td>

<p>logical scalar indicating whether to return the original data.  The
default value is <code>keep.data=TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>

<p>optional character string indicating the name of the data used for argument <code>y</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parent.of.data</code></td>
<td>

<p>character string indicating the source of the data used for the
goodness-of-fit test.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset.expression</code></td>
<td>

<p>character string indicating the expression used to subset the data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments affecting the goodness-of-fit test.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>distChoose</code> returns a list with information on the goodness-of-fit
tests for various distributions and which distribution appears to best fit the
data based on the p-values from the goodness-of-fit tests.  This function was written in
order to compare ProUCL's way of choosing the best-fitting distribution (USEPA, 2015) with
other ways of choosing the best-fitting distribution.
</p>
<p><b>Method Based on Shapiro-Wilk, Shapiro-Francia, or Probability Plot Correlation Test</b> <br>
(<code>method="sw"</code>, <code>method="sf"</code>, or <code>method="ppcc"</code>)
</p>
<p>For each value of the argument <code>choices</code>, the function <code>distChoose</code>
runs the goodness-of-fit test using the data in <code>y</code> assuming that particular
distribution.  For example, if <br><code>choices=c("norm", "gamma", "lnorm")</code>,
indicating the Normal, Gamma, and Lognormal distributions, and
<code>method="sw"</code>, then the usual Shapiro-Wilk test is performed for the Normal
and Lognormal distributions, and the extension of the Shapiro-Wilk test is performed
for the Gamma distribution (see the section
<em>Testing Goodness-of-Fit for Any Continuous Distribution</em> in the help
file for <code>gofTest</code> for an explanation of the latter).  The distribution associated
with the largest p-value is the chosen distribution.  In the case when all p-values are
less than the value of the argument <code>alpha</code>, the distribution “Nonparametric” is chosen.  <br></p>
<p><b>Method Based on ProUCL Algorithm</b> (<code>method="proucl"</code>)
</p>
<p>When <code>method="proucl"</code>, the function <code>distChoose</code> uses the
algorithm that ProUCL (USEPA, 2015) uses to determine the best fitting
distribution.  The candidate distributions are the
Normal, Gamma, and Lognormal distributions.  The algorithm
used by ProUCL is as follows:
</p>

<ol>
<li>
<p> Perform the Shapiro-Wilk and Lilliefors goodness-of-fit tests for the
Normal distribution, i.e., call the function <code>gofTest</code> with
<code>distribution = "norm", test="sw"</code> and <br><code>distribution = "norm", test="lillie"</code>.
If either or both of the associated p-values are greater than or equal to the user-supplied value
of <code>alpha</code>, then choose the Normal distribution.  Otherwise, proceed to the next step.
</p>
</li>
<li>
<p> Perform the “ProUCL Anderson-Darling” and “ProUCL Kolmogorov-Smirnov” goodness-of-fit
tests for the Gamma distribution,
i.e., call the function <code>gofTest</code> with <br><code>distribution="gamma", test="proucl.ad.gamma"</code> and <br><code>distribution="gamma", test="proucl.ks.gamma"</code>.
If either or both of the associated p-values are greater than or equal to the user-supplied value
of <code>alpha</code>, then choose the Gamma distribution.  Otherwise, proceed to the next step.
</p>
</li>
<li>
<p> Perform the Shapiro-Wilk and Lilliefors goodness-of-fit tests for the
Lognormal distribution, i.e., call the function <code>gofTest</code> with
<code>distribution="lnorm", test="sw"</code> and <br><code>distribution="lnorm", test="lillie"</code>.
If either or both of the associated p-values are greater than or equal to the user-supplied value
of <code>alpha</code>, then choose the Lognormal distribution.  Otherwise, proceed to the next step.
</p>
</li>
<li>
<p> If none of the goodness-of-fit tests above yields a p-value greater than or equal to the user-supplied value
of <code>alpha</code>, then choose the “Nonparametric” distribution.
</p>
</li>
</ol>
<h3>Value</h3>

<p>a list of class <code>"distChoose"</code> containing the results of the goodness-of-fit tests.
Objects of class <code>"distChoose"</code> have a special printing method.
See the help files for <code>distChoose.object</code> for details.
</p>


<h3>Note</h3>

<p>In practice, almost any goodness-of-fit test will <em>not</em> reject the null hypothesis
if the number of observations is relatively small.  Conversely, almost any goodness-of-fit
test <em>will</em> reject the null hypothesis if the number of observations is very large,
since “real” data are never distributed according to any theoretical distribution
(Conover, 1980, p.367).  For most cases, however, the distribution of “real” data
is close enough to some theoretical distribution that fairly accurate results may be
provided by assuming that particular theoretical distribution.  One way to asses the
goodness of the fit is to use goodness-of-fit tests.  Another way is to look at
quantile-quantile (Q-Q) plots (see <code>qqPlot</code>).
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Birnbaum, Z.W., and F.H. Tingey. (1951).
One-Sided Confidence Contours for Probability Distribution Functions.
<em>Annals of Mathematical Statistics</em> <b>22</b>, 592-596.
</p>
<p>Blom, G. (1958). <em>Statistical Estimates and Transformed Beta Variables</em>.
John Wiley and Sons, New York.
</p>
<p>Conover, W.J. (1980). <em>Practical Nonparametric Statistics</em>. Second Edition.
John Wiley and Sons, New York.
</p>
<p>Dallal, G.E., and L. Wilkinson. (1986).
An Analytic Approximation to the Distribution of Lilliefor's Test for Normality.
<em>The American Statistician</em> <b>40</b>, 294-296.
</p>
<p>D'Agostino, R.B. (1970). Transformation to Normality of the Null Distribution of <code class="reqn">g1</code>.
<em>Biometrika</em> <b>57</b>, 679-681.
</p>
<p>D'Agostino, R.B. (1971). An Omnibus Test of Normality for Moderate and Large Size Samples.
<em>Biometrika</em> <b>58</b>, 341-348.
</p>
<p>D'Agostino, R.B. (1986b). Tests for the Normal Distribution. In: D'Agostino, R.B., and M.A. Stephens, eds.
<em>Goodness-of Fit Techniques</em>. Marcel Dekker, New York.
</p>
<p>D'Agostino, R.B., and E.S. Pearson (1973). Tests for Departures from Normality.
Empirical Results for the Distributions of <code class="reqn">b2</code> and <code class="reqn">\sqrt{b1}</code>.
<em>Biometrika</em> <b>60</b>(3), 613-622.
</p>
<p>D'Agostino, R.B., and G.L. Tietjen (1973). Approaches to the Null Distribution of <code class="reqn">\sqrt{b1}</code>.
<em>Biometrika</em> <b>60</b>(1), 169-173.
</p>
<p>Fisher, R.A. (1950). <em>Statistical Methods for Research Workers</em>. 11'th Edition.
Hafner Publishing Company, New York, pp.99-100.
</p>
<p>Gibbons, R.D., D.K. Bhaumik, and S. Aryal. (2009).
<em>Statistical Methods for Groundwater Monitoring</em>, Second Edition.
John Wiley &amp; Sons, Hoboken.
</p>
<p>Kendall, M.G., and A. Stuart. (1991).
<em>The Advanced Theory of Statistics, Volume 2: Inference and Relationship</em>.
Fifth Edition. Oxford University Press, New York.
</p>
<p>Kim, P.J., and R.I. Jennrich. (1973).
Tables of the Exact Sampling Distribution of the Two Sample Kolmogorov-Smirnov Criterion.
In Harter, H.L., and D.B. Owen, eds. <em>Selected Tables in Mathematical Statistics, Vol. 1</em>.
American Mathematical Society, Providence, Rhode Island, pp.79-170.
</p>
<p>Kolmogorov, A.N. (1933). Sulla determinazione empirica di una legge di distribuzione.
<em>Giornale dell' Istituto Italiano degle Attuari</em> <b>4</b>, 83-91.
</p>
<p>Marsaglia, G., W.W. Tsang, and J. Wang. (2003). Evaluating Kolmogorov's distribution.
<em>Journal of Statistical Software</em>, <b>8</b>(18).
<a href="https://doi.org/10.18637/jss.v008.i18">doi:10.18637/jss.v008.i18</a>.
</p>
<p>Moore, D.S. (1986). Tests of Chi-Squared Type. In D'Agostino, R.B., and M.A. Stephens, eds.
<em>Goodness-of Fit Techniques</em>. Marcel Dekker, New York, pp.63-95.
</p>
<p>Pomeranz, J. (1973).
Exact Cumulative Distribution of the Kolmogorov-Smirnov Statistic for Small Samples (Algorithm 487).
<em>Collected Algorithms from ACM</em> ??, ???-???.
</p>
<p>Royston, J.P. (1992a). Approximating the Shapiro-Wilk W-Test for Non-Normality.
<em>Statistics and Computing</em> <b>2</b>, 117-119.
</p>
<p>Royston, J.P. (1992b).
Estimation, Reference Ranges and Goodness of Fit for the Three-Parameter Log-Normal Distribution.
<em>Statistics in Medicine</em> <b>11</b>, 897-912.
</p>
<p>Royston, J.P. (1992c).
A Pocket-Calculator Algorithm for the Shapiro-Francia Test of Non-Normality: An Application to Medicine.
<em>Statistics in Medicine</em> <b>12</b>, 181-184.
</p>
<p>Royston, P. (1993). A Toolkit for Testing for Non-Normality in Complete and Censored Samples.
<em>The Statistician</em> <b>42</b>, 37-43.
</p>
<p>Ryan, T., and B. Joiner. (1973). <em>Normal Probability Plots and Tests for Normality</em>.
Technical Report, Pennsylvannia State University, Department of Statistics.
</p>
<p>Shapiro, S.S., and R.S. Francia. (1972). An Approximate Analysis of Variance Test for Normality.
<em>Journal of the American Statistical Association</em> <b>67</b>(337), 215-219.
</p>
<p>Shapiro, S.S., and M.B. Wilk. (1965). An Analysis of Variance Test for Normality (Complete Samples).
<em>Biometrika</em> <b>52</b>, 591-611.
</p>
<p>Smirnov, N.V. (1939).
Estimate of Deviation Between Empirical Distribution Functions in Two Independent Samples.
<em>Bulletin Moscow University</em> <b>2</b>(2), 3-16.
</p>
<p>Smirnov, N.V. (1948). Table for Estimating the Goodness of Fit of Empirical Distributions.
<em>Annals of Mathematical Statistics</em> <b>19</b>, 279-281.
</p>
<p>Stephens, M.A. (1970).
Use of the Kolmogorov-Smirnov, Cramer-von Mises and Related Statistics Without Extensive Tables.
<em>Journal of the Royal Statistical Society, Series B</em>, <b>32</b>, 115-122.
</p>
<p>Stephens, M.A. (1986a). Tests Based on EDF Statistics. In D'Agostino, R. B., and M.A. Stevens, eds.
<em>Goodness-of-Fit Techniques</em>. Marcel Dekker, New York.
</p>
<p>USEPA. (2015).  <em>ProUCL Version 5.1.002 Technical Guide</em>.  EPA/600/R-07/041, October 2015.
Office of Research and Development. U.S. Environmental Protection Agency, Washington, D.C.
</p>
<p>Verrill, S., and R.A. Johnson. (1987).
The Asymptotic Equivalence of Some Modified Shapiro-Wilk Statistics – Complete and Censored Sample Cases.
<em>The Annals of Statistics</em> <b>15</b>(1), 413-419.
</p>
<p>Verrill, S., and R.A. Johnson. (1988).
Tables and Large-Sample Distribution Theory for Censored-Data Correlation Statistics for Testing Normality.
<em>Journal of the American Statistical Association</em> <b>83</b>, 1192-1197.
</p>
<p>Weisberg, S., and C. Bingham. (1975).
An Approximate Analysis of Variance Test for Non-Normality Suitable for Machine Calculation.
<em>Technometrics</em> <b>17</b>, 133-134.
</p>
<p>Wilk, M.B., and S.S. Shapiro. (1968). The Joint Assessment of Normality of Several Independent
Samples. <em>Technometrics</em>, <b>10</b>(4), 825-839.
</p>
<p>Zar, J.H. (2010). <em>Biostatistical Analysis</em>. Fifth Edition.
Prentice-Hall, Upper Saddle River, NJ.
</p>


<h3>See Also</h3>

<p><code>gofTest</code>, <code>distChoose.object</code>, <code>print.distChoose</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Generate 20 observations from a gamma distribution with
  # parameters shape = 2 and scale = 3 and:
  #
  # 1) Call distChoose using the Shapiro-Wilk method.
  #
  # 2) Call distChoose using the Shapiro-Wilk method and specify
  #    the bias-corrected method of estimating shape for the Gamma
  #    distribution.
  #
  # 3) Compare the results in 2) above with the results using the
  #    ProUCL method.
  #
  # Notes:  The call to set.seed lets you reproduce this example.
  #
  #         The ProUCL method chooses the Normal distribution, whereas the
  #         Shapiro-Wilk method chooses the Gamma distribution.

  set.seed(47)
  dat &lt;- rgamma(20, shape = 2, scale = 3)


  # 1) Call distChoose using the Shapiro-Wilk method.
  #--------------------------------------------------

  distChoose(dat)

  #Results of Choosing Distribution
  #--------------------------------
  #
  #Candidate Distributions:         Normal
  #                                 Gamma
  #                                 Lognormal
  #
  #Choice Method:                   Shapiro-Wilk
  #
  #Type I Error per Test:           0.05
  #
  #Decision:                        Gamma
  #
  #Estimated Parameter(s):          shape = 1.909462
  #                                 scale = 4.056819
  #
  #Estimation Method:               MLE
  #
  #Data:                            dat
  #
  #Sample Size:                     20
  #
  #Test Results:
  #
  #  Normal
  #    Test Statistic:              W = 0.9097488
  #    P-value:                     0.06303695
  #
  #  Gamma
  #    Test Statistic:              W = 0.9834958
  #    P-value:                     0.970903
  #
  #  Lognormal
  #    Test Statistic:              W = 0.9185006
  #    P-value:                     0.09271768

  #--------------------

  # 2) Call distChoose using the Shapiro-Wilk method and specify
  #    the bias-corrected method of estimating shape for the Gamma
  #    distribution.
  #---------------------------------------------------------------

  distChoose(dat, method = "sw",
    est.arg.list = list(gamma = list(method = "bcmle")))

  #Results of Choosing Distribution
  #--------------------------------
  #
  #Candidate Distributions:         Normal
  #                                 Gamma
  #                                 Lognormal
  #
  #Choice Method:                   Shapiro-Wilk
  #
  #Type I Error per Test:           0.05
  #
  #Decision:                        Gamma
  #
  #Estimated Parameter(s):          shape = 1.656376
  #                                 scale = 4.676680
  #
  #Estimation Method:               Bias-Corrected MLE
  #
  #Data:                            dat
  #
  #Sample Size:                     20
  #
  #Test Results:
  #
  #  Normal
  #    Test Statistic:              W = 0.9097488
  #    P-value:                     0.06303695
  #
  #  Gamma
  #    Test Statistic:              W = 0.9834346
  #    P-value:                     0.9704046
  #
  #  Lognormal
  #    Test Statistic:              W = 0.9185006
  #    P-value:                     0.09271768

  #--------------------

  # 3) Compare the results in 2) above with the results using the
  #    ProUCL method.
  #---------------------------------------------------------------

  distChoose(dat, method = "proucl")

  #Results of Choosing Distribution
  #--------------------------------
  #
  #Candidate Distributions:         Normal
  #                                 Gamma
  #                                 Lognormal
  #
  #Choice Method:                   ProUCL
  #
  #Type I Error per Test:           0.05
  #
  #Decision:                        Normal
  #
  #Estimated Parameter(s):          mean = 7.746340
  #                                 sd   = 5.432175
  #
  #Estimation Method:               mvue
  #
  #Data:                            dat
  #
  #Sample Size:                     20
  #
  #Test Results:
  #
  #  Normal
  #    Shapiro-Wilk GOF
  #      Test Statistic:            W = 0.9097488
  #      P-value:                   0.06303695
  #    Lilliefors (Kolmogorov-Smirnov) GOF
  #      Test Statistic:            D = 0.1547851
  #      P-value:                   0.238092
  #
  #  Gamma
  #    ProUCL Anderson-Darling Gamma GOF
  #      Test Statistic:            A = 0.1853826
  #      P-value:                   &gt;= 0.10
  #    ProUCL Kolmogorov-Smirnov Gamma GOF
  #      Test Statistic:            D = 0.0988692
  #      P-value:                   &gt;= 0.10
  #
  #  Lognormal
  #    Shapiro-Wilk GOF
  #      Test Statistic:            W = 0.9185006
  #      P-value:                   0.09271768
  #    Lilliefors (Kolmogorov-Smirnov) GOF
  #      Test Statistic:            D = 0.149317
  #      P-value:                   0.2869177

  #--------------------

  # Clean up
  #---------

  rm(dat)

  #====================================================================

  # Example 10-2 of USEPA (2009, page 10-14) gives an example of
  # using the Shapiro-Wilk test to test the assumption of normality
  # for nickel concentrations (ppb) in groundwater collected over
  # 4 years.  The data for this example are stored in
  # EPA.09.Ex.10.1.nickel.df.

  EPA.09.Ex.10.1.nickel.df
  #   Month   Well Nickel.ppb
  #1      1 Well.1       58.8
  #2      3 Well.1        1.0
  #3      6 Well.1      262.0
  #4      8 Well.1       56.0
  #5     10 Well.1        8.7
  #6      1 Well.2       19.0
  #7      3 Well.2       81.5
  #8      6 Well.2      331.0
  #9      8 Well.2       14.0
  #10    10 Well.2       64.4
  #11     1 Well.3       39.0
  #12     3 Well.3      151.0
  #13     6 Well.3       27.0
  #14     8 Well.3       21.4
  #15    10 Well.3      578.0
  #16     1 Well.4        3.1
  #17     3 Well.4      942.0
  #18     6 Well.4       85.6
  #19     8 Well.4       10.0
  #20    10 Well.4      637.0

  # Use distChoose with the probability plot correlation method,
  # and for the lognormal distribution specify the
  # mean and CV parameterization:
  #------------------------------------------------------------

  distChoose(Nickel.ppb ~ 1, data = EPA.09.Ex.10.1.nickel.df,
    choices = c("norm", "gamma", "lnormAlt"), method = "ppcc")

  #Results of Choosing Distribution
  #--------------------------------
  #
  #Candidate Distributions:         Normal
  #                                 Gamma
  #                                 Lognormal
  #
  #Choice Method:                   PPCC
  #
  #Type I Error per Test:           0.05
  #
  #Decision:                        Lognormal
  #
  #Estimated Parameter(s):          mean = 213.415628
  #                                 cv   =   2.809377
  #
  #Estimation Method:               mvue
  #
  #Data:                            Nickel.ppb
  #
  #Data Source:                     EPA.09.Ex.10.1.nickel.df
  #
  #Sample Size:                     20
  #
  #Test Results:
  #
  #  Normal
  #    Test Statistic:              r = 0.8199825
  #    P-value:                     5.753418e-05
  #
  #  Gamma
  #    Test Statistic:              r = 0.9749044
  #    P-value:                     0.317334
  #
  #  Lognormal
  #    Test Statistic:              r = 0.9912528
  #    P-value:                     0.9187852

  #--------------------

  # Repeat the above example using the ProUCL method.
  #--------------------------------------------------

  distChoose(Nickel.ppb ~ 1, data = EPA.09.Ex.10.1.nickel.df,
    method = "proucl")

  #Results of Choosing Distribution
  #--------------------------------
  #
  #Candidate Distributions:         Normal
  #                                 Gamma
  #                                 Lognormal
  #
  #Choice Method:                   ProUCL
  #
  #Type I Error per Test:           0.05
  #
  #Decision:                        Gamma
  #
  #Estimated Parameter(s):          shape =   0.5198727
  #                                 scale = 326.0894272
  #
  #Estimation Method:               MLE
  #
  #Data:                            Nickel.ppb
  #
  #Data Source:                     EPA.09.Ex.10.1.nickel.df
  #
  #Sample Size:                     20
  #
  #Test Results:
  #
  #  Normal
  #    Shapiro-Wilk GOF
  #      Test Statistic:            W = 0.6788888
  #      P-value:                   2.17927e-05
  #    Lilliefors (Kolmogorov-Smirnov) GOF
  #      Test Statistic:            D = 0.3267052
  #      P-value:                   5.032807e-06
  #
  #  Gamma
  #    ProUCL Anderson-Darling Gamma GOF
  #      Test Statistic:            A = 0.5076725
  #      P-value:                   &gt;= 0.10
  #    ProUCL Kolmogorov-Smirnov Gamma GOF
  #      Test Statistic:            D = 0.1842904
  #      P-value:                   &gt;= 0.10
  #
  #  Lognormal
  #    Shapiro-Wilk GOF
  #      Test Statistic:            W = 0.978946
  #      P-value:                   0.9197735
  #    Lilliefors (Kolmogorov-Smirnov) GOF
  #      Test Statistic:            D = 0.08405167
  #      P-value:                   0.9699648

  #====================================================================

  ## Not run: 
  # 1) Simulate 1000 trials where for each trial you:
  #    a) Generate 20 observations from a Gamma distribution with
  #       parameters mean = 10 and CV = 1.
  #    b) Use distChoose with the Shapiro-Wilk method.
  #    c) Use distChoose with the ProUCL method.
  #
  #  2) Compare the proportion of times the
  #     Normal vs. Gamma vs. Lognormal vs. Nonparametric distribution
  #     is chosen for b) and c) above.
  #------------------------------------------------------------------

  set.seed(58)
  N &lt;- 1000

  Choose.fac &lt;- factor(rep("", N), levels = c("Normal", "Gamma", "Lognormal", "Nonparametric"))
  Choose.df &lt;- data.frame(SW = Choose.fac, ProUCL = Choose.fac)

  for(i in 1:N) {
    dat &lt;- rgammaAlt(20, mean = 10, cv = 1)
    Choose.df[i, "SW"]     &lt;- distChoose(dat, method = "sw")$decision
    Choose.df[i, "ProUCL"] &lt;- distChoose(dat, method = "proucl")$decision
  }

  summaryStats(Choose.df, digits = 0)

  #              ProUCL(N) ProUCL(Pct) SW(N) SW(Pct)
  #Normal              443          44    41       4
  #Gamma               546          55   733      73
  #Lognormal             9           1   215      22
  #Nonparametric         2           0    11       1
  #Combined           1000         100  1000     100


  #--------------------


  # Repeat above example for the Lognormal Distribution with mean=10 and CV = 1.
  #-----------------------------------------------------------------------------

  set.seed(297)
  N &lt;- 1000

  Choose.fac &lt;- factor(rep("", N), levels = c("Normal", "Gamma", "Lognormal", "Nonparametric"))
  Choose.df &lt;- data.frame(SW = Choose.fac, ProUCL = Choose.fac)

  for(i in 1:N) {
    dat &lt;- rlnormAlt(20, mean = 10, cv = 1)
    Choose.df[i, "SW"]     &lt;- distChoose(dat, method = "sw")$decision
    Choose.df[i, "ProUCL"] &lt;- distChoose(dat, method = "proucl")$decision
  }

  summaryStats(Choose.df, digits = 0)

  #              ProUCL(N) ProUCL(Pct) SW(N) SW(Pct)
  #Normal              313          31    15       2
  #Gamma               556          56   254      25
  #Lognormal           121          12   706      71
  #Nonparametric        10           1    25       2
  #Combined           1000         100  1000     100


  #--------------------


  # Clean up
  #---------

  rm(N, Choose.fac, Choose.df, i, dat)
  
## End(Not run)

</code></pre>


</div>