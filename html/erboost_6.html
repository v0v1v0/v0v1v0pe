<div class="container">

<table style="width: 100%;"><tr>
<td>erboost.perf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>erboost performance</h2>

<h3>Description</h3>

<p>Estimates the optimal number of boosting iterations for a <code>erboost</code> object and
optionally plots various performance measures
</p>


<h3>Usage</h3>

<pre><code class="language-R">erboost.perf(object, 
         plot.it = TRUE, 
         oobag.curve = FALSE, 
         overlay = TRUE, 
         method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a <code>erboost.object</code> created from an initial call to 
<code>erboost</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot.it</code></td>
<td>
<p>an indicator of whether or not to plot the performance measures.
Setting <code>plot.it=TRUE</code> creates two plots. The first plot plots 
<code>object$train.error</code> (in black) and <code>object$valid.error</code> (in red) 
versus the iteration number. The scale of the error measurement, shown on the 
left vertical axis, depends on the <code>distribution</code> argument used in the 
initial call to <code>erboost</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>oobag.curve</code></td>
<td>
<p>indicates whether to plot the out-of-bag performance measures
in a second plot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overlay</code></td>
<td>
<p>if TRUE and oobag.curve=TRUE then a right y-axis is added to the 
training and test error plot and the estimated cumulative improvement in the loss 
function is plotted versus the iteration number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>indicate the method used to estimate the optimal number
of boosting iterations. <code>method="OOB"</code> computes the out-of-bag
estimate and <code>method="test"</code> uses the test (or validation) dataset 
to compute an out-of-sample estimate. <code>method="cv"</code> extracts the 
optimal number of iterations using cross-validation if <code>erboost</code> was called
with <code>cv.folds</code>&gt;1</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>erboost.perf</code> returns the estimated optimal number of iterations. The method 
of computation depends on the <code>method</code> argument.</p>


<h3>Author(s)</h3>

<p>Yi Yang <a href="mailto:yiyang@umn.edu">yiyang@umn.edu</a> and Hui Zou <a href="mailto:hzou@stat.umn.edu">hzou@stat.umn.edu</a></p>


<h3>References</h3>

<p>Yang, Y. and Zou, H. (2015), “Nonparametric Multiple Expectile Regression via ER-Boost,” <em>Journal of Statistical Computation and Simulation</em>, 84(1), 84-95.
</p>
<p>G. Ridgeway (1999). “The state of boosting,” <em>Computing Science and
Statistics</em> 31:172-181.
</p>
<p><a href="https://cran.r-project.org/package=gbm">https://cran.r-project.org/package=gbm</a><br></p>


<h3>See Also</h3>

<p><code>erboost</code>, <code>erboost.object</code></p>


</div>