<div class="container">

<table style="width: 100%;"><tr>
<td>summaryByCrossValid</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Summarize distribution/niche model cross-validation object</h2>

<h3>Description</h3>

<p>This function summarizes models calibrated using the <code>trainByCrossValid</code> function. It returns aspects of the best models across k-folds (the particular aspects depends on the kind of models used).
</p>


<h3>Usage</h3>

<pre><code class="language-R">summaryByCrossValid(
  x,
  metric = "cbiTest",
  decreasing = TRUE,
  interceptOnly = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The output from the <code>trainByCrossValid</code> function (which is a list). Note that the object <em>must</em> include a sublist named <code>tuning</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>Metric by which to select the best model in each k-fold. This can be any of the columns that appear in the data frames in <code>x$tuning</code> (or any columns added manually), but typically is one of the following <em>plus</em> either <code>Train</code>, <code>Test</code>, or <code>Delta</code> (e.g., <code>'logLossTrain'</code>, <code>'logLossTest'</code>, or <code>'logLossDelta'</code>):
</p>

<ul>
<li> <p><code>'logLoss'</code>: Log loss.
</p>
</li>
<li> <p><code>'cbi'</code>: Continuous Boyce Index (CBI). Calculated with <code>evalContBoyce</code>.
</p>
</li>
<li> <p><code>'auc'</code>: Area under the receiver-operator characteristic curve (AUC). Calculated with <code>evalAUC</code>.
</p>
</li>
<li> <p><code>'tss'</code>: Maximum value of the True Skill Statistic. Calculated with <code>evalTSS</code>.
</p>
</li>
<li> <p><code>'msss'</code>: Sensitivity and specificity calculated at the threshold that maximizes sensitivity (true presence prediction rate) plus specificity (true absence prediction rate).
</p>
</li>
<li> <p><code>'mdss'</code>: Sensitivity (se) and specificity (sp) calculated at the threshold that minimizes the difference between sensitivity and specificity.
</p>
</li>
<li> <p><code>'minTrainPres'</code>: Sensitivity and specificity at the greatest threshold at which all training presences are classified as "present".
</p>
</li>
<li> <p><code>'trainSe95'</code> and/or <code>'trainSe90'</code>: Sensitivity at the threshold that ensures either 95
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>decreasing</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), for each k-fold sort models by the value listed in <code>metric</code> in decreasing order (highest connotes "best", lowest "worst"). If <code>FALSE</code> use the lowest value of <code>metric</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interceptOnly</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default) and the top models in each case were intercept-only models, return an emppty data frame (with a warning). If <code>FALSE</code>, return results using the first model in each fold that was not an intercept-only model. This is only used if the training function was a generalized linear model (GLM), natural splines model (NS), or generalized additive model (GAM).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Data frame with statistics on the best set of models across k-folds. Depending on the model algorithm, this could be:
</p>

<ul>
<li>
<p> BRTs (boosted regression trees): Learning rate, tree complexity, and bag fraction.
</p>
</li>
<li>
<p> GLMs (generalized linear models): Frequency of use of each term in the best models.
</p>
</li>
<li>
<p> Maxent: Frequency of times each specific combination of feature classes was used in the best models plus mean master regularization multiplier for each feature set.
</p>
</li>
<li>
<p> NSs (natural splines): Data frame, one row per fold and one column per predictor, with values representing the maximum degrees of freedom used for each variable in the best model of each fold.
</p>
</li>
<li>
<p> RFs (random forests): Data frame, one row per fold, with values representing the optimal value of <code>numTrees</code> and <code>mtry</code> (see <code>ranger</code>).
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>trainByCrossValid</code>, <code>trainBRT</code>, <code>trainGAM</code>, <code>trainGLM</code>, <code>trainMaxEnt</code>, <code>trainNS</code>, <code>trainRF</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># The example below show a very basic modeling workflow. It has been 
# designed to work fast, not produce accurate, defensible models.
# The general idea is to calibrate a series of models and evaluate them
# against a withheld set of data. One can then use the series of models
# of the top models to better select a "final" model.

## Not run: 
# Running the entire set of commands can take a few minutes. This can
# be sped up by increasing the number of cores used. The examples below use
# one core, but you can change that argument according to your machine's
# capabilities.

library(sf)
library(terra)
set.seed(123)

### setup data
##############

# environmental rasters
rastFile &lt;- system.file('extdata/madClim.tif', package='enmSdmX')
madClim &lt;- rast(rastFile)

# coordinate reference system
wgs84 &lt;- getCRS('WGS84')

# lemur occurrence data
data(lemurs)
occs &lt;- lemurs[lemurs$species == 'Eulemur fulvus', ]
occs &lt;- vect(occs, geom=c('longitude', 'latitude'), crs=wgs84)

occs &lt;- elimCellDuplicates(occs, madClim)

occEnv &lt;- extract(madClim, occs, ID = FALSE)
occEnv &lt;- occEnv[complete.cases(occEnv), ]
	
# create background sites (using just 1000 to speed things up!)
bgEnv &lt;- terra::spatSample(madClim, 3000)
bgEnv &lt;- bgEnv[complete.cases(bgEnv), ]
bgEnv &lt;- bgEnv[sample(nrow(bgEnv), 1000), ]

# collate occurrences and background sites
presBg &lt;- data.frame(
   presBg = c(
      rep(1, nrow(occEnv)),
      rep(0, nrow(bgEnv))
   )
)

env &lt;- rbind(occEnv, bgEnv)
env &lt;- cbind(presBg, env)

predictors &lt;- c('bio1', 'bio12')

# using "vector" form of "folds" argument
folds &lt;- dismo::kfold(env, 3) # just 3 folds (for speed)

### calibrate models
####################

cores &lt;- 1 # increase this to go faster, if your computer handles it

## MaxEnt
mxx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainMaxEnt,
	regMult = 1:2, # too few values for valid model, but fast!
	verbose = 1,
	cores = cores
)

# summarize MaxEnt feature sets and regularization across folds
summaryByCrossValid(mxx)

## MaxNet
mnx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainMaxNet,
	regMult = 1:2, # too few values for valid model, but fast!
	verbose = 1,
	cores = cores
)

# summarize MaxEnt feature sets and regularization across folds
summaryByCrossValid(mnx)

## generalized linear models
glx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainGLM,
	verbose = 1,
	cores = cores
)

# summarize GLM terms in best models
summaryByCrossValid(glx)

## generalized additive models
gax &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainGAM,
	verbose = 1,
	cores = cores
)

# summarize GAM terms in best models
summaryByCrossValid(gax)

## natural splines
nsx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainNS,
	df = 1:2,
	verbose = 1,
	cores = cores
)

# summarize NS terms in best models
summaryByCrossValid(nsx)

## boosted regression trees
brtx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainBRT,
	learningRate = c(0.001, 0.0001), # too few values for reliable model(?)
	treeComplexity = c(2, 4), # too few values for reliable model, but fast
	minTrees = 1000,
	maxTrees = 1500, # too small for reliable model(?), but fast
	tryBy = 'treeComplexity',
	anyway = TRUE, # return models that did not converge
	verbose = 1,
	cores = cores
)

# summarize BRT parameters across best models
summaryByCrossValid(brtx)

## random forests
rfx &lt;- trainByCrossValid(
	data = env,
	resp = 'presBg',
	preds = c('bio1', 'bio12'),
	folds = folds,
	trainFx = trainRF,
	verbose = 1,
	cores = cores
)

# summarize RF parameters in best models
summaryByCrossValid(rfx)


## End(Not run)
</code></pre>


</div>