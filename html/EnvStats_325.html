<div class="container">

<table style="width: 100%;"><tr>
<td>kendallTrendTest</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Kendall's Nonparametric Test for Montonic Trend
</h2>

<h3>Description</h3>

<p>Perform a nonparametric test for a monotonic trend based on Kendall's
tau statistic, and optionally compute a confidence interval for the
slope.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kendallTrendTest(y, ...)

## S3 method for class 'formula'
kendallTrendTest(y, data = NULL, subset,
  na.action = na.pass, ...)

## Default S3 method:
kendallTrendTest(y, x = seq(along = y),
  alternative = "two.sided", correct = TRUE, ci.slope = TRUE,
  conf.level = 0.95, warn = TRUE, data.name = NULL, data.name.x = NULL,
  parent.of.data = NULL, subset.expression = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>an object containing data for the trend test.  In the default method,
the argument <code>y</code> must be numeric vector of observations.
In the formula method, <code>y</code> must be a formula of the form <code>y ~ 1</code> or
<code>y ~ x</code>.  The form <code>y ~ 1</code> indicates use the observations in the vector
<code>y</code> for the test for trend and use the default value of the argument <code>x</code>
in the call to <code>kendallTrendTest.default</code>.  The form <code>y ~ x</code> indicates
use the observations in the vector <code>y</code> for the test for trend and use the
specified value of the argument <code>x</code> in the call to
<code>kendallTrendTest.default</code>.  Missing (<code>NA</code>), undefined (<code>NaN</code>),
and infinite (<code>Inf</code>, <code>-Inf</code>) values are allowed but will be
removed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>specifies an optional data frame, list or environment (or object coercible by
<code>as.data.frame</code> to a data frame) containing the variables in the model.
If not found in <code>data</code>, the variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>kendallTrendTest</code> is called.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>specifies an optional vector specifying a subset of observations to be used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>

<p>specifies a function which indicates what should happen when the data contain <code>NA</code>s.
The default is <code>na.pass</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>numeric vector of "predictor" values.  The length of <code>x</code> must equal the length of <code>y</code>.
Missing (<code>NA</code>), undefined (<code>NaN</code>), and infinite (<code>Inf</code>, <code>-Inf</code>) values are
allowed but will be removed.  The default value of <code>x</code> is the vector
of numbers <code class="reqn">1, 2, \dots, n</code> where <code class="reqn">n</code> is the number of elements in
<code>y</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>

<p>character string indicating the kind of alternative hypothesis.  The
possible values are <code>"two.sided"</code> (tau not equal to 0; the default),
<code>"less"</code> (tau less than 0), and <code>"greater"</code> (tau greater than 0).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>correct</code></td>
<td>

<p>logical scalar indicating whether to use the correction for continuity in
computing the <code class="reqn">z</code>-statistic that is based on the test statistic <code class="reqn">S</code>.
The default value is <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.slope</code></td>
<td>

<p>logical scalar indicating whether to compute a confidence interval for the
slope.  The default value is <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>

<p>numeric scalar between 0 and 1 indicating the confidence level associated
with the confidence interval for the slope.  The default value is
<code>0.95</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>

<p>logical scalar indicating whether to print a warning message when
<code>y</code> does not contain at least two non-missing values,
or when <code>x</code> does not contain at least two unique non-missing values.
The default value is <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>

<p>character string indicating the name of the data used for the trend test.
The default value is <code>deparse(substitute(y))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name.x</code></td>
<td>

<p>character string indicating the name of the data used for the predictor variable x.
If <code>x</code> is not supplied this argument is ignored.  When <code>x</code> is supplied,
the default value is <code>deparse(substitute(x))</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parent.of.data</code></td>
<td>

<p>character string indicating the source of the data used for the trend test.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset.expression</code></td>
<td>

<p>character string indicating the expression used to subset the data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments affecting the test for trend.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>kendallTrendTest</code> performs Kendall's nonparametric test for a monotonic trend,
which is a special case of the test for independence based on Kendall's tau statistic
(see <code>cor.test</code>).  The slope is estimated using the method of Theil (1950) and
Sen (1968).  When <code>ci.slope=TRUE</code>, the confidence interval for the slope is
computed using Gilbert's (1987) Modification of the Theil/Sen Method.
</p>
<p>Kendall's test for a monotonic trend is a special case of the test for independence
based on Kendall's tau statistic.  The first section below explains the general case
of testing for independence.  The second section explains the special case of
testing for monotonic trend.  The last section explains how a simple linear
regression model is a special case of a monotonic trend and how the slope may be
estimated.
<br></p>
<p><b>The General Case of Testing for Independence</b> <br></p>
<p><em>Definition of Kendall's Tau</em> <br>
Let <code class="reqn">X</code> and <code class="reqn">Y</code> denote two continuous random variables with some joint
(bivariate) distribution.  Let <code class="reqn">(X_1, Y_1), (X_2, Y_2), \ldots, (X_n, Y_n)</code>
denote a set of <code class="reqn">n</code> bivariate observations from this distribution, and assume
these bivariate observations are mutually independent.  Kendall (1938, 1975) proposed
a test for the hypothesis that the <code class="reqn">X</code> and <code class="reqn">Y</code> random variables are
independent based on estimating the following quantity:
</p>
<p style="text-align: center;"><code class="reqn">\tau = \{ 2 Pr[(X_2 - X_1)(Y_2 - Y_1) &gt; 0] \} - 1 \;\;\;\;\;\; (1)</code>
</p>

<p>The quantity in Equation (1) is called Kendall's tau, although this term is more
often applied to the estimate of <code class="reqn">\tau</code> (see Equation (2) below).
If <code class="reqn">X</code> and <code class="reqn">Y</code> are independent, then <code class="reqn">\tau=0</code>.  Furthermore, for most
distributions of interest, if <code class="reqn">\tau=0</code> then the random variables <code class="reqn">X</code> and
<code class="reqn">Y</code> are independent.  (It can be shown that there exist some distributions for
which <code class="reqn">\tau=0</code> and the random variables <code class="reqn">X</code> and <code class="reqn">Y</code> are not independent;
see Hollander and Wolfe (1999, p.364)).
</p>
<p>Note that Kendall's tau is similar to a correlation coefficient in that
<code class="reqn">-1 \le \tau \le 1</code>.  If <code class="reqn">X</code> and <code class="reqn">Y</code> always vary in the same direction,
that is if <code class="reqn">X_1 &lt; X_2</code> always implies <code class="reqn">Y_1 &lt; Y_2</code>, then <code class="reqn">\tau = 1</code>.
If <code class="reqn">X</code> and <code class="reqn">Y</code> always vary in the opposite direction, that is if
<code class="reqn">X_1 &lt; X_2</code> always implies <code class="reqn">Y_1 &gt; Y_2</code>, then <code class="reqn">\tau = -1</code>.  If
<code class="reqn">\tau &gt; 0</code>, this indicates <code class="reqn">X</code> and <code class="reqn">Y</code> are positively associated.
If <code class="reqn">\tau &lt; 0</code>, this indicates <code class="reqn">X</code> and <code class="reqn">Y</code> are negatively associated.
<br></p>
<p><em>Estimating Kendall's Tau</em> <br>
The quantity in Equation (1) can be estimated by:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\tau} = \frac{2S}{n(n-1)} \;\;\;\;\;\; (2)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">S = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} sign[(X_j - X_i)(Y_j - Y_i)] \;\;\;\;\;\; (3)</code>
</p>

<p>and <code class="reqn">sign()</code> denotes the <code>sign</code> function:
</p>

<table>
<tr>
<td style="text-align: left;">
                    </td>
<td style="text-align: right;"> <code class="reqn">-1</code> </td>
<td style="text-align: left;"> <code class="reqn">x &lt; 0</code> </td>
</tr>
<tr>
<td style="text-align: left;">
    <code class="reqn">sign(x) =</code> </td>
<td style="text-align: right;"> <code class="reqn">0</code>  </td>
<td style="text-align: left;"> <code class="reqn">x = 0 \;\;\;\;\;\; (4)</code> </td>
</tr>
<tr>
<td style="text-align: left;">
                    </td>
<td style="text-align: right;"> <code class="reqn">1</code>  </td>
<td style="text-align: left;"> <code class="reqn">x &gt; 0</code>
  </td>
</tr>
</table>
<p>(Hollander and Wolfe, 1999, Chapter 8; Conover, 1980, pp.256–260;
Gilbert, 1987, Chapter 16; Helsel and Hirsch, 1992, pp.212–216;
Gibbons et al., 2009, Chapter 11). The quantity defined in Equation (2) is called
Kendall's rank correlation coefficient or more often Kendall's tau.
</p>
<p>Note that the quantity <code class="reqn">S</code> defined in Equation (3) is equal to the number of
concordant pairs minus the number of discordant pairs.  Hollander and Wolfe
(1999, p.364) use the notation <code class="reqn">K</code> instead of <code class="reqn">S</code>, and Conover (1980, p.257)
uses the notation <code class="reqn">T</code>.
<br></p>
<p><em>Testing the Null Hypothesis of Independence</em> <br>
The null hypothesis <code class="reqn">H_0: \tau = 0</code>, can be tested using the statistic <code class="reqn">S</code>
defined in Equation (3) above.  Tables of the distribution of <code class="reqn">S</code> for small
samples are given in Hollander and Wolfe (1999), Conover (1980, pp.458–459),
Gilbert (1987, p.272), Helsel and Hirsch (1992, p.469), and Gibbons (2009, p.210).
The function <code>kendallTrendTest</code> uses the large sample approximation to the
distribution of <code class="reqn">S</code> under the null hypothesis, which is given by:
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{S - E(S)}{\sqrt{Var(S)}} \;\;\;\;\;\; (5)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">E(S) = 0 \;\;\;\;\;\; (6)</code>
</p>

<p style="text-align: center;"><code class="reqn">Var(S) = \frac{n(n-1)(2n+5)}{18} \;\;\;\;\;\; (7)</code>
</p>

<p>Under the null hypothesis, the quantity <code class="reqn">z</code> defined in Equation (5) is
approximately distributed as a standard normal random variable.
</p>
<p>Both Kendall (1975) and Mann (1945) show that the normal approximation is excellent
even for samples as small as <code class="reqn">n=10</code>, provided that the following continuity
correction is used:
</p>
<p style="text-align: center;"><code class="reqn">z = \frac{S - sign(S)}{\sqrt{Var(S)}} \;\;\;\;\;\; (8)</code>
</p>

<p>The function <code>kendallTrendTest</code> performs the usual one-sample z-test using
the statistic computed in Equation (8) or Equation (5).  The argument
<code>correct</code> determines which equation is used to compute the z-statistic.
By default, <code>correct=TRUE</code> so Equation (8) is used.
</p>
<p>In the case of tied observations in either the observed <code class="reqn">X</code>'s and/or observed
<code class="reqn">Y</code>'s, the formula for the variance of <code class="reqn">S</code> given in Equation (7) must be
modified as follows:
</p>

<table>
<tr>
<td style="text-align: left;">
  <code class="reqn">Var(S) =</code> </td>
<td style="text-align: left;"> <code class="reqn">\frac{n(n-1)(2n+5)}{18} -</code> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> <code class="reqn">\frac{\sum_{i=1}^{g} t_i(t_i-1)(2t_i+5)}{18} - </code> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> <code class="reqn">\frac{\sum_{j=1}^{h} u_j(u_j-1)(2u_j+5)}{18} + </code> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> <code class="reqn">\frac{[\sum_{i=1}^{g} t_i(t_i-1)(t_i-2)][\sum_{j=1}^{h} u_j(u_j-1)(u_j-2)]}{9n(n-1)(n-2)} +</code> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> </td>
</tr>
<tr>
<td style="text-align: left;">
                 </td>
<td style="text-align: left;"> <code class="reqn">\frac{[\sum_{i=1}^{g} t_i(t_i-1)][\sum_{j=1}^{h} u_j(u_j-1)]}{2n(n-1)} \;\;\;\;\;\; (9)</code>
  </td>
</tr>
</table>
<p>where <code class="reqn">g</code> is the number of tied groups in the <code class="reqn">X</code> observations,
<code class="reqn">t_i</code> is the size of the <code class="reqn">i</code>'th tied group in the <code class="reqn">X</code> observations,
<code class="reqn">h</code> is the number of tied groups in the <code class="reqn">Y</code> observations, and
<code class="reqn">u_j</code> is the size of the <code class="reqn">j</code>'th tied group in the <code class="reqn">Y</code> observations.
In the case of no ties in either the <code class="reqn">X</code> or <code class="reqn">Y</code> observations, Equation (9)
reduces to Equation (7).
<br></p>
<p><b>The Special Case of Testing for Monotonic Trend</b> <br>
Often in environmental sampling, observations are taken periodically over time
(Hirsch et al., 1982; van Belle and Hughes, 1984; Hirsch and Slack, 1984).  In
this case, the random variables <code class="reqn">Y_1, Y_2, \ldots, Y_n</code> can be thought of as
representing the observations, and the variables <code class="reqn">X_1, X_2, \ldots, X_n</code>
are no longer random but represent the time at which the <code class="reqn">i</code>'th observation
was taken.  If the observations are equally spaced over time, then it is useful to
make the simplification <code class="reqn">X_i = i</code> for <code class="reqn">i = 1, 2, \ldots, n</code>.  This is in
fact the default value of the argument <code>x</code> for the function
<code>kendallTrendTest</code>.
</p>
<p>In the case where the <code class="reqn">X</code>'s represent time and are all distinct, the test for
independence between <code class="reqn">X</code> and <code class="reqn">Y</code> is equivalent to testing for a monotonic
trend in <code class="reqn">Y</code>, and the test statistic <code class="reqn">S</code> simplifies to:
</p>
<p style="text-align: center;"><code class="reqn">S = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} sign(Y_j - Y_i) \;\;\;\;\;\; (10)</code>
</p>

<p>Also, the formula for the variance of <code class="reqn">S</code> in the presence of ties (under the
null hypothesis <code class="reqn">H_0: \tau = 0</code>) simplifies to:
</p>
<p style="text-align: center;"><code class="reqn">Var(S) = \frac{n(n-1)(2n+5)}{18} - \frac{\sum_{j=1}^{h} u_j(u_j-1)(2u_j+5)}{18} \;\;\;\;\;\; (11)</code>
</p>

<p>A form of the test statistic <code class="reqn">S</code> in Equation (10) was introduced by Mann (1945).
<br></p>
<p><b>The Special Case of a Simple Linear Model:  Estimating the Slope</b> <br>
Consider the simple linear regression model
</p>
<p style="text-align: center;"><code class="reqn">Y_i = \beta_0 + \beta_1 X_i + \epsilon_i \;\;\;\;\;\; (12)</code>
</p>

<p>where <code class="reqn">\beta_0</code> denotes the intercept, <code class="reqn">\beta_1</code> denotes the slope,
<code class="reqn">i = 1, 2, \ldots, n</code>, and the <code class="reqn">\epsilon</code>'s are assumed to be
independent and identically distributed random variables from the same distribution.
This is a special case of dependence between the <code class="reqn">X</code>'s and the <code class="reqn">Y</code>'s, and
the null hypothesis of a zero slope can be tested using Kendall's test statistic
<code class="reqn">S</code> (Equation (3) or (10) above) and the associated z-statistic
(Equation (5) or (8) above) (Hollander and Wolfe, 1999, pp.415–420).
</p>
<p>Theil (1950) proposed the following nonparametric estimator of the slope:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\beta}_1 = Median(\frac{Y_j - Y_i}{X_j - X_i}); \;\; i &lt; j \;\;\;\;\;\; (13)</code>
</p>

<p>Note that the computation of the estimated slope involves computing
</p>
<p style="text-align: center;"><code class="reqn">N = {n \choose 2} = \frac{n(n-1)}{2} \;\;\;\;\;\; (14)</code>
</p>

<p>“two-point” estimated slopes (assuming no tied <code class="reqn">X</code> values), and taking
the median of these N values.
</p>
<p>Sen (1968) generalized this estimator to the case where there are possibly tied
observations in the <code class="reqn">X</code>'s.  In this case, Sen simply ignores the two-point
estimated slopes where the <code class="reqn">X</code>'s are tied and computes the median based on the
remaining <code class="reqn">N'</code> two-point estimated slopes.  That is, Sen's estimator is given by:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\beta}_1 = Median(\frac{Y_j - Y_i}{X_j - X_i}); \;\; i &lt; j, X_i \ne X_j  \;\;\;\;\;\; (15)</code>
</p>

<p>(Hollander and Wolfe, 1999, pp.421–422).
</p>
<p>Conover (1980, p. 267) suggests the following estimator for the intercept:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\beta}_0 = Y_{0.5} - \hat{\beta}_1 X_{0.5} \;\;\;\;\;\; (16)</code>
</p>

<p>where <code class="reqn">X_{0.5}</code> and <code class="reqn">Y_{0.5}</code> denote the sample medians of the <code class="reqn">X</code>'s
and <code class="reqn">Y</code>'s, respectively.  With these estimators of slope and intercept, the
estimated regression line passes through the point <code class="reqn">(X_{0.5}, Y_{0.5})</code>.
</p>
<p><b>NOTE:</b> The function <code>kendallTrendTest</code> always returns estimates of
slope and intercept assuming a linear model (Equation (12)), while the p-value
is based on Kendall's tau, which is testing for the broader alternative of any
kind of dependence between the <code class="reqn">X</code>'s and <code class="reqn">Y</code>'s.
<br></p>
<p><em>Confidence Interval for the Slope</em> <br>
Theil (1950) and Sen (1968) proposed methods to compute a confidence interval for
the true slope, assuming the linear model of Equation (12) (see
Hollander and Wolfe, 1999, pp.421-422).  Gilbert (1987, p.218) illustrates a
simpler method than the one given by Sen (1968) that is based on a normal
approximation.  Gilbert's (1987) method is an extension of the one given in
Hollander and Wolfe (1999, p.424) that allows for ties and/or multiple
observations per time period.  This method is valid for a sample size as small as
<code class="reqn">n=10</code> unless there are several tied observations.
</p>
<p>Let <code class="reqn">N'</code> denote the number of defined two-point estimated slopes that are used
in Equation (15) above (if there are no tied <code class="reqn">X</code> values then <code class="reqn">N' = N</code>), and
let <code class="reqn">\hat{\beta}_{1_{(1)}}, \hat{\beta}_{1_{(2)}}, \ldots, \hat{\beta}_{1_{(N')}}</code>
denote the <code class="reqn">N'</code> ordered slopes.  For Gilbert's (1987) method, a
<code class="reqn">100(1-\alpha)\%</code> two-sided confidence interval for the true slope is given by:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{\beta}_{1_{(M1)}}, \hat{\beta}_{1_{(M2+1)}}] \;\;\;\;\;\; (17)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">M1 = \frac{N' - C_{\alpha}}{2} \;\;\;\;\;\; (18)</code>
</p>

<p style="text-align: center;"><code class="reqn">M2 = \frac{N' + C_{\alpha}}{2} \;\;\;\;\;\; (19)</code>
</p>

<p style="text-align: center;"><code class="reqn">C_\alpha = z_{1 - \alpha/2} \sqrt{Var(S)} \;\;\;\;\;\; (20)</code>
</p>

<p><code class="reqn">Var(S)</code> is defined in Equations (7), (9), or (11), and
<code class="reqn">z_p</code> denotes the <code class="reqn">p</code>'th quantile of the standard normal distribution.
One-sided confidence intervals may computed in a similar fashion.
</p>
<p>Usually the quantities <code class="reqn">M1</code> and <code class="reqn">M2</code> will not be integers.
Gilbert (1987, p.219) suggests interpolating between adjacent values in this case,
which is what the function <code>kendallTrendTest</code> does.
</p>


<h3>Value</h3>

<p>A list of class <code>"htest"</code> containing the results of the hypothesis
test.  See the help file for <code>htest.object</code> for details.
In addition, the following components are part of the list returned by
<code>kendallTrendTest</code>:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>The value of the Kendall S-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.S</code></td>
<td>
<p>The variance of the Kendall S-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>slopes</code></td>
<td>
<p>A numeric vector of all possible two-point slope estimates.
This component is used by the function <code>kendallSeasonalTrendTest</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Kendall's test for independence or trend is a nonparametric test.  No
assumptions are made about the distribution of the <code class="reqn">X</code> and <code class="reqn">Y</code>
variables.  Hirsch et al. (1982) introduced the "seasonal Kendall test" to
test for trend within each season.  They note that Kendall's test for trend
is easy to compute, even in the presence of missing values, and can also be
used with censored values.
</p>
<p>van Belle and Hughes (1984) note that Kendall's test for trend is slightly
less powerful than the test based on Spearman's rho, but it converges to
normality faster.  Also, Bradley (1968, p.288) shows that for the case of a
linear model with normal (Gaussian) errors, the asymptotic relative
efficiency of Kendall's test for trend versus the parametric test for a
zero slope is 0.98.
</p>
<p>The results of the function <code>kendallTrendTest</code> are similar to the
results of the built-in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> function <code>cor.test</code> with the
argument <code>method="kendall"</code> except that <code>cor.test</code>
1) computes exact p-values when the number of pairs is less than 50 and
there are no ties, and 2) does not return a confidence interval for
the slope.
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Bradley, J.V. (1968). <em>Distribution-Free Statistical Tests</em>.
Prentice-Hall, Englewood Cliffs, NJ.
</p>
<p>Conover, W.J. (1980). <em>Practical Nonparametric Statistics</em>. Second Edition.
John Wiley and Sons, New York, pp.256-272.
</p>
<p>Gibbons, R.D., D.K. Bhaumik, and S. Aryal. (2009).
<em>Statistical Methods for Groundwater Monitoring</em>, Second Edition.
John Wiley &amp; Sons, Hoboken.
</p>
<p>Gilbert, R.O. (1987). <em>Statistical Methods for Environmental Pollution Monitoring</em>.
Van Nostrand Reinhold, New York, NY, Chapter 16.
</p>
<p>Helsel, D.R. and R.M. Hirsch. (1988). Discussion of Applicability of the t-test for Detecting Trends
in Water Quality Variables. <em>Water Resources Bulletin</em> <b>24</b>(1), 201-204.
</p>
<p>Helsel, D.R., and R.M. Hirsch. (1992). <em>Statistical Methods in Water Resources Research</em>.
Elsevier, NY.
</p>
<p>Helsel, D.R., and R. M. Hirsch. (2002). <em>Statistical Methods in Water Resources</em>.
Techniques of Water Resources Investigations, Book 4, chapter A3. U.S. Geological Survey.
Available on-line at <a href="https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf">https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf</a>.
</p>
<p>Hirsch, R.M., J.R. Slack, and R.A. Smith. (1982). Techniques of Trend Analysis for Monthly Water Quality
Data. <em>Water Resources Research</em> <b>18</b>(1), 107-121.
</p>
<p>Hirsch, R.M. and J.R. Slack. (1984). A Nonparametric Trend Test for Seasonal Data with Serial Dependence.
<em>Water Resources Research</em> <b>20</b>(6), 727-732.
</p>
<p>Hirsch, R.M., R.B. Alexander, and R.A. Smith. (1991). Selection of Methods for the Detection and
Estimation of Trends in Water Quality. <em>Water Resources Research</em> <b>27</b>(5), 803-813.
</p>
<p>Hollander, M., and D.A. Wolfe. (1999). <em>Nonparametric Statistical Methods,
Second Edition</em>.  John Wiley and Sons, New York.
</p>
<p>Kendall, M.G. (1938). A New Measure of Rank Correlation. <em>Biometrika</em> <b>30</b>, 81-93.
</p>
<p>Kendall, M.G. (1975). <em>Rank Correlation Methods</em>. Charles Griffin, London.
</p>
<p>Mann, H.B. (1945). Nonparametric Tests Against Trend. <em>Econometrica</em> <b>13</b>, 245-259.
</p>
<p>Millard, S.P., and Neerchal, N.K. (2001). <em>Environmental Statistics with S-PLUS</em>.
CRC Press, Boca Raton, Florida.
</p>
<p>Sen, P.K. (1968). Estimates of the Regression Coefficient Based on Kendall's Tau.
<em>Journal of the American Statistical Association</em> <b>63</b>, 1379-1389.
</p>
<p>Theil, H. (1950). A Rank-Invariant Method of Linear and Polynomial Regression Analysis, I-III.
<em>Proc. Kon. Ned. Akad. v. Wetensch. A.</em> <b>53</b>, 386-392, 521-525, 1397-1412.
</p>
<p>USEPA. (2009).  <em>Statistical Analysis of Groundwater Monitoring Data at RCRA Facilities, Unified Guidance</em>.
EPA 530/R-09-007, March 2009.  Office of Resource Conservation and Recovery Program Implementation and Information Division.
U.S. Environmental Protection Agency, Washington, D.C.
</p>
<p>USEPA. (2010).  <em>Errata Sheet - March 2009 Unified Guidance</em>.
EPA 530/R-09-007a, August 9, 2010.  Office of Resource Conservation and Recovery, Program Information and Implementation Division.
U.S. Environmental Protection Agency, Washington, D.C.
</p>
<p>van Belle, G., and J.P. Hughes. (1984). Nonparametric Tests for Trend in Water Quality.
<em>Water Resources Research</em> <b>20</b>(1), 127-136.
</p>


<h3>See Also</h3>

<p><code>cor.test</code>, <code>kendallSeasonalTrendTest</code>, <code>htest.object</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Reproduce Example 17-6 on page 17-33 of USEPA (2009).  This example
  # tests for trend in sulfate concentrations (ppm) collected at various
  # months between 1989 and 1996.

  head(EPA.09.Ex.17.6.sulfate.df)
  #  Sample.No Year Month Sampling.Date       Date Sulfate.ppm
  #1         1   89     6          89.6 1989-06-01         480
  #2         2   89     8          89.8 1989-08-01         450
  #3         3   90     1          90.1 1990-01-01         490
  #4         4   90     3          90.3 1990-03-01         520
  #5         5   90     6          90.6 1990-06-01         485
  #6         6   90     8          90.8 1990-08-01         510


  # Plot the data
  #--------------
  dev.new()
  with(EPA.09.Ex.17.6.sulfate.df,
    plot(Sampling.Date, Sulfate.ppm, pch = 15, ylim = c(400, 900),
    xlab = "Sampling Date", ylab = "Sulfate Conc (ppm)",
    main = "Figure 17-6. Time Series Plot of \nSulfate Concentrations (ppm)")
  )
  Sulfate.fit &lt;- lm(Sulfate.ppm ~ Sampling.Date,
    data = EPA.09.Ex.17.6.sulfate.df)
  abline(Sulfate.fit, lty = 2)


  # Perform the Kendall test for trend
  #-----------------------------------
  kendallTrendTest(Sulfate.ppm ~ Sampling.Date,
    data = EPA.09.Ex.17.6.sulfate.df)

  #Results of Hypothesis Test
  #--------------------------
  #
  #Null Hypothesis:                 tau = 0
  #
  #Alternative Hypothesis:          True tau is not equal to 0
  #
  #Test Name:                       Kendall's Test for Trend
  #                                 (with continuity correction)
  #
  #Estimated Parameter(s):          tau       =     0.7667984
  #                                 slope     =    26.6666667
  #                                 intercept = -1909.3333333
  #
  #Estimation Method:               slope:      Theil/Sen Estimator
  #                                 intercept:  Conover's Estimator
  #
  #Data:                            y = Sulfate.ppm
  #                                 x = Sampling.Date
  #
  #Data Source:                     EPA.09.Ex.17.6.sulfate.df
  #
  #Sample Size:                     23
  #
  #Test Statistic:                  z = 5.107322
  #
  #P-value:                         3.267574e-07
  #
  #Confidence Interval for:         slope
  #
  #Confidence Interval Method:      Gilbert's Modification
  #                                 of Theil/Sen Method
  #
  #Confidence Interval Type:        two-sided
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             LCL = 20.00000
  #                                 UCL = 35.71182


  # Clean up
  #---------
  rm(Sulfate.fit)
  graphics.off()
</code></pre>


</div>