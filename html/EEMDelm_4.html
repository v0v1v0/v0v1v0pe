<div class="container">

<table style="width: 100%;"><tr>
<td>EMDelm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Empirical Mode Decomposition Based ELM Model
</h2>

<h3>Description</h3>

<p>The EMDelm function computes forecasted value with different forecasting evaluation criteria for Empirical Mode Decomposition based Extreme Learning Machine model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">EMDelm(xt, stepahead = 10, s.num = 4L, num.sift = 50L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xt</code></td>
<td>

<p>Input univariate time series (ts) data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stepahead</code></td>
<td>

<p>The forecast horizon.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s.num</code></td>
<td>

<p>Integer. Use the S number stopping criterion for the EMD procedure with the given values of S. That is, iterate until the number of extrema and zero crossings in the signal differ at most by one, and stay the same for S consecutive iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.sift</code></td>
<td>

<p>Number of siftings to find out IMFs.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function decomposes the original time series into several independent intrinsic mode functions (IMFs) and one residual component (Huang et al., 1998). Then extreme learning machine, a class of feedforward neural network is used to forecast these IMFs and residual component individually (Huang et al., 2006). Finally, the prediction results of all IMFs including residual are aggregated to formulate an ensemble output for the original time series.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>TotalIMF </code></td>
<td>
<p>Total number of IMFs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AllIMF </code></td>
<td>
<p>List of all IMFs with residual for input series.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data_test </code></td>
<td>
<p>Testing set is used to measure the out of sample performance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AllIMF_forecast </code></td>
<td>
<p>Forecasted value of all individual IMF.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FinalEMDELM_forecast </code></td>
<td>
<p>Final forecasted value of the EMDELM model.It is obtained by combining the forecasted value of all individual IMF.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAE_EMDELM </code></td>
<td>
<p>Mean Absolute Error (MAE) for EMDELM model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAPE_EMDELM </code></td>
<td>
<p>Mean Absolute Percentage Error (MAPE) for EMDELM  model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rmse_EMDELM </code></td>
<td>
<p>Root Mean Square Error (RMSE) for EMDELM model.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Choudhary, K., Jha, G.K., Kumar, R.R. and Mishra, D.C. (2019) Agricultural commodity price analysis using ensemble empirical mode decomposition: A case study of daily potato price series. Indian journal of agricultural sciences, 89(5), 882–886.
</p>
<p>Dong, J., Dai, W., Tang, L. and Yu, L. (2019) Why do EMD based methods improve prediction. A multiscale complexity perspective. Journal of Forecasting, 38(7), 714–731.
</p>
<p>Huang, N.E., Shen, Z., Long, S.R., Wu, M.C., Shih, H.H., Zheng, Q. and Liu, H.H. (1998). The empirical mode decomposition and the Hilbert spectrum for nonlinear and non stationary time series analysis. In Proceedings of the Royal Society of London A: mathematical, physical and engineering sciences. 454, 903–995.
</p>
<p>Huang, G.B., Zhu, Q.Y. and Siew, C.K. (2006). Extreme learning machine: theory and applications. Neurocomputing, 70, 489–501.
</p>


<h3>See Also</h3>

<p>EEMDELM, CEEMDANelm
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data("Data_Soybean")
EMDelm(Data_Soybean)

</code></pre>


</div>