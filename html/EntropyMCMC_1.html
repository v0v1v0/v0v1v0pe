<div class="container">

<table style="width: 100%;"><tr>
<td>EntropyMCMC-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>(A)MCMC Simulation and Convergence Evaluation using Entropy and
Kullback-Leibler Divergence  Estimation</h2>

<h3>Description</h3>

<p>Contains functions to analyse (Adaptive) Markov Chain Monte Carlo (MCMC) algorithms, evaluate their convergence rate, and compare candidate MCMC algorithms for a same target density, based on entropy and Kullback-Leibler divergence criteria. MCMC algorithms can be simulated using provided functions, or imported from external codes.
The diagnostics are based on consistent estimates of entropy and Kulback distance 
between the density at
iteration <code class="reqn">t</code> and the target density <code class="reqn">f</code>, based on iid (parallel) chains.</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> EntropyMCMC</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 1.0.4</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2019-03-08</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
<td style="text-align: left;">
LazyLoad: </td>
<td style="text-align: left;"> yes</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p><b>Statistical background:</b>
</p>
<p>This package allows for simulation of standard or adaptive MCMC samplers for a user-defined
target density, and provides statistical tools to evaluate convergence of MCMC's 
and compare performance of algorithms for the same target density
(typically against benchmark samplers).
</p>
<p>The criteria are graphical and based on plots against iterations (time) <code class="reqn">t</code>,
of the <em>Kullback divergence</em> 
<code class="reqn">K(p^t,f)</code>
between the density <code class="reqn">p^t</code> of the MCMC algorithm at time <code class="reqn">t</code>, 
and the target density <code class="reqn">f</code>, for <code class="reqn">t=1</code> up to the number of iterations 
that have been simulated.
This requires estimation of the  entropy of  <code class="reqn">p^t</code>,
</p>
<p style="text-align: center;"><code class="reqn">E_{p^t} [\log(p^t)],</code>
</p>

<p>and of the external entropy  
</p>
<p style="text-align: center;"><code class="reqn">E_{p^t} [\log(f)].</code>
</p>

<p>Consistent estimates are computed based on <code class="reqn">N</code> iid (parallel) chains, 
since the <code class="reqn">N</code> positions of the chains at iterations <code class="reqn">t</code> 
forms a <code class="reqn">N</code>-iid sample from the density <code class="reqn">p^t</code>.
</p>
<p><b>Computational considerations:</b>
</p>
<p>The simulation of iid chains can be performed in this package, which provides a mechanism 
for defining (A)MCMC algorithms and building the iid chains required for convergence evaluation.
Each MCMC algorithm is defined by a list with five elements.
Each user can define its own MCMC, starting from the standard MCMC algorithms
that are already defined:
</p>

<ul>
<li> <p><code>RWHM</code>: a standard Randow-Walk Hastings-Metropolis (HM) algorithm.
</p>
</li>
<li> <p><code>HMIS_norm</code>: an Independence Sampler HM with gaussian proposal
</p>
</li>
<li> <p><code>AMHaario</code>: the
Haario (2001) Adaptive Hastings-Metropolis algorithm, provided as an example 
of a standard AMCMC.
</p>
</li>
<li> <p><code>IID_norm</code>: a “fake” MCMC that is just a gaussian IID sampler, used mostly
for testing purpose. Simulation of <code class="reqn">N</code> iid chains for <code class="reqn">n</code> iterations using this algorithm just returns <code class="reqn">N\times n</code> gaussian <code class="reqn">d</code>-dimensional vectors.
</p>
</li>
</ul>
<p>Functions for doing the simulations and the convergence evaluation
automatically using these algorithms in their first argument are provided.
Two strategies are available:
</p>

<ul>
<li> <p><em>Simulation and Kullback estimation separately:</em>
A “cube” of <code class="reqn">N</code> chains for <code class="reqn">n</code> iterations in a space of dimension <code class="reqn">d</code>
is first simulated and stored using <code>MCMCcopies</code> or its multicore or cluser versions, 
then the entropy and Kullback divergence 
are estimated from that object using <code>EntropyMCMC</code> or its multicore version.
</p>
</li>
<li> <p><em>Simulation and Kullback estimation simultaneously:</em>
For each iteration <code class="reqn">t</code>, the next step of all the  <code>N</code>
chains are generated,
then the Entropy and Kullback divergence <code class="reqn">K(p^t,f)</code>
are estimated, and the past of the parallel chains 
is discarded so that the amount of memory requirement is kept small, and
only entropy-related estimates are stored and returned. Functions for this strategy are
<code>EntropyParallel</code> and its multicore and cluster version.
</p>
</li>
</ul>
<p>See the Examples section of <code>plot_Kblist</code> for an illustration of these two methods.
</p>
<p><b>Doing the simulations outside from this package</b>
</p>
<p>A third hybrid strategy is also available:
the simulation of iid chains can be done using an external code
(in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>, <code>C</code> or any language) and imported 
in the <span class="pkg">EntropyMCMC</span> package (defining an object of the appropriate class 
<code>"plMCMC"</code> and structure, see <code>MCMCcopies</code>).
</p>
<p>Then the Kullback divergence criterion can be computed using <code>EntropyMCMC</code> 
or its multicore version, and convergence/comparison diagnostics can be displayed 
using the associated <code>plot</code> method.
</p>
<p><b>About High Performance Computing</b>
</p>
<p>The required simulations can be done using singlecore or
HCP (multicore computers, snow or clusters using the <span class="pkg">parallel</span> or
<span class="pkg">Rmpi</span> pakages). Note that the <span class="pkg">parallel</span> package using socket cluster is not 
available on Windows machines.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau,
Institut Denis Poisson, 
University of Orleans, CNRS, Orleans France.
<a href="https://www.idpoisson.fr/chauveau/">https://www.idpoisson.fr/chauveau/</a>
</p>
<p>Maintainer: Didier Chauveau <a href="mailto:didier.chauveau@univ-orleans.fr">didier.chauveau@univ-orleans.fr</a>
</p>
<p>Contributor: Houssam Alrachid
</p>


<h3>References</h3>


<ul>
<li>
<p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419–431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816–2827.
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li>
</ul>
</div>