<div class="container">

<table style="width: 100%;"><tr>
<td>elm_train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Extreme Learning Machine training function</h2>

<h3>Description</h3>

<p>Extreme Learning Machine training function
</p>


<h3>Usage</h3>

<pre><code class="language-R">elm_train(
  x,
  y,
  nhid,
  actfun,
  init_weights = "normal_gaussian",
  bias = FALSE,
  moorep_pseudoinv_tol = 0.01,
  leaky_relu_alpha = 0,
  seed = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a matrix. The columns of the input matrix should be of type numeric</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a matrix. In case of regression the matrix should have <em>n</em> rows and <em>1</em> column. In case of classification it should consist of <em>n</em> rows and <em>n</em> columns, where <em>n &gt; 1</em> and equals to the number of the unique labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nhid</code></td>
<td>
<p>a numeric value specifying the hidden neurons. Must be &gt;= 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>actfun</code></td>
<td>
<p>a character string specifying the type of activation function. It should be one of the following : 'sig' <em>( sigmoid )</em>, 'sin' <em>( sine )</em>, 'radbas' <em>( radial basis )</em>, 'hardlim' <em>( hard-limit )</em>, 'hardlims' <em>( symmetric hard-limit )</em>, 'satlins' <em>( satlins )</em>, 'tansig' <em>( tan-sigmoid )</em>, 'tribas' <em>( triangular basis )</em>, 'relu' <em>( rectifier linear unit )</em> or 'purelin' <em>( linear )</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init_weights</code></td>
<td>
<p>a character string spcecifying the distribution from which the <em>input-weights</em> and the <em>bias</em> should be initialized. It should be one of the following : 'normal_gaussian' <em>(normal / Gaussian distribution with zero mean and unit variance)</em>, 'uniform_positive' <em>( in the range [0,1] )</em> or 'uniform_negative' <em>( in the range [-1,1] )</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias</code></td>
<td>
<p>either TRUE or FALSE. If TRUE then <em>bias</em> weights will be added to the hidden layer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>moorep_pseudoinv_tol</code></td>
<td>
<p>a numeric value. See the references web-link for more details on <em>Moore-Penrose pseudo-inverse</em> and specifically on the <em>pseudo inverse tolerance value</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>leaky_relu_alpha</code></td>
<td>
<p>a numeric value between 0.0 and 1.0. If 0.0 then a simple <em>relu</em> ( f(x) = 0.0 for x &lt; 0, f(x) = x for x &gt;= 0 ) activation function will be used, otherwise a <em>leaky-relu</em> ( f(x) = alpha * x for x &lt; 0, f(x) = x for x &gt;= 0 ). It is applicable only if <em>actfun</em> equals to 'relu'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>a numeric value specifying the random seed. Defaults to 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>a boolean. If TRUE then information will be printed in the console</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The input matrix should be of type numeric. This means the user should convert any <em>character</em>, <em>factor</em> or <em>boolean</em> columns to numeric values before using the <em>elm_train</em> function
</p>


<h3>References</h3>

<p>http://arma.sourceforge.net/docs.html
</p>
<p>https://en.wikipedia.org/wiki/Moore
</p>
<p>https://www.kaggle.com/robertbm/extreme-learning-machine-example
</p>
<p>http://rt.dgyblog.com/ml/ml-elm.html
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(elmNNRcpp)

#-----------
# Regression
#-----------

data(Boston, package = 'KernelKnn')

Boston = as.matrix(Boston)
dimnames(Boston) = NULL

x = Boston[, -ncol(Boston)]
y = matrix(Boston[, ncol(Boston)], nrow = length(Boston[, ncol(Boston)]), ncol = 1)

out_regr = elm_train(x, y, nhid = 20, actfun = 'purelin', init_weights = 'uniform_negative')


#---------------
# Classification
#---------------

data(ionosphere, package = 'KernelKnn')

x_class = ionosphere[, -c(2, ncol(ionosphere))]
x_class = as.matrix(x_class)
dimnames(x_class) = NULL

y_class = as.numeric(ionosphere[, ncol(ionosphere)])

y_class_onehot = onehot_encode(y_class - 1)     # class labels should begin from 0

out_class = elm_train(x_class, y_class_onehot, nhid = 20, actfun = 'relu')

</code></pre>


</div>