<div class="container">

<table style="width: 100%;"><tr>
<td>EntropyParallel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parallel simulation and Entropy estimation of MCMC's
- single core and cluster versions
</h2>

<h3>Description</h3>

<p>This function simulates “parallel chains” (iid copies) 
of a MCMC algorithm, i.e.
for each “time” iteration <code class="reqn">t</code> the next step of all the  <code>nmc</code>
chains are generated,
then the Entropy of the density <code class="reqn">p^t</code> of the algorithm at iteration
<code class="reqn">t</code>, 
<code class="reqn">E_{p^t}[\log(p^t)]</code>,
and the Kullback divergence between <code class="reqn">p^t</code> and the target density
are estimated, based on these <code>nmc</code> steps iid from <code class="reqn">p^t</code>.
By default <code>keep.all = FALSE</code> i.e. the past of the parallel chains 
is discarded so that the amount of memory requirement is kept small, and
only entropy-related estimates are returned. 
If <code>keep.all = TRUE</code>, the entire set of chains trajectories
is saved in an array of dimensions <code>(n,d,nmc)</code>, such as the one
returned by <code>MCMCcopies</code> or <code>MCMCcopies.cl</code>.
</p>
<p>A version of this function implementing several HPC (parallel) computing
strategies is available (see details).
</p>


<h3>Usage</h3>

<pre><code class="language-R">EntropyParallel(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param,
          method = "A.Nearest.Neighbor",k=1, trim = 0.02, keep.all = FALSE,
          verb = TRUE, EntVect = FALSE)

EntropyParallel.cl(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param,
          method = "A.Nearest.Neighbor",k=1, eps = 0, trim=0.02,
          verb=TRUE, EntVect = FALSE, cltype="PAR_SOCK", nbnodes = 4,
          par.logf = FALSE, uselogtarget = FALSE, logtarget = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mcmc_algo</code></td>
<td>
<p>a list defining an MCMC algorithm in terms of the 
functions it uses, such as <code>RWHM</code>, see details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The number of (time) iterations of each single chain to run.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ptheta0</code></td>
<td>
<p>A <code>(nmc,d)</code> matrix, with the ith row giving a d-dimensional 
initial theta values for the ith chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in the example below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f_param</code></td>
<td>
<p>A list holding all the necessary target parameters,
including the data in an actual Bayesian model, and
consistent with the target definition.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The method for estimating the entropy 
<code class="reqn">E_{p^t}[\log(p^t)]</code>. 
The methods currently  implemented for this function are
<code>"Nearest.Neighbor"</code> as in Kozachenko and Leonenko (1987), 
<code>"k.Nearest.Neighbor"</code> as in      
Leonenko et al. (2005) (the default in the single core version),	and 
<code>"A.Nearest.Neighbor"</code> which is as <code>"k.NearestNeighbor"</code> using the
<span class="pkg">RANN</span> package for (Approximate) fast computation of nearest neighbors, 
instead of R code (the default for the cluster version).
Other methods such as  <code>"Gyorfi.trim"</code> subsampling method as defined in 
Gyorfi and Vander Mulen (1989) are available as well
(see Chauveau and Vandekerkhove (2012)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>The k-nearest neighbor index, the default is <code class="reqn">k=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Error bound: default of 0.0 implies exact nearest neighbour search, see
the <span class="pkg">RANN</span> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trim</code></td>
<td>
<p>not used in this implementation, only for <code>method="Gyorfi.trim"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.all</code></td>
<td>
<p>If <code>TRUE</code>, all the simulated chains are stored in a 3-dimensional
array of dimensions <code>(n,d,nmc)</code>, such as the one returned by
<code>MCMCcopies</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verb</code></td>
<td>
<p>Verbose mode for summarizing output during the simulation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EntVect</code></td>
<td>
<p>If <code>FALSE</code> (the default), the entropy is computed only on the kth-nearest neighbor. If <code>TRUE</code>,  the entropy is computed for all j-NN's for <code class="reqn">j=1</code> to <code class="reqn">k</code> (the latter being mostly for testing purposes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cltype</code></td>
<td>
<p>Character string specifying the type of cluster; 
currently implemented 
types are: "PAR_SOCK" for socket cluster with <code>parallel</code> library, the default;
"SNOW_SOCK" for socket cluster with <code>snow</code> library, and
"SNOW_RMPI" for <code>snow</code> MPI cluster with <code>Rmpi</code> library.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbnodes</code></td>
<td>
<p>The number of nodes or virtual cores requested to run the <code>nmc</code>
simulations in parallel. For the snow version, defaults to all; 
for the cluster version, defaults to 4.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.logf</code></td>
<td>
<p>if <code>TRUE</code>, then the computation of the log of the target density
at each of the  <code>nmc</code> chain locations, needed for the NN procedure is also
executed in parallel using <code>parRapply()</code>. 
This may speed up the process if the target is complicated
i.e. takes some time to evaluate. If the target is simple enough
(like <code>target_norm</code>), then communications between nodes are slower than
computations, in which case <code>par.logf = FALSE</code> (the default) should be preferred.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uselogtarget</code></td>
<td>
<p>Set to <code>FALSE</code> by default; 
useful in some cases where <code class="reqn">log(f(\theta))</code> returns <code>-Inf</code> values in 
Kullback computations because   
<code class="reqn">f(\theta)</code> itself returns too small values for some <code class="reqn">\theta</code> far from modal regions.
In these case using a function computing the logarithm of the target can remove the infinity values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logtarget</code></td>
<td>
<p>The function defining <code class="reqn">log(f(theta))</code>, <code>NULL</code> by default, 
required if <code>uselogtarget</code> equals <code>TRUE</code>.
This option and <code>uselogtarget</code> are currently implemented only for the "A.Nearest.Neighbor" method,
and for the default <code>EntVect = FALSE</code> option.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>About parallel computing:</b>
</p>
<p>For the HPC (parallel) version, the computation of the <code>nmc</code> chains next step
are done by the cluster nodes:
<code>EntropyParallel.cl</code> is a generic <em>cluster</em> version implementing 
several types of cluster for running on a single, multicore computer
or on a true cluster using MPI communications. It is under development and may not 
work on all platform/OS. For instance the parallel socket cluster version 
does not work on Windows machines (see the <span class="pkg">parallel</span> package documentation).
Currently tested under LINUX, Mac OSX, and a cluster
using OpenMPI and Sun Grid Engine.
</p>
<p>Note that the parallel computing for this approach is less efficient 
than the two-steps procedure consisting in 
(i) parallel simulation of the iid chains using <code>MCMCcopies.cl</code> to generate the 
“cube” of simulated values,
and then (ii) entropy and Kullback estimation using <code>EntropyMCMC.mc</code>.
This is because  each node computes only one iteration at a time for the <code>nmc</code> chains
here, whereas it computes all the <code class="reqn">n</code> iterations once for the <code>nmc</code> chains
when the entire cube is saved first. This is a trade-off between memory and speed.
</p>
<p>Note also that the <code>Rmpi</code> option is less efficient than the default option
using <span class="pkg">parallel</span> if you are running on a single computer. 
MPI communication are required only for running on a true cluster/grid.
</p>
<p><b>About passing your MCMC algorithm:</b>
</p>
<p>The list <code>mcmc_algo</code> must contain the named elements:
</p>

<ul>
<li> <p><code>name</code>, the name of the MCMC, such as "RWHM"
</p>
</li>
<li> <p><code>chain</code>, the function for simulation of n steps of a single chain
</p>
</li>
<li> <p><code>step</code>, the function for simulation of 1 step of that algorithm
</p>
</li>
<li> <p><code>q_pdf</code>, the density of the proposal
</p>
</li>
<li> <p><code>q_proposal</code>, the function that simulates a proposal
</p>
</li>
</ul>
<p>For examples, see the algorithms currently implemented:
<code>RWHM</code>, the Random Walk Hasting-Metropolis with gaussian proposal;
<code>HMIS_norm</code>, an Independence Sampler HM with gaussian proposal;
<code>IID_norm</code>, a gaussian iid sampler which is merely 
a "fake" MCMC for testing purposes. 
</p>
<p>Currently only non-adaptive Markov chains or adaptive chains for which
the past can be summarized by some sufficient statistics are eligible for this
computation forgetting the past of the <code>nmc</code> chains.
Adaptive chains such as <code>AMHaario</code>, the Adaptive-Metropolis (AM) from Haario (2001) are 
not yet tested for this function.
</p>


<h3>Value</h3>

<p>An object of class <code>"KbMCMC"</code>, containing


</p>
<table>
<tr style="vertical-align: top;">
<td><code>Kullback</code></td>
<td>
<p>A vector of estimated <code class="reqn">K(p^t,f)</code>, 
for <code class="reqn">t=1</code> up to the number of iterations <code>n</code>. This is the 
convergence/comparison criterion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Entp</code></td>
<td>
<p>A vector of estimated <code class="reqn">E_{p^t}[\log(p^t)]</code>, 
for <code class="reqn">t=1</code> up to the number of iterations that have been simulated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>The state space dimension of the MCMC algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algo</code></td>
<td>
<p>The name of the MCMC algorithm that have been used to simulate
the copies of chains, see <code>MCMCcopies</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in this example.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The <code>method</code> input parameter (see above).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm that have been used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob.accept</code></td>
<td>
<p>Estimated rate of acceptation 
(meaningful for accept/reject-type algorithms).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ptheta</code></td>
<td>
<p>The <code>nmc</code> copies of chains in an array(n,d,nmc) 
of simulated values, where 1st value (1,d,nmc) is <code>Ptheta0</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Didier Chauveau, Houssam Alrachid.</p>


<h3>References</h3>


<ul>
<li>
<p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419–431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816–2827.
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>MCMCcopies</code>, <code>MCMCcopies.mc</code> and 
<code>MCMCcopies.cl</code> for just simulating the iid chains, and 
<code>EntropyMCMC</code> or <code>EntropyMCMC.mc</code>
for computing entropy and Kullback estimates from an already simulated
set of iid chains (internally or from external code).
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Toy example using the bivariate gaussian target
## same as for MCMCcopies
n = 150; nmc = 50; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulations and entropy + Kullback using the singlecore version
e1 &lt;- EntropyParallel(RWHM, n, nmc, Ptheta0, target_norm,
                target_norm_param, q_param, verb = FALSE)
par(mfrow=c(1,2))
plot(e1) # default plot.plMCMC method, convergence after about 80 iterations
plot(e1, Kullback = FALSE) # Plot Entropy estimates over time
abline(normEntropy(target_norm_param), 0, col=8, lty=2) # true E_f[log(f)]

# Another example using multicore version, (not available on Windows)
varq=0.05 # variance of the proposal, even smaller
q_param=list(mean=rep(0,d),v=varq*diag(d))
n=300 # requires more iterations to show convergence
e1 &lt;- EntropyParallel.cl(RWHM, n, nmc, Ptheta0, target_norm,
                         target_norm_param, q_param, cltype="PAR_SOCK",
                         verb = FALSE, nbnodes = 2)
plot(e1) # convergence after about 150 iterations
  
</code></pre>


</div>