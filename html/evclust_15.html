<div class="container">

<table style="width: 100%;"><tr>
<td>EkNNclus</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>EkNNclus algorithm</h2>

<h3>Description</h3>

<p><code>EkNNclus</code> computes hard and credal partitions from dissimilarity or attribute
data using the EkNNclus algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">EkNNclus(
  x = NULL,
  D,
  K,
  y0,
  ntrials = 1,
  q = 0.5,
  b = 1,
  disp = TRUE,
  tr = FALSE,
  eps = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>n x p data matrix (n instances, p attributes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>n x n dissimilarity matrix (used only if x is not supplied).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y0</code></td>
<td>
<p>Initial partition (vector of length n, with values in (1,2,...)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntrials</code></td>
<td>
<p>Number of runs of the algorithm (the best solution is kept).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>Parameter in (0,1). Gamma is set to the inverse of the q-quantile of distances
from the K nearest neighbors (same notation as in the paper).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>Exponent of distances, <code class="reqn">\alpha_{ij} = \phi(d_{ij}^b)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>disp</code></td>
<td>
<p>If TRUE, intermediate results are displayed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tr</code></td>
<td>
<p>If TRUE, a trace of the cost function is returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Minimal distance between two vectors (distances smaller than <code>eps</code>
are replaced by <code>eps</code>)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The number of clusters is not specified. It is influenced by parameters K and q.
(It is advised to start with the default values.) For n not too large (say, until one
thousand), y0 can be defined as the vector (1,2,...,n). For larger values of n, it is
advised to start with a random partition of c clusters, c&lt;n.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>). In addition to the
usual attributes, the output credal partition has the following attributes:
</p>

<dl>
<dt>trace</dt>
<dd>
<p>Trace of the algorithm (sequence of values of the cost function).</p>
</dd>
<dt>W</dt>
<dd>
<p>The weight matrix.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux, O. Kanjanatarakul and S. Sriboonchitta.
EK-NNclus: a clustering procedure based on the evidential K-nearest neighbor rule.
Knowledge-Based Systems, Vol. 88, pages 57â€“69, 2015.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Clustering of the fourclass dataset
## Not run: 
data(fourclass)
n&lt;-nrow(fourclass)
N=2
clus&lt;- EkNNclus(fourclass[,1:2],K=60,y0=(1:n),ntrials=N,q=0.9,b=2,disp=TRUE,tr=TRUE)
## Plot of the partition
plot(clus,X=fourclass[,1:2],ytrue=fourclass$y,Outliers=FALSE,plot_approx=FALSE)
## Plot of the cost function vs number of iteration
L&lt;-vector(length=N)
for(i in 1:N) L[i]&lt;-dim(clus$trace[clus$trace[,1]==i,])[1]
imax&lt;-which.max(L)
plot(0:(L[imax]-1),-clus$trace[clus$trace[,1]==imax,3],type="l",lty=imax,
xlab="time steps",ylab="energy")
for(i in (1:N)) if(i != imax) lines(0:(L[i]-1),-clus$trace[clus$trace[,1]==i,3],
type="l",lty=i)

## End(Not run)
</code></pre>


</div>