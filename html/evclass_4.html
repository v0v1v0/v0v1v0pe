<div class="container">

<table style="width: 100%;"><tr>
<td>EkNNfit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Training of the EkNN classifier</h2>

<h3>Description</h3>

<p><code>EkNNfit</code> optimizes the parameters of the EkNN classifier.
</p>


<h3>Usage</h3>

<pre><code class="language-R">EkNNfit(
  x,
  y,
  K,
  param = NULL,
  alpha = 0.95,
  lambda = 1/max(as.numeric(y)),
  optimize = TRUE,
  options = list(maxiter = 300, eta = 0.1, gain_min = 1e-06, disp = TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Input matrix of size n x d, where n is the number of objects and d the number of
attributes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector of class labels (of length n). May be a factor, or a vector of
integers from 1 to M (number of classes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param</code></td>
<td>
<p>Initial parameters (default: NULL).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Parameter <code class="reqn">\alpha</code> (default: 0.95)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Parameter of the cost function. If <code>lambda=1</code>, the
cost function measures the error between the plausibilities and the 0-1 target values.
If <code>lambda=1/M</code>, where M is the number of classes (default), the piginistic probabilities
are considered in the cost function. If <code>lambda=0</code>, the beliefs are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimize</code></td>
<td>
<p>Boolean. If TRUE (default), the parameters are optimized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>A list of parameters for the optimization algorithm: maxiter
(maximum number of iterations), eta (initial step of gradient variation),
gain_min (minimum gain in the optimisation loop), disp (Boolean; if TRUE, intermediate
results are displayed during the optimization).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If the argument <code>param</code> is not supplied, the function <code>EkNNinit</code> is called.
</p>


<h3>Value</h3>

<p>A list with five elements:
</p>

<dl>
<dt>param</dt>
<dd>
<p>The optimized parameters.</p>
</dd>
<dt>cost</dt>
<dd>
<p>Final value of the cost function.</p>
</dd>
<dt>err</dt>
<dd>
<p>Leave-one-out error rate.</p>
</dd>
<dt>ypred</dt>
<dd>
<p>Leave-one-out predicted class labels (coded as integers from 1 to M).</p>
</dd>
<dt>m</dt>
<dd>
<p>Leave-one-out predicted mass functions. The first M columns correspond
to the mass assigned to each class. The last column corresponds to the mass
assigned to the whole set of classes.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux. A k-nearest neighbor classification rule based on Dempster-Shafer
theory. IEEE Transactions on Systems, Man and Cybernetics, 25(05):804–813, 1995.
</p>
<p>L. M. Zouhal and T. Denoeux. An evidence-theoretic k-NN rule with parameter
optimization. IEEE Transactions on Systems, Man and Cybernetics Part C,
28(2):263–271,1998.
</p>


<h3>See Also</h3>

<p><code>EkNNinit</code>, <code>EkNNval</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Iris dataset
data(iris)
x&lt;-iris[,1:4]
y&lt;-iris[,5]
fit&lt;-EkNNfit(x,y,K=5)
</code></pre>


</div>