<div class="container">

<table style="width: 100%;"><tr>
<td>combine_log</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Combine and filter (.p) log files from Mr.Bayes
</h2>

<h3>Description</h3>

<p>Imports parameter (.p) log files from Mr. Bayes and combines them into a single data frame. Samples can be dropped from the start of each log file (i.e., discarded as burn-in) and/or downsampled to reduce the size of the output object.
</p>


<h3>Usage</h3>

<pre><code class="language-R">combine_log(path = ".", burnin = 0.25, downsample = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>

<p>The path to a folder containing (.p) log files or a character vector of log files to be read.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burnin</code></td>
<td>

<p>Either the number or a proportion of generations to drop from the beginning of each log file.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>downsample</code></td>
<td>

<p>Either the number or the proportion of generations the user wants to keep after downsampling for the final (combined) log file. Generations will be dropped in approximately equally-spaced intervals.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>combine_log()</code> imports log files produced by Mr.Bayes, ignoring the first row of the file (which contains an ID number). The files are appended together, optionally after removing burn-in generations from the beginning and/or by further filtering throughout the rest of each file. When <code>burnin</code> is greater than 0, the number or propotion of generations corresponding to the supplied value will be dropped from the beginning of each file as it is read in. For example, setting <code>burnin = .25</code> (the default) will drop the first 25% of generations from each file. When <code>downsample</code> is greater than 0, the file will be downsampled until the number or proportion of generations corresponding to the supplied value is reached. For example, if <code>downsample = 10000</code> generations (the default) for log files from 4 independent runs (i.e., 4 (.p) files), each log file will be downsampled to 2500 generations, and the final combined data frame will contain 10000 samples, selected in approximately equally spaced intervals from the original data.
</p>
<p>The output can be supplied to <code>get_pwt_rates_MrBayes</code> and to <code>FBD_reshape</code>. The latter will convert the log data frame from my wide to long format, which is necessary to be used as input for downstream analyses using <code>FBD_summary</code>, <code>FBD_dens_plot</code>, <code>FBD_normality_plot</code>, <code>FBD_tests1</code>, or <code>FBD_tests2</code>.
</p>


<h3>Value</h3>

<p>A data frame with columns corresponding to the columns in the supplied log files and rows containing the sampled parameter values. Examples of the kind of output produced can be accessed using <code>data("posterior1p")</code> and <code>data("posterior3p")</code>.
</p>


<h3>See Also</h3>

<p><code>vignette("fbd-params")</code> for the use of this function as part of an analysis pipeline.
</p>
<p><code>FBD_reshape</code>, which reshapes a combined parameter log file for use in some other package functions.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># See vignette("fbd-params") for how to use this
# function as part of an analysis pipeline
## Not run: 
posterior &lt;- combine_log("path/to/folder", burnin = .25,
                         downsample = 10000)

## End(Not run)
</code></pre>


</div>