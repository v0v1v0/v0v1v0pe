<div class="container">

<table style="width: 100%;"><tr>
<td>fclustIndex</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fuzzy Cluster Indexes (Validity/Performance Measures)</h2>

<h3>Description</h3>

<p>Calculates the values of several fuzzy validity measures. The values
of the indexes can be independently used in order to evaluate and compare
clustering partitions or even to determine the number of clusters
existing in a data set.</p>


<h3>Usage</h3>

<pre><code class="language-R">fclustIndex(y, x, index = "all")</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>An object of a fuzzy clustering result of class <code>"fclust"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Data matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>The validity measures used: <code>"gath.geva"</code>, <code>"xie.beni"</code>,
<code>"fukuyama.sugeno"</code>, <code>"partition.coefficient"</code>,
<code>"partition.entropy"</code>, <code>"proportion.exponent"</code>,
<code>"separation.index"</code> and <code>"all"</code> for all the indexes.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The validity measures and a short description of them follows, where
<code class="reqn">N</code> is the number of data points, <code class="reqn">u_{ij}</code> the values of the
membership matrix, <code class="reqn">v_j</code> the centers of the clusters and <code class="reqn">k</code>
te number of clusters.
</p>

<dl>
<dt>
<b>gath.geva</b>:</dt>
<dd>
<p>Gath and Geva introduced 2 main criteria for comparing and finding
optimal partitions based on the heuristics that a better clustering
assumes clear separation between the clusters, minimal volume of the
clusters and maximal number of data points concentrated in the
vicinity of the cluster centroids. These indexes are only for the
cmeans clustering algorithm valid.
For the first, the “fuzzy hypervolume” we have:
<code class="reqn">F_{HV}=\sum_{j=1}^{c}{[\det(F_j)]}^{1/2}</code>, where
<code class="reqn">F_j=\frac{\sum_{i=1}^N
	  u_{ij}(x_i-v_j)(x_i-v_j)^T}{\sum_{i=1}^{N}u_{ij}}</code>, for the
case when the defuzzification parameter is 2.
For the second, the “average partition density”:
<code class="reqn">D_{PA}=\frac{1}{k}\sum_{j=1}^k\frac{S_j}{{[\det(F_j)]}^{1/2}}</code>,
where <code class="reqn">S_j=\sum_{i=1}^N u_{ij}</code>.
Moreover, the “partition density” which expresses the general
partition density according to the physical definition of density
is calculated by:
<code class="reqn">P_D=\frac{S}{F_{HV}}</code>, where <code class="reqn">S=\sum_{j=1}^k\sum_{i=1}^N
	u_{ij}</code>.
</p>
</dd>
<dt>
<b>xie.beni</b>:</dt>
<dd>
<p>This index is a function of the data set and the centroids of the
clusters. Xie and Beni explained this index by writing it as a ratio
of the total variation of the partition and the centroids $(U,V)$
and the separation of the centroids vectors. The minimum values of
this index under comparison support the best partitions.
<code class="reqn">u_{XB}(U,V;X)=\frac{\sum_{j=1}^k\sum_{i=1}^Nu_{ij}^2{||x_i-v_j||}^2}{N(\min_{j\neq l}\{{||v_j-v_l||}^2\})}</code>
</p>
</dd>
<dt>
<b>fukuyama.sugeno</b>:</dt>
<dd>
<p>This index consists of the difference of two terms, the first
combining the fuzziness in the membership matrix with the
geometrical compactness of the representation of the data set via
the prototypes, and the second the fuzziness in its row of the
partition matrix with the distance from the $i$th prototype to the
grand mean of the data. The minimum values of this index also
propose a good partition.
<code class="reqn">u_{FS}(U,V;X)=\sum_{i=1}^{N}\sum_{j=1}^k
	(u_{ij}^2)^q(||x_i-v_j||^2-||v_j-\bar v||^2)</code>
</p>
</dd>
<dt>
<b>partition.coefficient</b>:</dt>
<dd>
<p>An index which measures the fuzziness of the partition but without
considering the data set itself. It is a heuristic measure since it
has no connection to any property of the data. The maximum values of
it imply a good partition in the meaning of a least fuzzy
clustering.
<code class="reqn">F(U;k)=\frac{tr (UU^T)}{N}=\frac{&lt;U,U&gt;}{N}=\frac{||U||^2}{N}</code>
</p>

<ul>
<li> <p><code class="reqn">F(U;k)</code> shows the fuzziness or the overlap of the partition
and depends on <code class="reqn">kN</code> elements. 
</p>
</li>
<li> <p><code class="reqn">1/k\leq F(U;k)\leq 1</code>, where if <code class="reqn">F(U;k)=1</code> then <code class="reqn">U</code> is a hard
partition and if <code class="reqn">F(U;k)=1/k</code> then <code class="reqn">U=[1/k]</code> is the centroid of
the fuzzy partion space <code class="reqn">P_{fk}</code>. The converse is also valid.
</p>
</li>
</ul>
</dd>
<dt>
<b>partition.entropy</b>:</dt>
<dd>
<p>It is a measure that provides information about the membership
matrix without also considering the data itself. The minimum values
imply a good partition in the meaning of a more crisp partition.
<code class="reqn">H(U;k)=\sum_{i=1}^{N} h(u_i)/N</code>, where
<code class="reqn">h(u)=-\sum_{j=1}^{k} u_j\,\log _a (u_j)</code> the Shannon's entropy.
</p>

<ul>
<li> <p><code class="reqn">H(U;k)</code> shows the uncertainty of a fuzzy partition and
depends also on <code class="reqn">kN</code> elements. Specifically, <code class="reqn">h(u_i)</code> is
interpreted as the amount of fuzzy information about the
membership of <code class="reqn">x_i</code> in <code class="reqn">k</code> classes that is retained by column
<code class="reqn">u_j</code>. Thus, at <code class="reqn">U=[1/k]</code> the most information is withheld since
the membership is the fuzziest possible.
</p>
</li>
<li> <p><code class="reqn">0\leq H(U;k)\leq \log_a(k)</code>, where for <code class="reqn">H(U;k)=0</code> <code class="reqn">U</code> is a
hard partition and for <code class="reqn">H(U;k)=\log_a(k)</code> <code class="reqn">U=[1/k]</code>.
</p>
</li>
</ul>
</dd>
<dt>
<b>proportion.exponent</b>:</dt>
<dd>
<p>It is a measure <code class="reqn">P(U;k)</code> of fuzziness adept to detect structural variations
in the partition matrix as it becomes more fuzzier. A crisp cluster
in the partition matrix can drive it to infinity when the partition
coefficient and the partition entropy are more sensitive to small
changes when approaching a hard partition. Its evaluation does not also
involve the data or the algorithm used to partition them and
its maximum implies the optimal partition but without knowing what
maximum is a statistically significant maximum.
</p>

<ul>
<li> <p><code class="reqn">0\leq P(U;k)&lt;\infty</code>, since the <code class="reqn">[0,1]</code> values explode to
<code class="reqn">[0,\infty)</code> due to the natural logarithm. Specifically, <code class="reqn">P=0</code>
when and only when <code class="reqn">U=[1/k]</code>, while <code class="reqn">P\rightarrow\infty</code> when
any column of <code class="reqn">U</code> is crisp. 
</p>
</li>
<li> <p><code class="reqn">P(U;k)</code> can easily explode and it is good for partitions
with large column maximums and at detecting structural
variations.
</p>
</li>
</ul>
</dd>
<dt>
<b>separation.index (known as CS Index)</b>:</dt>
<dd>
<p>This index identifies unique cluster structure with well-defined
properties that depend on the data and a measure of distance. It
answers the question if the clusters are compact and separated, but
it rather seems computationally infeasible for big data sets since a
distance matrix between all the data membership values has to be
calculated. It also presupposes that a hard partition is derived
from the fuzzy one.<br><code class="reqn">D_1(U;k;X,d)=\min_{i+1\,\leq\,l\,\leq\,k-1}\left\{\min_{1\,\leq\,j\,\leq\,k}\left\{\frac{dis(u_j,u_l)}{\max_{1\leq m\leq k}\{dia(u_m)\}}\right\}\right\}</code>, where <code class="reqn">dia</code>  is the diameter of the subset, <code class="reqn">dis</code> the distance of
two subsets, and <code class="reqn">d</code> a metric.
<code class="reqn">U</code> is a CS partition of <code class="reqn">X</code> <code class="reqn">\Leftrightarrow D_1&gt;1</code>. When this
holds then <code class="reqn">U</code> is unique.
</p>
</dd>
</dl>
<h3>Value</h3>

<p>Returns a vector with the validity measures values.
</p>


<h3>Author(s)</h3>

<p>Evgenia Dimitriadou</p>


<h3>References</h3>

<p>James C. Bezdek, <em>Pattern Recognition with Fuzzy Objective
Function Algorithms</em>, Plenum Press, 1981, NY.<br>
L. X. Xie and G. Beni, <em>Validity measure for fuzzy
clustering</em>, IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. <b>3</b>, n. 8, p. 841-847, 1991.<br>
I. Gath and A. B. Geva, <em>Unsupervised Optimal Fuzzy
Clustering</em>, IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. <b>11</b>, n. 7, p. 773-781, 1989.<br>
Y. Fukuyama and M. Sugeno, <em>A new method of choosing the
number of clusters for the fuzzy $c$-means method</em>, Proc. 5th Fuzzy
Syst. Symp., p. 247-250, 1989 (in japanese).</p>


<h3>See Also</h3>

<p><code>cmeans</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># a 2-dimensional example
x&lt;-rbind(matrix(rnorm(100,sd=0.3),ncol=2),
         matrix(rnorm(100,mean=1,sd=0.3),ncol=2))
cl&lt;-cmeans(x,2,20,verbose=TRUE,method="cmeans")
resultindexes &lt;- fclustIndex(cl,x, index="all")
resultindexes   
</code></pre>


</div>