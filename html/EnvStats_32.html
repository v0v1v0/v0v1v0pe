<div class="container">

<table style="width: 100%;"><tr>
<td>CastilloAndHadi1994</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Abstract:  Castillo and Hadi (1994)
</h2>

<h3>Description</h3>

<p>Detailed abstract of the manuscript: <br><br></p>
<p>Castillo, E., and A. Hadi. (1994).  Parameter and Quantile Estimation for the 
Generalized Extreme-Value Distribution.  <em>Environmetrics</em> <b>5</b>, 417–432.
</p>


<h3>Details</h3>

<p><b>Abstract</b> <br>
Castillo and Hadi (1994) introduce a new way to estimate the parameters and 
quantiles of the generalized extreme value distribution (GEVD) 
with parameters <code>location=</code><code class="reqn">\eta</code>, <code>scale=</code><code class="reqn">\theta</code>, and 
<code>shape=</code><code class="reqn">\kappa</code>.  The estimator is based on a two-stage procedure using 
order statistics,  denoted here by “TSOE”, which stands for 
two-stage order-statistics estimator.  Castillo and Hadi (1994) compare the TSOE 
to the maximum likelihood estimator (MLE; Jenkinson, 1969; Prescott and Walden, 1983) 
and probability-weighted moments estimator (PWME; 
Hosking et al., 1985).
</p>
<p>Castillo and Hadi (1994) note that for some samples the likelihood may not have 
a local maximum, and also when <code class="reqn">\kappa &gt; 1</code> the likelihood can be made 
infinite so the MLE does not exist.  They also note, as do 
Hosking et al., 1985), that when <code class="reqn">\kappa \le -1</code>, 
the moments and probability-weighed moments of the GEVD do not exist, hence 
neither does the PWME.  (Hosking et al., however, claim that in practice the 
shape parameter usually lies between -1/2 and 1/2.)  On the other hand, the 
TSOE exists for all values of <code class="reqn">\kappa</code>.
</p>
<p>Based on computer simulations, Castillo and Hadi (1994) found that the 
performance (bias and root mean squared error) of the TSOE is comparable to the 
PWME for values of <code class="reqn">\kappa</code> in the range <code class="reqn">-1/2 \le \kappa \le 1/2</code>.  
They also found that the TSOE is superior to the PWME for large values of 
<code class="reqn">\kappa</code>.  Their results, however, are based on using the PWME computed 
using the approximation given in equation (14) of Hosking et al. (1985, p.253).  
The true PWME is computed using equation (12) of Hosking et al. (1985, p.253).  
Hosking et al. (1985) introduced the approximation as a matter of computational 
convenience, and noted that it is valid in the range <code class="reqn">-1/2 \le \kappa \le 1/2</code>.  
If Castillo and Hadi (1994) had used the true PWME for values of <code class="reqn">\kappa</code> 
larger than 1/2, they probably would have gotten very different results for the 
PWME.  (Note: the function <code>egevd</code> with <code>method="pwme"</code> uses 
the exact equation (12) of Hosking et al. (1985), not the approximation (14)).
</p>
<p>Castillo and Hadi (1994) suggest using the bootstrap or jackknife to obtain 
variance estimates and confidence intervals for the distribution parameters 
based on the TSOE.
<br></p>
<p><b>More Details</b>
Let <code class="reqn">\underline{x} = (x_1, x_2, \ldots, x_n)</code> be a vector of 
<code class="reqn">n</code> observations from a generalized extreme value distribution with 
parameters <code>location=</code><code class="reqn">\eta</code>, <code>scale=</code><code class="reqn">\theta</code>, and 
<code>shape=</code><code class="reqn">\kappa</code> with cumulative distribution function <code class="reqn">F</code>.  
Also, let <code class="reqn">x(1), x(2), \ldots, x(n)</code> denote the ordered values of 
<code class="reqn">\underline{x}</code>.
</p>
<p><em>First Stage</em> <br>
Castillo and Hadi (1994) propose as initial estimates of the distribution 
parameters the solutions to the following set of simultaneous equations based 
on just three observations from the total sample of size <code class="reqn">n</code>:
</p>
<p style="text-align: center;"><code class="reqn">F[x(1); \eta, \theta, \kappa] = p_{1,n}</code>
</p>

<p style="text-align: center;"><code class="reqn">F[x(j); \eta, \theta, \kappa] = p_{j,n}</code>
</p>

<p style="text-align: center;"><code class="reqn">F[x(n); \eta, \theta, \kappa] = p_{n,n} \;\;\;\; (1)</code>
</p>

<p>where <code class="reqn">2 \le j \le n-1</code>, and 
</p>
<p style="text-align: center;"><code class="reqn">p_{i,n} = \hat{F}[x(i); \eta, \theta, \kappa]</code>
</p>

<p>denotes the <code class="reqn">i</code>'th plotting position for a sample of size <code class="reqn">n</code>; that is, a 
nonparametric estimate of the value of <code class="reqn">F</code> at <code class="reqn">x(i)</code>.  Typically, 
plotting positions have the form:
</p>
<p style="text-align: center;"><code class="reqn">p_{i,n} = \frac{i-a}{n+b} \;\;\;\; (2)</code>
</p>

<p>where <code class="reqn">b &gt; -a &gt; -1</code>.  In their simulation studies, Castillo and Hadi (1994) 
used a=0.35, b=0.
</p>
<p>Since <code class="reqn">j</code> is arbitrary in the above set of equations (1), denote the solutions 
to these equations by: 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\eta}_j, \hat{\theta}_j, \hat{\kappa}_j</code>
</p>

<p>There are thus <code class="reqn">n-2</code> sets of estimates.
</p>
<p>Castillo and Hadi (1994) show that the estimate of the shape parameter, <code class="reqn">\kappa</code>, 
is the solution to the equation:
</p>
<p style="text-align: center;"><code class="reqn">\frac{x(j) - x(n)}{x(1) - x(n)} = \frac{1 - A_{jn}^\kappa}{1 - A_{1n}^\kappa} \;\;\;\; (3)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">A_{ik} = C_i / C_k \;\;\;\; (4)</code>
</p>

<p style="text-align: center;"><code class="reqn">C_i = -log(p_{i,n}) \;\;\;\; (5)</code>
</p>

<p>Castillo and Hadi (1994) show how to easily solve equation (3) using the method of 
bisection.
</p>
<p>Once the estimate of the shape parameter is obtained, the other estimates are given 
by:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\theta}_j = \frac{\hat{\kappa}_j [x(1) - x(n)]}{(C_n)^{\hat{\kappa}_j} - (C_1)^{\hat{\kappa}_j}} \;\;\;\; (6)</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\eta}_j = x(1) - \frac{\hat{\theta}_j [1 - (C_1)^{\hat{\kappa}_j}]}{\hat{\kappa}_j} \;\;\;\; (7)</code>
</p>

<p><br></p>
<p><em>Second Stage</em> <br>
Apply a robust function to the <code class="reqn">n-2</code> sets of estimates obtained in the 
first stage.  Castillo and Hadi (1994) suggest using either the median or the 
least median of squares (using a column of 1's as the predictor variable; 
see the help file for lmsreg in the package <span class="pkg">MASS</span>).  Using 
the median, for example, the final distribution parameter estimates are 
given by: 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\eta} = Median(\hat{\eta}_2, \hat{\eta}_3, \ldots, \hat{\eta}_{n-1})</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\theta} = Median(\hat{\theta}_2, \hat{\theta}_3, \ldots, \hat{\theta}_{n-1})</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\kappa} = Median(\hat{\kappa}_2, \hat{\kappa}_3, \ldots, \hat{\kappa}_{n-1})</code>
</p>



<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Forbes, C., M. Evans, N. Hastings, and B. Peacock. (2011).  Statistical Distributions. 
Fourth Edition. John Wiley and Sons, Hoboken, NJ.
</p>
<p>Hosking, J.R.M. (1985).  Algorithm AS 215: Maximum-Likelihood Estimation of the 
Parameters of the Generalized Extreme-Value Distribution.  
<em>Applied Statistics</em> <b>34</b>(3), 301–310.
</p>
<p>Jenkinson, A.F. (1969).  Statistics of Extremes. <em>Technical Note 98</em>, 
World Meteorological Office, Geneva.
</p>
<p>Johnson, N. L., S. Kotz, and N. Balakrishnan. (1995). 
<em>Continuous Univariate Distributions, Volume 2</em>. 
Second Edition. John Wiley and Sons, New York.
</p>
<p>Prescott, P., and A.T. Walden. (1983).  Maximum Likelihood Estimation of the 
Three-Parameter Generalized Extreme-Value Distribution from Censored Samples.  
<em>Journal of Statistical Computing and Simulation</em> <b>16</b>, 241–250.
</p>


<h3>See Also</h3>

<p>Generalized Extreme Value Distribution, <code>egevd</code>, 
Hosking et al., 1985).
</p>


</div>