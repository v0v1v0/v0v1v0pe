<div class="container">

<table style="width: 100%;"><tr>
<td>phi</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
<code class="reqn">\phi</code> and Other Contingency Tables Correlations</h2>

<h3>Description</h3>

<p>Compute phi (<code class="reqn">\phi</code>), Cramer's <em>V</em>, Tschuprow's <em>T</em>, Cohen's <em>w</em>,
פ (Fei), Pearson's contingency coefficient for
contingency tables or goodness-of-fit. Pair with any reported
<code>stats::chisq.test()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">phi(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = "greater", ...)

cramers_v(x, y = NULL, adjust = TRUE, ci = 0.95, alternative = "greater", ...)

tschuprows_t(
  x,
  y = NULL,
  adjust = TRUE,
  ci = 0.95,
  alternative = "greater",
  ...
)

cohens_w(
  x,
  y = NULL,
  p = rep(1, length(x)),
  ci = 0.95,
  alternative = "greater",
  ...
)

fei(x, p = rep(1, length(x)), ci = 0.95, alternative = "greater", ...)

pearsons_c(
  x,
  y = NULL,
  p = rep(1, length(x)),
  ci = 0.95,
  alternative = "greater",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a numeric vector or matrix. <code>x</code> and <code>y</code> can also
both be factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector; ignored if <code>x</code> is a matrix.  If
<code>x</code> is a factor, <code>y</code> should be a factor of the same length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjust</code></td>
<td>
<p>Should the effect size be corrected for small-sample bias?
Defaults to <code>TRUE</code>; Advisable for small samples and large tables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
effectsize_CIs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>a vector of probabilities of the same length as <code>x</code>.
An error is given if any entry of <code>p</code> is negative.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>phi (<code class="reqn">\phi</code>), Cramer's <em>V</em>, Tschuprow's <em>T</em>, Cohen's <em>w</em>, and Pearson's
<em>C</em> are effect sizes for tests of independence in 2D contingency tables. For
2-by-2 tables, phi, Cramer's <em>V</em>, Tschuprow's <em>T</em>, and Cohen's <em>w</em> are
identical, and are equal to the simple correlation between two dichotomous
variables, ranging between  0 (no dependence) and 1 (perfect dependence).
<br><br>
For larger tables, Cramer's <em>V</em>, Tschuprow's <em>T</em> or Pearson's <em>C</em> should be
used, as they are bounded between 0-1. (Cohen's <em>w</em> can also be used, but
since it is not bounded at 1 (can be larger) its interpretation is more
difficult.) For square table, Cramer's <em>V</em> and Tschuprow's <em>T</em> give the same
results, but for non-square tables Tschuprow's <em>T</em> is more conservative:
while <em>V</em> will be 1 if either columns are fully dependent on rows (for each
column, there is only one non-0 cell) <em>or</em> rows are fully dependent on
columns, <em>T</em> will only be 1 if both are true.
<br><br>
For goodness-of-fit in 1D tables Cohen's <em>W</em>, פ (Fei)
or Pearson's <em>C</em> can be used. Cohen's <em>w</em> has no upper bound (can be
arbitrarily large, depending on the expected distribution). <em>Fei</em> is an
adjusted Cohen's <em>w</em>, accounting for the expected distribution, making it
bounded between 0-1 (Ben-Shachar et al, 2023). Pearson's <em>C</em> is also bounded
between 0-1.
<br><br>
To summarize, for correlation-like effect sizes, we recommend:
</p>

<ul>
<li>
<p> For a 2x2 table, use <code>phi()</code>
</p>
</li>
<li>
<p> For larger tables, use <code>cramers_v()</code>
</p>
</li>
<li>
<p> For goodness-of-fit, use <code>fei()</code>
</p>
</li>
</ul>
<h3>Value</h3>

<p>A data frame with the effect size (<code>Cramers_v</code>, <code>phi</code> (possibly with
the suffix <code style="white-space: pre;">⁠_adjusted⁠</code>), <code>Cohens_w</code>, <code>Fei</code>) and its CIs (<code>CI_low</code> and
<code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the "pivot
method"). This method finds the noncentrality parameter ("<em>ncp</em>") of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br><br>
For additional details on estimation and troubleshooting, see effectsize_CIs.
</p>


<h3>CIs and Significance Tests</h3>

<p>"Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more." (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br><br>
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are "close enough"
to 0 to be negligible are needed ("equivalence testing"; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code>
</h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li>
<p> Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd Ed.). New York: Routledge.
</p>
</li>
<li>
<p> Ben-Shachar, M.S., Patil, I., Thériault, R., Wiernik, B.M., Lüdecke, D.
(2023). Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the
Chi‑Squared Statistic. Mathematics, 11, 1982. <a href="https://doi.org/10.3390/math11091982">doi:10.3390/math11091982</a>
</p>
</li>
<li>
<p> Johnston, J. E., Berry, K. J., &amp; Mielke Jr, P. W. (2006). Measures of
effect size for chi-squared and likelihood-ratio goodness-of-fit tests.
Perceptual and motor skills, 103(2), 412-414.
</p>
</li>
<li>
<p> Rosenberg, M. S. (2010). A generalized formula for converting chi-square
tests to effect sizes for meta-analysis. PloS one, 5(4), e10059.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>chisq_to_phi()</code> for details regarding estimation and CIs.
</p>
<p>Other effect sizes for contingency table: 
<code>cohens_g()</code>,
<code>oddsratio()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## 2-by-2 tables
## -------------
data("RCT_table")
RCT_table # note groups are COLUMNS

phi(RCT_table)
pearsons_c(RCT_table)



## Larger tables
## -------------
data("Music_preferences")
Music_preferences

cramers_v(Music_preferences)

cohens_w(Music_preferences)

pearsons_c(Music_preferences)



## Goodness of fit
## ---------------
data("Smoking_FASD")
Smoking_FASD

fei(Smoking_FASD)

cohens_w(Smoking_FASD)

pearsons_c(Smoking_FASD)

# Use custom expected values:
fei(Smoking_FASD, p = c(0.015, 0.010, 0.975))

cohens_w(Smoking_FASD, p = c(0.015, 0.010, 0.975))

pearsons_c(Smoking_FASD, p = c(0.015, 0.010, 0.975))

</code></pre>


</div>