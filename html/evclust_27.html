<div class="container">

<table style="width: 100%;"><tr>
<td>nnevclus_mb</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>NN-EVCLUS algorithm (minibatch version)</h2>

<h3>Description</h3>

<p><code>nnevclus_mb</code> computes a credal partition from a dissimilarity matrix using the 
NN-EVCLUS algorithm. Training is done using mini-batch gradient descent with the RMSprop
optimization algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">nnevclus_mb(
  x,
  foncD = function(x) as.matrix(dist(x)),
  c,
  type = "simple",
  n_H,
  nbatch = 10,
  alpha0 = 0.9,
  fhat = NULL,
  lambda = 0,
  y = NULL,
  Is = NULL,
  nu = 0,
  disp = TRUE,
  options = list(Niter = 1000, epsi = 0.001, rho = 0.9, delta = 1e-08, Dtmax = 100, print
    = 5),
  param0 = list(V0 = NULL, W0 = NULL, beta0 = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>nxp matrix of p attributes observed for n objects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foncD</code></td>
<td>
<p>A function to compute distances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c</code></td>
<td>
<p>Number of clusters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of focal sets ("simple": empty set, singletons and Omega;
"full": all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; "pairs": <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_H</code></td>
<td>
<p>Size or the hidden layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbatch</code></td>
<td>
<p>Number of mini-batches.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha0</code></td>
<td>
<p>Order of the quantile to normalize distances. Parameter d0 is set to 
the alpha0-quantile of distances. Default: 0.9.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fhat</code></td>
<td>
<p>Vector of outputs from a one-class SVM for novelty detection (optional)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Regularization coefficient (default: 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Optional vector of class labels for a subset of the training set 
(for semi-supervised learning).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Is</code></td>
<td>
<p>Vector of indices corresponding to y (for semi-supervised learning).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>Coefficient of the supervised error term (default: 0).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>disp</code></td>
<td>
<p>If TRUE, intermediate results are displayed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>Parameters of the optimization algorithm (Niter: maximum number of
iterations; epsi, rho, delta: parameters of RMSprop; Dtmax: the algorithm stops when
the loss has not decreased in the last Dtmax iterations; print: number of iterations 
between two displays).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param0</code></td>
<td>
<p>Optional list of initial network parameters (see details).
</p>
<p>#'</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is a neural network version of <code>kevclus</code>. The neural net has one layer
of ReLU units and a softmax output layer (see Denoeux, 2020). The network is trained
in mini-batch mode using the RMSprop algorithm. The inputs are a feature vector x, 
an optional distance matrix D, and an optional vector of one-class SVM outputs fhat, 
which is used for novelty detection. Part of the output belief mass is transfered to 
the empty set based on beta[1]+beta[2]*fhat, where beta is an additional parameter 
vector. The network can be trained in fully unsupervised mode or in semi-supervised mode
(with class labels for a subset of the learning instances). The output is a credal 
partition (a "credpart" object), with a specific field containing the network parameters (U, V, W,
beta).
</p>


<h3>Value</h3>

<p>The output credal partition (an object of class <code>"credpart"</code>). In 
addition to the usual attributes, the output credal partition has the following 
attributes:
</p>

<dl>
<dt>Kmat</dt>
<dd>
<p>The matrix of degrees of conflict. Same size as D.</p>
</dd>
<dt>trace</dt>
<dd>
<p>Trace of the algorithm (values of the loss function).</p>
</dd>
<dt>param</dt>
<dd>
<p>The network parameters as a list with components V, W and beta.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux. NN-EVCLUS: Neural Network-based Evidential Clustering. 
Information Sciences, Vol. 572, Pages 297-330, 2021.
</p>


<h3>See Also</h3>

<p><code>nnevclus</code>, <code>predict.credpart</code>, 
<code>kevclus</code>, <code>kcevclus</code>, <code>harris</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## Unsupervised learning
data(fourclass)
x&lt;-scale(fourclass[,1:2])
y&lt;-fourclass[,3]
svmfit&lt;-ksvm(~.,data=x,type="one-svc",kernel="rbfdot",nu=0.2,kpar=list(sigma=0.2))
fhat&lt;-predict(svmfit,newdata=x,type="decision")
clus&lt;-nnevclus_mb(x,foncD=function(x) as.matrix(dist(x)),c=4,type='pairs',
n_H=10,nbatch=10,alpha0=0.9,fhat=fhat)
plot(clus,x)
## semi-supervised learning
Is&lt;-sample(400,100)
clus&lt;-nnevclus_mb(x,foncD=function(x) as.matrix(dist(x)),c=4,type='pairs',
n_H=10,nbatch=10,alpha0=0.9,fhat=fhat,lambda=0, y=y[Is],Is=Is,nu=0.5)
plot(clus,x)

## End(Not run)

</code></pre>


</div>