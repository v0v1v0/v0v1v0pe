<div class="container">

<table style="width: 100%;"><tr>
<td>elm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit an extreme learning model</h2>

<h3>Description</h3>

<p>Formula interface for <code>elm_train</code>, transforms a data frame and formula
into the necessary input for elm_train, automatically calls <code>onehot_encode</code>
for classification.
</p>


<h3>Usage</h3>

<pre><code class="language-R">elm(
  formula,
  data,
  nhid,
  actfun,
  init_weights = "normal_gaussian",
  bias = FALSE,
  moorep_pseudoinv_tol = 0.01,
  leaky_relu_alpha = 0,
  seed = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>formula used to specify the regression or classification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data.frame with the data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nhid</code></td>
<td>
<p>a numeric value specifying the hidden neurons. Must be &gt;= 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>actfun</code></td>
<td>
<p>a character string specifying the type of activation function. It should be one of the following : 'sig' <em>( sigmoid )</em>, 'sin' <em>( sine )</em>, 'radbas' <em>( radial basis )</em>, 'hardlim' <em>( hard-limit )</em>, 'hardlims' <em>( symmetric hard-limit )</em>, 'satlins' <em>( satlins )</em>, 'tansig' <em>( tan-sigmoid )</em>, 'tribas' <em>( triangular basis )</em>, 'relu' <em>( rectifier linear unit )</em> or 'purelin' <em>( linear )</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init_weights</code></td>
<td>
<p>a character string spcecifying the distribution from which the <em>input-weights</em> and the <em>bias</em> should be initialized. It should be one of the following : 'normal_gaussian' <em>(normal / Gaussian distribution with zero mean and unit variance)</em>, 'uniform_positive' <em>( in the range [0,1] )</em> or 'uniform_negative' <em>( in the range [-1,1] )</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias</code></td>
<td>
<p>either TRUE or FALSE. If TRUE then <em>bias</em> weights will be added to the hidden layer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>moorep_pseudoinv_tol</code></td>
<td>
<p>a numeric value. See the references web-link for more details on <em>Moore-Penrose pseudo-inverse</em> and specifically on the <em>pseudo inverse tolerance value</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>leaky_relu_alpha</code></td>
<td>
<p>a numeric value between 0.0 and 1.0. If 0.0 then a simple <em>relu</em> ( f(x) = 0.0 for x &lt; 0, f(x) = x for x &gt;= 0 ) activation function will be used, otherwise a <em>leaky-relu</em> ( f(x) = alpha * x for x &lt; 0, f(x) = x for x &gt;= 0 ). It is applicable only if <em>actfun</em> equals to 'relu'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>a numeric value specifying the random seed. Defaults to 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>a boolean. If TRUE then information will be printed in the console</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>elm object which can be used with predict, residuals and fitted.
</p>


<h3>Examples</h3>

<pre><code class="language-R">elm(Species ~ ., data = iris, nhid = 20, actfun="sig")

mod_elm &lt;- elm(Species ~ ., data = iris, nhid = 20, actfun="sig")

# predict classes
predict(mod_elm, newdata = iris[1:3,-5])

# predict probabilities
predict(mod_elm, newdata = iris[1:3,-5], type="prob")

# predict elm output
predict(mod_elm, newdata = iris[1:3,-5], type="raw")

data("Boston")
elm(medv ~ ., data = Boston, nhid = 40, actfun="relu")

data("ionosphere")
elm(class ~ ., data = ionosphere, nhid=20, actfun="relu")

</code></pre>


</div>