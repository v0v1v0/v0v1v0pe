<div class="container">

<table style="width: 100%;"><tr>
<td>lr.test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Likelihood-Ratio Test
</h2>

<h3>Description</h3>

<p>Conduct the likelihood-ratio test for two nested extreme value distribution models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lr.test(x, y, alpha = 0.05, df = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x,y</code></td>
<td>

<p>Each can be either an object of class “fevd” (provided the fit method is MLE or GMLE) or a single numeric giving the negative log-likelihod value for each model.  <code>x</code> should be the model with fewer parameters, but if both <code>x</code> and <code>y</code> are “fevd” objects, then the order does not matter (it will be determined from which model has more parameters).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>single numeric between 0 and 1 giving the significance level for the test.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>

<p>single numeric giving the degrees of freedom.  If both <code>x</code> and <code>y</code> are “fevd” objects, then the degrees of freedom will be calculated, and this argument ignored.  Otherwise, if either or both of <code>x</code> and <code>y</code> are single numerics, then it must be provided or the test may be invalid.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Not used.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>When it is desired to incorporate covariates into an extreme value analysis, one method is to incorporate them into the parameters of the extreme value distributions themselves in a regression-like manner (cf. Coles, 2001 ch 6; Reiss and Thomas, 2007 ch 15).  In order to justify whether or not inclusion of the covariates into the model is significant or not is to apply the likelihood-ratio test (of course, the test is more general than that, cf. Coles (2001) p 35).
</p>
<p>The test is only valid for comparing nested models.  That is, the parameters of one model must be a subset of the parameters of the second model.
</p>
<p>Suppose the base model, m0, is nested within the model m1.  Let <code>x</code> be the negative log-likelihood for m0 and <code>y</code> for m1.  Then the likelihood-ratio statistic (or deviance statistic) is given by (Coles, 2001, p 35; Reiss and Thomas, 2007, p 118):
</p>
<p>D = -2*(<code>y</code> - <code>x</code>).
</p>
<p>Letting c.alpha be the (1 - alpha) quantile of the chi-square distribution with degrees of freedom equal to the difference in the number of model parameters, the null hypothesis that D = 0 is rejected if D &gt; c.alpha (i.e., in favor of model m1).
</p>


<h3>Value</h3>

<p>A list object of class “htest” is returned with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic </code></td>
<td>
<p>The test statistic value (referred to as D above).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter </code></td>
<td>
<p>numeric vector giving the chi-square critical value (c.alpha described above), the significance leve (alpha) and the degrees of freedom.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>character string stating “greater” indicating that the alternative decision is determined if the statistic is greater than c.alpha.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>numeric giving the p-value for the test.  If the p-value is smaller than alpha, then the decision is to reject the null hypothesis in favor of the model with more parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>character string saying “Likelihood-ratio Test”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>character vector of length two giving the names of the datasets used for the test (if “fevd” objects are passed) or the negative log-likelihood values if numbers are passed, or the names of x and y.  Although the names may differ, the models should have been fit to the same data set.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Eric Gilleland
</p>


<h3>References</h3>

<p>Coles, S.  (2001) <em>An introduction to statistical modeling of extreme values</em>, London, U.K.: Springer-Verlag, 208 pp.
</p>
<p>Reiss, R.-D. and Thomas, M. (2007) <em>Statistical Analysis of Extreme Values: with applications to insurance, finance, hydrology and other fields</em>. Birkhauser, 530pp., 3rd edition. 
</p>


<h3>See Also</h3>

<p><code>fevd</code>, <code>taildep.test</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(PORTw)
fit0 &lt;- fevd(PORTw$TMX1, type="Gumbel") 
fit1 &lt;- fevd(PORTw$TMX1)
fit2 &lt;- fevd(TMX1, PORTw, scale.fun=~STDTMAX)
lr.test(fit0, fit1)
lr.test(fit1, fit2)

</code></pre>


</div>