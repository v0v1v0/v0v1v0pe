<div class="container">

<table style="width: 100%;"><tr>
<td>scroll</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Scroll search function</h2>

<h3>Description</h3>

<p>Scroll search function
</p>


<h3>Usage</h3>

<pre><code class="language-R">scroll(
  conn,
  x,
  time_scroll = "1m",
  raw = FALSE,
  asdf = FALSE,
  stream_opts = list(),
  ...
)

scroll_clear(conn, x = NULL, all = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>conn</code></td>
<td>
<p>an Elasticsearch connection object, see <code>connect()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>(character) For <code>scroll</code>, a single scroll id; for
<code>scroll_clear</code>, one or more scroll id's</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time_scroll</code></td>
<td>
<p>(character) Specify how long a consistent view of the
index should be maintained for scrolled search, e.g., "30s", "1m".
See units-time.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>raw</code></td>
<td>
<p>(logical) If <code>FALSE</code> (default), data is parsed to list.
If <code>TRUE</code>, then raw JSON.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>asdf</code></td>
<td>
<p>(logical) If <code>TRUE</code>, use <code>jsonlite::fromJSON()</code>
to parse JSON directly to a data.frame. If <code>FALSE</code> (Default), list
output is given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stream_opts</code></td>
<td>
<p>(list) A list of options passed to
<code>jsonlite::stream_out()</code> - Except that you can't pass <code>x</code> as
that's the data that's streamed out, and pass a file path sinstead of a
connection to <code>con</code>. <code>pagesize</code> param doesn't do much as
that's more or less controlled by paging with ES.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Curl args passed on to crul::verb-POST</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all</code></td>
<td>
<p>(logical) If <code>TRUE</code> (default) then all search contexts
cleared.  If <code>FALSE</code>, scroll id's must be passed to <code>x</code></p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>scroll()</code> returns a list, identical to what
<code>Search()</code> returns. With attribute <code>scroll</code> that is the
scroll value set via the <code>time_scroll</code> parameter
</p>
<p><code>scroll_clear()</code> returns a boolean (<code>TRUE</code> on success)
</p>


<h3>Scores</h3>

<p>Scores will be the same for all documents that are returned from a
scroll request. Dems da rules.
</p>


<h3>Inputs</h3>

<p>Inputs to <code>scroll()</code> can be one of:
</p>

<ul>
<li>
<p> list - This usually will be the output of <code>Search()</code>, but
you could in theory make a list yourself with the appropriate elements
</p>
</li>
<li>
<p> character - A scroll ID - this is typically the scroll id output
from a call to <code>Search()</code>, accessed like <code>res$`_scroll_id`</code>
</p>
</li>
</ul>
<p>All other classes passed to <code>scroll()</code> will fail with message
</p>
<p>Lists passed to <code>scroll()</code> without a <code style="white-space: pre;">⁠_scroll_id⁠</code> element will
trigger an error.
</p>
<p>From lists output form <code>Search()</code> there should be an attribute
("scroll") that is the <code>scroll</code> value set in the <code>Search()</code>
request - if that attribute is missing from the list, we'll attempt to
use the <code>time_scroll</code> parameter value set in the
<code>scroll()</code> function call
</p>
<p>The output of <code>scroll()</code> has the scroll time value as an attribute so
the output can be passed back into <code>scroll()</code> to continue.
</p>


<h3>Clear scroll</h3>

<p>Search context are automatically removed when the scroll timeout has
been exceeded.  Keeping scrolls open has a cost, so scrolls should be
explicitly cleared as soon  as the scroll is not being used anymore
using <code>scroll_clear</code>
</p>


<h3>Sliced scrolling</h3>

<p>For scroll queries that return a lot of documents it is possible to split
the scroll in multiple slices which can be consumed independently.
</p>
<p>See the example in this man file.
</p>


<h3>Aggregations</h3>

<p>If the request specifies aggregations, only the initial search response
will contain the aggregations results.
</p>


<h3>See Also</h3>

<p><code>Search()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# connection setup
(con &lt;- connect())

# Basic usage - can use across all indices
res &lt;- Search(con, time_scroll="1m")
scroll(con, res)$`_scroll_id`

# use on a specific index - and specify a query
res &lt;- Search(con, index = 'shakespeare', q="a*", time_scroll="1m")
res$`_scroll_id`

# Setting "sort=_doc" to turn off sorting of results - faster
res &lt;- Search(con, index = 'shakespeare', q="a*", time_scroll="1m",
  body = '{"sort": ["_doc"]}')
res$`_scroll_id`

# Pass scroll_id to scroll function
scroll(con, res$`_scroll_id`)

# Get all results - one approach is to use a while loop
res &lt;- Search(con, index = 'shakespeare', q="a*", time_scroll="5m",
  body = '{"sort": ["_doc"]}')
out &lt;- res$hits$hits
hits &lt;- 1
while(hits != 0){
  res &lt;- scroll(con, res$`_scroll_id`, time_scroll="5m")
  hits &lt;- length(res$hits$hits)
  if(hits &gt; 0)
    out &lt;- c(out, res$hits$hits)
}
length(out)
res$hits$total
out[[1]]

# clear scroll
## individual scroll id
res &lt;- Search(con, index = 'shakespeare', q="a*", time_scroll="5m",
  body = '{"sort": ["_doc"]}')
scroll_clear(con, res$`_scroll_id`)

## many scroll ids
res1 &lt;- Search(con, index = 'shakespeare', q="c*", time_scroll="5m",
  body = '{"sort": ["_doc"]}')
res2 &lt;- Search(con, index = 'shakespeare', q="d*", time_scroll="5m",
  body = '{"sort": ["_doc"]}')
nodes_stats(con, metric = "indices")$nodes[[1]]$indices$search$open_contexts
scroll_clear(con, c(res1$`_scroll_id`, res2$`_scroll_id`))
nodes_stats(con, metric = "indices")$nodes[[1]]$indices$search$open_contexts

## all scroll ids
res1 &lt;- Search(con, index = 'shakespeare', q="f*", time_scroll="1m",
  body = '{"sort": ["_doc"]}')
res2 &lt;- Search(con, index = 'shakespeare', q="g*", time_scroll="1m",
  body = '{"sort": ["_doc"]}')
res3 &lt;- Search(con, index = 'shakespeare', q="k*", time_scroll="1m",
  body = '{"sort": ["_doc"]}')
scroll_clear(con, all = TRUE)

## sliced scrolling
body1 &lt;- '{
  "slice": {
    "id": 0,
    "max": 2
  },
  "query": {
    "match" : {
      "text_entry" : "a*"
    }
  }
}'

body2 &lt;- '{
  "slice": {
    "id": 1,
    "max": 2
  },
  "query": {
    "match" : {
      "text_entry" : "a*"
    }
  }
}'

res1 &lt;- Search(con, index = 'shakespeare', time_scroll="1m", body = body1)
res2 &lt;- Search(con, index = 'shakespeare', time_scroll="1m", body = body2)
scroll(con, res1$`_scroll_id`)
scroll(con, res2$`_scroll_id`)

out1 &lt;- list()
hits &lt;- 1
while(hits != 0){
  tmp1 &lt;- scroll(con, res1$`_scroll_id`)
  hits &lt;- length(tmp1$hits$hits)
  if(hits &gt; 0)
    out1 &lt;- c(out1, tmp1$hits$hits)
}

out2 &lt;- list()
hits &lt;- 1
while(hits != 0){
  tmp2 &lt;- scroll(con, res2$`_scroll_id`)
  hits &lt;- length(tmp2$hits$hits)
  if(hits &gt; 0)
    out2 &lt;- c(out2, tmp2$hits$hits)
}

c(
 lapply(out1, "[[", "_source"),
 lapply(out2, "[[", "_source")
)


# using jsonlite::stream_out
res &lt;- Search(con, time_scroll = "1m")
file &lt;- tempfile()
scroll(con, 
  x = res$`_scroll_id`,
  stream_opts = list(file = file)
)
jsonlite::stream_in(file(file))
unlink(file)

## stream_out and while loop
(file &lt;- tempfile())
res &lt;- Search(con, index = "shakespeare", time_scroll = "5m",
  size = 1000, stream_opts = list(file = file))
while(!inherits(res, "warning")) {
  res &lt;- tryCatch(scroll(
    conn = con,
    x = res$`_scroll_id`,
    time_scroll = "5m",
    stream_opts = list(file = file)
  ), warning = function(w) w)
}
NROW(df &lt;- jsonlite::stream_in(file(file)))
head(df)

## End(Not run)
</code></pre>


</div>