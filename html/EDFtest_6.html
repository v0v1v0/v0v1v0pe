<div class="container">

<table style="width: 100%;"><tr>
<td>AD.pvalue</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>P-value of Anderson-Darling statistic</h2>

<h3>Description</h3>

<p>Compute the P-value of the given Anderson-Darling statistic <code class="reqn">A^2</code>
using <code>imhof</code> function in <code>CompQuadForm</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">AD.uniform.pvalue(a, neig = 100, verbose = FALSE)

AD.normal.pvalue(a, neig = 100, verbose = FALSE)

AD.gamma.pvalue(a, shape, neig = 100, verbose = FALSE)

AD.logistic.pvalue(a, neig = 100, verbose = FALSE)

AD.laplace.pvalue(a, neig = 100, verbose = FALSE)

AD.weibull.pvalue(a, neig = 100, verbose = FALSE)

AD.extremevalue.pvalue(a, neig = 100, verbose = FALSE)

AD.exp.pvalue(a, neig = 100, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>Anderson-Darling statistic <code class="reqn">A^2</code> with a given distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neig</code></td>
<td>
<p>Number of eigenvalues used for <code>imhof</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical; if TRUE, print warning messages.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shape</code></td>
<td>
<p>The shape parameter of Gamma distribution.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Parameters must be estimated by maximum likelihood (ML) in order
for the P-values computed here to be asymptotically valid.
They are computed using the fact that when parameters are
estimated by maximum likelihood and the null hypothesis
is true, the asymptotic distribution of the GOF statistic
is the distribution of an infinite weighted sum
of weighted chi-square random variables on 1 degree of freedom.
The weights are eigenvalues of an integral equation. They
depend on the distribution being tested, the statistic being used,
and in some cases on the actual parameter values. These weights
are then computed approximately by discretization of the integral
equation; when that equation depends on one or more parameter
values we use the MLE in the equation.
</p>
<p>Some notes on the specific distributions: For the Normal, Logistic,
Laplace, Extreme Value, Weibull and Exponential distributions, the
limiting distributions do not depend on the parameters. For the
Gamma distribution, the shape parameter affects the limiting
distribution. The tests remain asymptotically valid when the MLE
is used to approximate the limit distribution.
</p>
<p>The Exponential distribution is a special case of the Weibull and
Gamma families arising when the shape is known to be 1. Knowing a
parameter and therefore not estimating it affects the distribution
of the test statistic and the functions provided for the Exponential
distribution allow for this.
</p>
<p>If a data set X_1,...,X_n follows the Weibull distribution then
Y_1 = log(X_1), ... ,Y_n = log(X_n) follows the Extreme Value
distribution and vice versa. The two procedures give identical
test statistics and P-values, in principal.
</p>
<p>Some of the models have more than one common parametrization. For
the Exponential, Gamma, and Weibull distributions, some writers
use a rate parameter and some use the scale parameter which is
the inverse of the rate. Our code uses the scale parameter.
</p>
<p>For the Laplace distribution, some writers use the density
<code class="reqn">f(x)= exp(-|x-\mu|/\beta)/(2\beta)</code> in which <code class="reqn">\beta</code>
is a scale parameter. Others use the
standard deviation <code class="reqn">\sigma = \beta/\sqrt{2}</code>. Our code
uses the scale parameter.
</p>
<p>For the Uniform distribution, we offer code for the two parameter
Uniform distribution on the range <code class="reqn">\theta_1</code> to <code class="reqn">\theta_2</code>.
These are estimated by the sample minimum and sample maximum.
The probability integral transforms of the remaining n-2 points
are then tested for uniformity on the range 0 to 1. This procedure
is justified because the these probability integral transforms
have exactly this distribution if the original data had a uniform
distribution over any interval.
</p>
<p>It is not unusual to test the hypothesis that a sample follows the
standard uniform distribution on [0,1]. In this case the parameters
<em>should not</em> be estimated. Instead use <code>AD(z)</code> or <code>CvM(z)</code> or
<code>Watson(z)</code> to compute the statistic values and then get P-values from
<code>AD.uniform.pvalue(a)</code> or <code>CvM.uniform.pvalue(w)</code> or
<code>Watson.uniform.pvalue(u)</code> whichever is wanted.
</p>


<h3>Value</h3>

<p>P-value of the Anderson-Darling statistic.
</p>


<h3>See Also</h3>

<p><code>AD</code> for calculating Anderson-Darling statistic;
<code>CvM.pvalue</code> for calculating P-value of Cram√©r-von Mises statistic;
<code>Watson.pvalue</code> for calculating P-value of Watson statistic.
</p>


<h3>Examples</h3>

<pre><code class="language-R">x0=runif(n=100,min=-1,max=1)
asq0 = AD.uniform(x0)
AD.uniform.pvalue(asq0)

x1=rnorm(n=100,mean=0,sd=1)
asq1 = AD.normal(x1)
AD.normal.pvalue(asq1)

x2=rgamma(n=100,shape=1,scale=1)
asq2 = AD.gamma(x2)
AD.gamma.pvalue(asq2,1)

x3=rlogis(n=100,location=0,scale=1)
asq3 = AD.logistic(x3)
AD.logistic.pvalue(asq3)

x4=rmutil::rlaplace(n=100,m=0,s=1)
asq4 = AD.laplace(x4)
AD.laplace.pvalue(asq4)

x5=rweibull(n=100,shape=1,scale=1)
asq5 = AD.weibull(x5)
AD.weibull.pvalue(asq5)
x5_log=log(x5)
AD.extremevalue.pvalue(AD.extremevalue(x5_log))

x6=rexp(n=100,rate=1/2)
asq6 = AD.exp(x6)
AD.exp.pvalue(asq6)
</code></pre>


</div>