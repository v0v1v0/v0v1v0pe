<div class="container">

<table style="width: 100%;"><tr>
<td>ebdbn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Empirical Bayes Dynamic Bayesian Network (EBDBN) Estimation</h2>

<h3>Description</h3>

<p>A function to infer the posterior mean and variance of network parameters
using an empirical Bayes estimation procedure for a Dynamic Bayesian Network (DBN).
</p>


<h3>Usage</h3>

<pre><code class="language-R">ebdbn(y, K, input = "feedback", conv.1 = .15, conv.2 = .05, conv.3 = .01, verbose = TRUE,
max.iter = 100, max.subiter = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A list of R (PxT) matrices of observed time course profiles (P genes, T time points)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of hidden states</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input</code></td>
<td>
<p>"feedback" for feedback loop networks, or a list of R (MxT) matrices of input profiles</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv.1</code></td>
<td>
<p>Value of convergence criterion 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv.2</code></td>
<td>
<p>Value of convergence criterion 2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv.3</code></td>
<td>
<p>Value of convergence criterion 3</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Verbose output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>Maximum overall iterations (default value is 100)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.subiter</code></td>
<td>
<p>Maximum iterations for hyperparameter updates (default value is 200)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>An object of class <code>ebdbNet</code>.
</p>
<p>This function infers the parameters of a network, based on the state space model
</p>
<p style="text-align: center;"><code class="reqn">x_t = Ax_{t-1} + Bu_t + w_t</code>
</p>

<p style="text-align: center;"><code class="reqn">y_t = Cx_t + Du_t + z_t</code>
</p>

<p>where <code class="reqn">x_t</code> represents the expression of K hidden states at time <code class="reqn">t</code>,
<code class="reqn">y_t</code> represents the expression of P observed states (e.g., genes) at time
<code class="reqn">t</code>, <code class="reqn">u_t</code> represents the values of M inputs at time <code class="reqn">t</code>,
<code class="reqn">w_t \sim MVN(0,I)</code>, and <code class="reqn">z_t \sim MVN(0,V^{-1})</code>,
with <code class="reqn">V = diag(v_1, \ldots, v_P)</code>. Note that the
dimensions of the matrices <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">C</code>, and <code class="reqn">D</code> are (KxK),
(KxM), (PxK), and (PxM), respectively. When a network is estimated with
feedback rather than inputs (<code>input</code> = "feedback"), the state
space model is
</p>
<p style="text-align: center;"><code class="reqn">x_t = Ax_{t-1} + By_{t-1} + w_t</code>
</p>

<p style="text-align: center;"><code class="reqn">y_t = Cx_t + Dy_{t-1} + z_t</code>
</p>

<p>The parameters of greatest interest are typically
contained in the matrix <code class="reqn">D</code>, which encodes the direct interactions among
observed variables from one time to the next (in the case of feedback loops),
or the direct interactions between inputs and observed variables at each time point
(in the case of inputs).
</p>
<p>The value of K is chosen prior to running the algorithm by using <code>hankel</code>.
The hidden states are estimated using the classic Kalman filter. Posterior distributions
of <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">C</code>, and <code class="reqn">D</code> are estimated using an empirical
Bayes procedure based on a hierarchical Bayesian structure defined over the
parameter set. Namely, if <code class="reqn">a_{(j)}</code>, <code class="reqn">b_{(j)}</code>,
<code class="reqn">c_{(j)}</code>, <code class="reqn">d_{(j)}</code>, denote vectors made up of the
rows of matrices <code class="reqn">A</code>, <code class="reqn">B</code>, <code class="reqn">C</code>, and <code class="reqn">D</code> respectively, then
</p>
<p style="text-align: center;"><code class="reqn">a_{(j)} \vert \alpha \sim N(0, diag(\alpha)^{-1})</code>
</p>

<p style="text-align: center;"><code class="reqn">b_{(j)} \vert \beta \sim N(0, diag(\beta)^{-1})</code>
</p>

<p style="text-align: center;"><code class="reqn">c_{(j)} \vert \gamma \sim N(0, diag(\gamma)^{-1})</code>
</p>

<p style="text-align: center;"><code class="reqn">d_{(j)} \vert \delta \sim N(0, diag(\delta)^{-1})</code>
</p>

<p>where <code class="reqn">\alpha = (\alpha_1, ..., \alpha_K)</code>,
<code class="reqn">\beta = (\beta_1, ..., \beta_M)</code>,
<code class="reqn">\gamma = (\gamma_1, ..., \gamma_K)</code>,
and <code class="reqn">\delta = (\delta_1, ..., \delta_M)</code>. An EM-like algorithm 
is used to estimate the hyperparameters in an iterative
procedure conditioned on current estimates of the hidden states.
</p>
<p><code>conv.1</code>, <code>conv.2</code>, and <code>conv.3</code> correspond to convergence
criteria <code class="reqn">\Delta_1</code>, <code class="reqn">\Delta_2</code>, and
<code class="reqn">\Delta_3</code> in the reference below, respectively.  After
terminating the algorithm, the z-scores of the <code class="reqn">D</code> matrix is
calculated, which in turn determines the presence or absence of edges in the network.
</p>
<p>See the reference below for additional details about the implementation of the
algorithm. 
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>APost </code></td>
<td>
<p>Posterior mean of matrix <code class="reqn">A</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BPost </code></td>
<td>
<p>Posterior mean of matrix <code class="reqn">B</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CPost </code></td>
<td>
<p>Posterior mean of matrix <code class="reqn">C</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DPost </code></td>
<td>
<p>Posterior mean of matrix <code class="reqn">D</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CvarPost </code></td>
<td>
<p>Posterior variance of matrix C</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DvarPost </code></td>
<td>
<p>Posterior variance of matrix D</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xPost </code></td>
<td>
<p>Posterior mean of hidden states x</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphaEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\alpha</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betaEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\beta</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gammaEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\gamma</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deltaEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\delta</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vEst </code></td>
<td>
<p>Estimated value of precisions <code class="reqn">v</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>muEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\mu</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmaEst </code></td>
<td>
<p>Estimated value of <code class="reqn">\Sigma</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alliterations </code></td>
<td>
<p>Total number of iterations run</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z </code></td>
<td>
<p>Z-statistics calculated from the posterior distribution of matrix D</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type </code></td>
<td>
<p>Either "input" or "feedback", as specified by the user</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Andrea Rau</p>


<h3>References</h3>

<p>Andrea Rau, Florence Jaffrezic, Jean-Louis Foulley, and R. W. Doerge (2010). An Empirical
Bayesian Method for Estimating Biological Networks from Temporal Microarray Data. <em>Statistical
Applications in Genetics and Molecular Biology</em> 9. Article 9.
</p>


<h3>See Also</h3>

<p><code>hankel</code>, <code>calcSensSpec</code>, <code>plot.ebdbNet</code></p>


<h3>Examples</h3>

<pre><code class="language-R">library(ebdbNet)
tmp &lt;- runif(1) ## Initialize random number generator
set.seed(125214) ## Save seed

## Simulate data
R &lt;- 5
T &lt;- 10
P &lt;- 10
simData &lt;- simulateVAR(R, T, P, v = rep(10, P), perc = 0.10)
Dtrue &lt;- simData$Dtrue
y &lt;- simData$y

## Simulate 8 inputs
u &lt;- vector("list", R)
M &lt;- 8
for(r in 1:R) {
	u[[r]] &lt;- matrix(rnorm(M*T), nrow = M, ncol = T)
}

####################################################
## Run EB-DBN without hidden states
####################################################
## Choose alternative value of K using hankel if hidden states are to be estimated
## K &lt;- hankel(y)$dim

## Run algorithm	
net &lt;- ebdbn(y = y, K = 0, input = u, conv.1 = 0.15, conv.2 = 0.10, conv.3 = 0.10,
	verbose = TRUE)

## Visualize results
## Note: no edges here, which is unsurprising as inputs were randomly simulated
## (in input networks, edges only go from inputs to genes)
## plot(net, sig.level = 0.95)

</code></pre>


</div>