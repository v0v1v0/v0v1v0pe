<div class="container">

<table style="width: 100%;"><tr>
<td>r2_semipartial</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Semi-Partial (Part) Correlation Squared (<code class="reqn">\Delta R^2</code>)</h2>

<h3>Description</h3>

<p>Compute the semi-partial (part) correlation squared (also known as
<code class="reqn">\Delta R^2</code>). Currently, only <code>lm()</code> models are supported.
</p>


<h3>Usage</h3>

<pre><code class="language-R">r2_semipartial(
  model,
  type = c("terms", "parameters"),
  ci = 0.95,
  alternative = "greater",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>An <code>lm</code> model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type, either <code>"terms"</code>, or <code>"parameters"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
effectsize_CIs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is similar to the last column of the "Conditional Dominance Statistics"
section of the <code>parameters::dominance_analysis()</code> output. For each term, the
model is refit <em>without</em> the columns on the model matrix that correspond to that term. The <code class="reqn">R^2</code> of
this <em>sub</em>-model is then subtracted from the <code class="reqn">R^2</code> of the <em>full</em> model to
yield the <code class="reqn">\Delta R^2</code>. (For <code>type = "parameters"</code>, this is done for each
column in the model matrix.)
</p>
<p><strong>Note</strong> that this is unlike <code>parameters::dominance_analysis()</code>, where term
deletion is done via the formula interface, and therefore may lead to
different results.
</p>
<p>For other, non-<code>lm()</code> models, as well as more verbose information and
options, please see the documentation for <code>parameters::dominance_analysis()</code>.
</p>


<h3>Value</h3>

<p>A data frame with the effect size.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Confidence intervals are based on the normal approximation as provided by Alf
and Graf (1999). An adjustment to the lower bound of the CI is used, to
improve the coverage properties of the CIs, according to Algina et al (2008):
If the <em>F</em> test associated with the <code class="reqn">sr^2</code> is significant (at <code>1-ci</code>
level), but the lower bound of the CI is 0, it is set to a small value
(arbitrarily to a 10th of the estimated <code class="reqn">sr^2</code>); if the <em>F</em> test is not
significant, the lower bound is set to 0. (Additionally, lower and upper
bound are "fixed" so that they cannot be smaller than 0 or larger than 1.)
</p>


<h3>CIs and Significance Tests</h3>

<p>"Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more." (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br><br>
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are "close enough"
to 0 to be negligible are needed ("equivalence testing"; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code>
</h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li>
<p> Alf Jr, E. F., &amp; Graf, R. G. (1999). Asymptotic confidence limits for the
difference between two squared multiple correlations: A simplified approach.
<em>Psychological Methods, 4</em>(1), 70-75. <a href="https://doi.org/10.1037/1082-989X.4.1.70">doi:10.1037/1082-989X.4.1.70</a>
</p>
</li>
<li>
<p> Algina, J., Keselman, H. J., &amp; Penfield, R. D. (2008). Confidence intervals
for the squared multiple semipartial correlation coefficient. <em>Journal of
Modern Applied Statistical Methods, 7</em>(1), 2-10. <a href="https://doi.org/10.22237/jmasm/1209614460">doi:10.22237/jmasm/1209614460</a>
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>eta_squared()</code>, <code>cohens_f()</code> for comparing two models,
<code>parameters::dominance_analysis()</code> and
<code>parameters::standardize_parameters()</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data("hardlyworking")

m &lt;- lm(salary ~ factor(n_comps) + xtra_hours * seniority, data = hardlyworking)

r2_semipartial(m)

r2_semipartial(m, type = "parameters")



# Compare to `eta_squared()`
# --------------------------
npk.aov &lt;- lm(yield ~ N + P + K, npk)

# When predictors are orthogonal,
# eta_squared(partial = FALSE) gives the same effect size:
performance::check_collinearity(npk.aov)

eta_squared(npk.aov, partial = FALSE)

r2_semipartial(npk.aov)


# Compare to `dominance_analysis()`
# ---------------------------------
m_full &lt;- lm(salary ~ ., data = hardlyworking)

r2_semipartial(m_full)

# Compare to last column of "Conditional Dominance Statistics":
parameters::dominance_analysis(m_full)

</code></pre>


</div>