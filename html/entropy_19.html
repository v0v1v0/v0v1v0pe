<div class="container">

<table style="width: 100%;"><tr>
<td>entropy.NSB</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>R Interface to NSB Entropy Estimator</h2>

<h3>Description</h3>

<p><code>entropy.NSB</code> estimates the Shannon entropy H of the random variable Y
from the corresponding observed counts <code>y</code> using the method 
of Nemenman, Shafee and Bialek (2002).
</p>
<p>Note that this function is an R interface to the "nsb-entropy" program. 
Hence, this needs to be installed separately from <a href="http://nsb-entropy.sourceforge.net/">http://nsb-entropy.sourceforge.net/</a>.</p>


<h3>Usage</h3>

<pre><code class="language-R">entropy.NSB(y, unit=c("log", "log2", "log10"), CMD="nsb-entropy")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of counts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit</code></td>
<td>
<p>the unit in which entropy is measured. 
The default is "nats" (natural units). For 
computing entropy in "bits" set <code>unit="log2"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CMD</code></td>
<td>
<p>path to the "nsb-entropy" executable.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The NSB estimator is due to Nemenman, Shafee and Bialek (2002).
It is a Dirichlet-multinomial entropy estimator, with a hierarchical prior
over the Dirichlet pseudocount parameters.
</p>
<p>Note that the NSB estimator is not a plug-in estimator, hence there
are no explicit underlying bin frequencies.
</p>


<h3>Value</h3>

<p><code>entropy.NSB</code> returns an estimate of the Shannon entropy. 
</p>


<h3>Author(s)</h3>

<p>Jean Hausser.
</p>


<h3>References</h3>

<p>Nemenman, I., F. Shafee, and W. Bialek. 2002. Entropy and inference, revisited.
In: Dietterich, T., S. Becker, Z. Gharamani, eds. Advances in Neural
Information Processing Systems 14: 471-478. Cambridge (Massachusetts):
MIT Press.
</p>


<h3>See Also</h3>

<p><code>entropy</code>, <code>entropy.shrink</code>,
<code>entropy.Dirichlet</code>, 
<code>entropy.ChaoShen</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># load entropy library 
library("entropy")

# observed counts for each bin
y = c(4, 2, 3, 0, 2, 4, 0, 0, 2, 1, 1)  

## Not run: 
# estimate entropy using the NSB method
entropy.NSB(y) # 2.187774

## End(Not run)

# compare to empirical estimate
entropy.empirical(y)
</code></pre>


</div>