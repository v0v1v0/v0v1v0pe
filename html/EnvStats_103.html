<div class="container">

<table style="width: 100%;"><tr>
<td>elnorm3</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimate Parameters of a Three-Parameter Lognormal Distribution (Log-Scale)
</h2>

<h3>Description</h3>

<p>Estimate the mean, standard deviation, and threshold parameters for a 
three-parameter lognormal distribution, and optionally 
construct a confidence interval for the threshold or the median of the distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  elnorm3(x, method = "lmle", ci = FALSE, ci.parameter = "threshold", 
    ci.method = "avar", ci.type = "two-sided", conf.level = 0.95, 
    threshold.lb.sd = 100, evNormOrdStats.method = "royston")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>numeric vector of observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>character string specifying the method of estimation.  Possible values are:
</p>
 
<ul>
<li> <p><code>"lmle"</code> (local maximum likelihood; the default)
</p>
</li>
<li> <p><code>"mme"</code> (method of moments)
</p>
</li>
<li> <p><code>"mmue"</code> (method of moments using an unbaised estimate of variance)
</p>
</li>
<li> <p><code>"mmme"</code> (modified method of moments due to Cohen and Whitten (1980))
</p>
</li>
<li> <p><code>"zero.skew"</code> (zero-skewness estimator due to Griffiths (1980))
</p>
</li>
<li> <p><code>"royston.skew"</code> (estimator based on Royston's (1992b) index of skewness).  
</p>
</li>
</ul>
<p>See the DETAILS section for more information.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>

<p>logical scalar indicating whether to compute a confidence interval for either 
the threshold or median of the distribution.  The default value is <code>FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.parameter</code></td>
<td>

<p>character string indicating the parameter for which the confidence interval is 
desired.  The possible values are <code>"threshold"</code> (the default) and 
<code>"median"</code>.  This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.method</code></td>
<td>

<p>character string indicating the method to use to construct the confidence interval.  
The possible values are <code>"avar"</code> (asymptotic variance; the default), <br><code>"likelihood.profile"</code>, and <code>"skewness"</code> (method suggested by Royston 
(1992b) for <code>method="zero.skew"</code>).  This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.type</code></td>
<td>

<p>character string indicating what kind of confidence interval to compute.  The 
possible values are <code>"two-sided"</code> (the default), <code>"lower"</code>, and 
<code>"upper"</code>.  This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>

<p>a scalar between 0 and 1 indicating the confidence level of the confidence interval.  
The default value is <code>conf.level=0.95</code>. This argument is ignored if 
<code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold.lb.sd</code></td>
<td>

<p>a positive numeric scalar specifying the range over which to look for the 
local maximum likelihood (<code>method="lmle"</code>) or zero-skewness <br>
(<code>method="zero.skewness"</code>) estimator of threshold.  The range is set to <br><code>[ mean(x) - threshold.lb.sd * sd(x), min(x) ]</code>.  If you receive a warning 
message that <code>elnorm3</code> is unable to find an acceptable estimate of threshold 
in this range, it may be because of convergence problems specific to the data in 
<code>x</code>.  When this occurs, try changing the value of <code>threshold.lb.sd</code>.  This 
same range is used in constructing confidence intervals for the threshold parameter.  
The default value is <code>threshold.lb.sd=100</code>.  This argument is relevant only if 
<code>method="lmle"</code>, <code>method="zero.skew"</code>, 
<code>ci.method="likelihood.profile"</code>, and/or <code>ci.method="skewness"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>evNormOrdStats.method</code></td>
<td>

<p>character string indicating which method to use in the call to 
<code>link{evNormOrdStatsScalar}</code> when <code>method="mmme"</code>.  See the DETAILS 
section for more information. 
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>x</code> contains any missing (<code>NA</code>), undefined (<code>NaN</code>) or 
infinite (<code>Inf</code>, <code>-Inf</code>) values, they will be removed prior to 
performing the estimation.
</p>
<p>Let <code class="reqn">X</code> denote a random variable from a 
three-parameter lognormal distribution with 
parameters <code>meanlog=</code><code class="reqn">\mu</code>, <code>sdlog=</code><code class="reqn">\sigma</code>, and 
<code>threshold=</code><code class="reqn">\gamma</code>.  Let <code class="reqn">\underline{x}</code> denote a vector of 
<code class="reqn">n</code> observations from this distribution.  Furthermore, let <code class="reqn">x_{(i)}</code> denote 
the <code class="reqn">i</code>'th order statistic in the sample, so that <code class="reqn">x_{(1)}</code> denotes the 
smallest value and <code class="reqn">x_{(n)}</code> denote the largest value in <code class="reqn">\underline{x}</code>.  
Finally, denote the sample mean and variance by:
</p>
<p style="text-align: center;"><code class="reqn">\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i \;\;\;\; (1)</code>
</p>

<p style="text-align: center;"><code class="reqn">s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2 \;\;\;\; (2)</code>
</p>

<p>Note that the sample variance is the unbiased version.  Denote the method of 
moments estimator of variance by:
</p>
<p style="text-align: center;"><code class="reqn">s^2_m = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2 \;\;\;\; (3)</code>
</p>

<p><b>Estimation</b> <br></p>
<p><em>Local Maximum Likelihood Estimation</em> (<code>method="lmle"</code>) <br>
Hill (1963) showed that the likelihood function approaches infinity as <code class="reqn">\gamma</code> 
approaches <code class="reqn">x_{(1)}</code>, so that the global maximum likelihood estimators of 
<code class="reqn">(\mu, \sigma, \gamma)</code> are <code class="reqn">(-\infty, \infty, x_{(1)})</code>, which are 
inadmissible, since <code class="reqn">\gamma</code> must be smaller than <code class="reqn">x_{(1)}</code>.  Cohen (1951) 
suggested using local maximum likelihood estimators (lmle's), derived by equating 
partial derivatives of the log-likelihood function to zero.  These estimators were 
studied by Harter and Moore (1966), Calitz (1973), Cohen and Whitten (1980), and 
Griffiths (1980), and appear to possess most of the desirable properties ordinarily 
associated with maximum likelihood estimators.
</p>
<p>Cohen (1951) showed that the lmle of <code class="reqn">\gamma</code> is given by the solution to the 
following equation:
</p>
<p style="text-align: center;"><code class="reqn">[\sum_{i=1}^n \frac{1}{w_i}] \, \{\sum_{i=1}^n y_i - \sum_{i=1}^n y_i^2 + \frac{1}{n}[\sum_{i=1}^n y_i]^2 \} - n \sum_{i=1}^n \frac{y_i}{w_i} = 0 \;\;\;\; (4)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">w_i = x_i - \hat{\gamma} \;\;\;\; (5)</code>
</p>

<p style="text-align: center;"><code class="reqn">y_i = log(x_i - \hat{\gamma}) = log(w_i) \;\;\;\; (6)</code>
</p>

<p>and that the lmle's of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> then follow as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu} = \frac{1}{n} \sum_{i=1}^n y_i = \bar{y} \;\;\;\; (7)</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^2 \;\;\;\; (8)</code>
</p>

<p>Unfortunately, while equation (4) simplifies the task of computing the lmle's, 
for certain data sets there still may be convergence problems (Calitz, 1973), and 
occasionally multiple roots of equation (4) may exist.  When multiple roots to 
equation (4) exisit, Cohen and Whitten (1980) recommend using the one that results 
in closest agreement between the mle of <code class="reqn">\mu</code> (equation (7)) and the sample 
mean (equation (1)).
</p>
<p>On the other hand, Griffiths (1980) showed that for a given value of the threshold 
parameter <code class="reqn">\gamma</code>, the maximized value of the log-likelihood (the 
“profile likelihood” for <code class="reqn">\gamma</code>) is given by:
</p>
<p style="text-align: center;"><code class="reqn">log[L(\gamma)] = \frac{-n}{2} [1 + log(2\pi) + 2\hat{\mu} + log(\hat{\sigma}^2) ] \;\;\;\; (9)</code>
</p>

<p>where the estimates of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> are defined in equations (7) 
and (8), so the lmle of <code class="reqn">\gamma</code> reduces to an iterative search over the values 
of <code class="reqn">\gamma</code>.  Griffiths (1980) noted that the distribution of the lmle of 
<code class="reqn">\gamma</code> is far from normal and that <code class="reqn">log[L(\gamma)]</code> is not quadratic 
near the lmle of <code class="reqn">\gamma</code>.  He suggested a better parameterization based on
</p>
<p style="text-align: center;"><code class="reqn">\eta = -log(x_{(1)} - \gamma) \;\;\;\; (10)</code>
</p>

<p>Thus, once the lmle of <code class="reqn">\eta</code> is found using equations (9) and (10), the lmle of 
<code class="reqn">\gamma</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\gamma} = x_{(1)} - exp(-\hat{\eta}) \;\;\;\; (11)</code>
</p>

<p>When <code>method="lmle"</code>, the function <code>elnorm3</code> uses the function 
<code>nlminb</code> to search for the minimum of <code class="reqn">-2log[L(\eta)]</code>, using the 
modified method of moments estimator (<code>method="mmme"</code>; see below) as the 
starting value for <code class="reqn">\gamma</code>.  Equation (11) is then used to solve for the 
lmle of <code class="reqn">\gamma</code>, and equation (4) is used to “fine tune” the estimated 
value of <code class="reqn">\gamma</code>.  The lmle's of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> are then computed 
using equations (6)-(8).
<br></p>
<p><em>Method of Moments Estimation</em> (<code>method="mme"</code>) <br>  
Denote the <code class="reqn">r</code>'th sample central moment by:
</p>
<p style="text-align: center;"><code class="reqn">m_r = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^r \;\;\;\; (12)</code>
</p>

<p>and note that
</p>
<p style="text-align: center;"><code class="reqn">s^2_m = m_2 \;\;\;\; (13)</code>
</p>

<p>Equating the sample first moment (the sample mean) with its population value 
(the population mean), and equating the second and third sample central moments 
with their population values yields (Johnson et al., 1994, p.228):
</p>
<p style="text-align: center;"><code class="reqn">\bar{x} = \gamma + \beta \sqrt{\omega} \;\;\;\; (14)</code>
</p>

<p style="text-align: center;"><code class="reqn">m_2 = s^2_m = \beta^2 \omega (\omega - 1) \;\;\;\; (15)</code>
</p>

<p style="text-align: center;"><code class="reqn">m_3 = \beta^3 \omega^{3/2} (\omega - 1)^2 (\omega + 2) \;\;\;\; (16)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\beta = exp(\mu) \;\;\;\; (17)</code>
</p>

<p style="text-align: center;"><code class="reqn">\omega = exp(\sigma^2) \;\;\;\; (18)</code>
</p>

<p>Combining equations (15) and (16) yields:
</p>
<p style="text-align: center;"><code class="reqn">b_1 = \frac{m_3}{m_2^{3/2}} = (\omega + 2) \sqrt{\omega - 1} \;\;\;\; (19)</code>
</p>

<p>The quantity on the left-hand side of equation (19) is the usual estimator of 
skewness.  Solving equation (19) for <code class="reqn">\omega</code> yields:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\omega} = (d + h)^{1/3} + (d - h)^{1/3} - 1 \;\;\;\; (20)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">d = 1 + \frac{b_1}{2} \;\;\;\; (21)</code>
</p>

<p style="text-align: center;"><code class="reqn">h = sqrt{d^2 - 1} \;\;\;\; (22)</code>
</p>

<p>Using equation (18), the method of moments estimator of <code class="reqn">\sigma</code> is then 
computed as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2 = log(\hat{\omega}) \;\;\;\; (23)</code>
</p>

<p>Combining equations (15) and (17), the method of moments estimator of <code class="reqn">\mu</code> 
is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu} = \frac{1}{2} log[\frac{s^2_m}{\hat{omega}(\hat{\omega} - 1)}] \;\;\;\; (24)</code>
</p>

<p>Finally, using equations (14), (17), and (18), the method of moments estimator of 
<code class="reqn">\gamma</code> is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\bar{x} - exp(\hat{mu} + \frac{\hat{\sigma}^2}{2}) \;\;\;\; (25)</code>
</p>

<p>There are two major problems with using method of moments estimators for the 
three-parameter lognormal distribution.  First, they are subject to very large 
sampling error due to the use of second and third sample moments 
(Cohen, 1988, p.121; Johnson et al., 1994, p.228).  Second, Heyde (1963) showed 
that the lognormal distribution is not uniquely determined by its moments.
<br></p>
<p><em>Method of Moments Estimators Using an Unbiased Estimate of Variance</em> (<code>method="mmue"</code>) <br>
This method of estimation is exactly the same as the method of moments 
(<code>method="mme"</code>), except that the unbiased estimator of variance (equation (3)) 
is used in place of the method of moments one (equation (4)).  This modification is 
given in Cohen (1988, pp.119-120).
<br></p>
<p><em>Modified Method of Moments Estimation</em> (<code>method="mmme"</code>) <br>
This method of estimation is described by Cohen (1988, pp.125-132).  It was 
introduced by Cohen and Whitten (1980; their MME-II with r=1) and was further 
investigated by Cohen et al. (1985).  It is motivated by the fact that the first 
order statistic in the sample, <code class="reqn">x_{(1)}</code>, contains more information about 
the threshold parameter <code class="reqn">\gamma</code> than any other observation and often more 
information than all of the other observations combined (Cohen, 1988, p.125).
</p>
<p>The first two sets of equations are the same as for the modified method of moments 
estimators (<code>method="mmme"</code>), i.e., equations (14) and (15) with the 
unbiased estimator of variance (equation (3)) used in place of the method of 
moments one (equation (4)).  The third equation replaces equation (16) 
by equating a function of the first order statistic with its expected value:
</p>
<p style="text-align: center;"><code class="reqn">log(x_{(1)} - \gamma) = \mu + \sigma E[Z_{(1,n)}] \;\;\;\; (26)</code>
</p>

<p>where <code class="reqn">E[Z_{(i,n)}]</code> denotes the expected value of the <code class="reqn">i</code>'th order 
statistic in a random sample of <code class="reqn">n</code> observations from a standard normal 
distribution.  (See the help file for <code>evNormOrdStats</code> for information 
on how <code class="reqn">E[Z_{(i,n)}]</code> is computed.)  Using equations (17) and (18), 
equation (26) can be rewritten as:
</p>
<p style="text-align: center;"><code class="reqn">x_{(1)} = \gamma + \beta exp\{\sqrt{log(\omega)} \, E[Z_{(i,n)}] \} \;\;\;\; (27)</code>
</p>

<p>Combining equations (14), (15), (17), (18), and (27) yields the following equation 
for the estimate of <code class="reqn">\omega</code>:
</p>
<p style="text-align: center;"><code class="reqn">\frac{s^2}{[\bar{x} - x_{(1)}]^2} = \frac{\hat{\omega}(\hat{\omega} - 1)}{[\sqrt{\hat{\omega}} - exp\{\sqrt{log(\omega)} \, E[Z_{(i,n)}] \} ]^2} \;\;\;\; (28)</code>
</p>

<p>After equation (28) is solved for <code class="reqn">\hat{\omega}</code>, the estimate of <code class="reqn">\sigma</code> 
is again computed using equation (23), and the estimate of <code class="reqn">\mu</code> is computed 
using equation (24), where the unbiased estimate of variaince is used in place of 
the biased one (just as for <code>method="mmue"</code>).
<br></p>
<p><em>Zero-Skewness Estimation</em> (<code>method="zero.skew"</code>) <br>
This method of estimation was introduced by Griffiths (1980), and elaborated upon 
by Royston (1992b).  The idea is that if the threshold parameter <code class="reqn">\gamma</code> were 
known, then the distribution of:
</p>
<p style="text-align: center;"><code class="reqn">Y = log(X - \gamma) \;\;\;\; (29)</code>
</p>

<p>is normal, so the skew of <code class="reqn">Y</code> is 0.  Thus, the threshold parameter <code class="reqn">\gamma</code> 
is estimated as that value that forces the sample skew (defined in equation (19)) of 
the observations defined in equation (6) to be 0.  That is, the zero-skewness 
estimator of <code class="reqn">\gamma</code> is the value that satisfies the following equation:
</p>
<p style="text-align: center;"><code class="reqn">0 = \frac{\frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^3}{[\frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^2]^{3/2}} \;\;\;\; (30)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">y_i = log(x_i - \hat{\gamma}) \;\;\;\; (31)</code>
</p>

<p>Note that since the denominator in equation (30) is always positive (assuming 
there are at least two unique values in <code class="reqn">\underline{x}</code>), only the numerator 
needs to be used to determine the value of <code class="reqn">\hat{\gamma}</code>.
</p>
<p>Once the value of <code class="reqn">\hat{\gamma}</code> has been determined, <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> 
are estimated using equations (7) and (8), except the unbiased estimator of variance 
is used in equation (8).
</p>
<p>Royston (1992b) developed a modification of the Shaprio-Wilk goodness-of-fit test 
for normality based on tranforming the data using equation (6) and the zero-skewness 
estimator of <code class="reqn">\gamma</code> (see <code>gofTest</code>).
<br></p>
<p><em>Estimators Based on Royston's Index of Skewness</em> (<code>method="royston.skew"</code>) <br>
This method of estimation is discussed by Royston (1992b), and is similar to the 
zero-skewness method discussed above, except a different measure of skewness is used.  
Royston's (1992b) index of skewness is given by:
</p>
<p style="text-align: center;"><code class="reqn">q = \frac{y_{(n)} - \tilde{y}}{\tilde{y} - y_{(1)}} \;\;\;\; (32)</code>
</p>

<p>where <code class="reqn">y_{(i)}</code> denotes the <code class="reqn">i</code>'th order statistic of <code class="reqn">y</code> and <code class="reqn">y</code> 
is defined in equation (31) above, and <code class="reqn">\tilde{y}</code> denotes the median of <code class="reqn">y</code>.  
Royston (1992b) shows that the value of <code class="reqn">\gamma</code> that yields a value of 
<code class="reqn">q=0</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\gamma} = \frac{y_{(1)}y_{(n)} - \tilde{y}^2}{y_{(1)} + y_{(n)} - 2\tilde{y}} \;\;\;\; (33)</code>
</p>

<p>Again, as for the zero-skewness method, once the value of <code class="reqn">\hat{\gamma}</code> has 
been determined, <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> are estimated using equations (7) and (8), 
except the unbiased estimator of variance is used in equation (8).
</p>
<p>Royston (1992b) developed this estimator as a quick way to estimate <code class="reqn">\gamma</code>.
<br></p>
<p><b>Confidence Intervals</b> <br>
This section explains three different methods for constructing confidence intervals 
for the threshold parameter <code class="reqn">\gamma</code>, or the median of the three-parameter 
lognormal distribution, which is given by:
</p>
<p style="text-align: center;"><code class="reqn">Med[X] = \gamma + exp(\mu) = \gamma + \beta \;\;\;\; (34)</code>
</p>

<p><br></p>
<p><em>Normal Approximation Based on Asymptotic Variances and Covariances</em> (<code>ci.method="avar"</code>) <br>
Formulas for asymptotic variances and covariances for the three-parameter lognormal 
distribution, based on the information matrix, are given in Cohen (1951), Cohen and 
Whitten (1980), Cohen et al., (1985), and Cohen (1988).  The relevant quantities for 
<code class="reqn">\gamma</code> and the median are:
</p>
<p style="text-align: center;"><code class="reqn">Var(\hat{\gamma}) = \sigma^2_{\hat{\gamma}} = \frac{\sigma^2}{n} \, (\frac{\beta^2}{\omega}) H \;\;\;\; (35)</code>
</p>

<p style="text-align: center;"><code class="reqn">Var(\hat{\beta}) = \sigma^2_{\hat{\beta}} = \frac{\sigma^2}{n} \, \beta^2 (1 + H) \;\;\;\; (36)</code>
</p>

<p style="text-align: center;"><code class="reqn">Cov(\hat{\gamma}, \hat{\beta}) = \sigma_{\hat{\gamma}, \hat{\beta}} = \frac{-\sigma^3}{n} \, (\frac{\beta^2}{\sqrt{\omega}}) H \;\;\;\; (37)</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">H = [\omega (1 + \sigma^2) - 2\sigma^2 - 1]^{-1} \;\;\;\; (38)</code>
</p>

<p>A two-sided <code class="reqn">(1-\alpha)100\%</code> confidence interval for <code class="reqn">\gamma</code> is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\gamma} - t_{n-2, 1-\alpha/2} \hat{\sigma}_{\hat{\gamma}}, \, \hat{\gamma} + t_{n-2, 1-\alpha/2} \hat{\sigma}_{\hat{\gamma}} \;\;\;\; (39)</code>
</p>

<p>where <code class="reqn">t_{\nu, p}</code> denotes the <code class="reqn">p</code>'th quantile of 
Student's t-distribution with <code class="reqn">n</code> degrees of freedom, and the 
quantity <code class="reqn">\hat{\sigma}_{\hat{\gamma}}</code> is computed using equations (35) and (38) 
and substituting estimated values of <code class="reqn">\beta</code>, <code class="reqn">\omega</code>, and <code class="reqn">\sigma</code>.  
One-sided confidence intervals are computed in a similar manner.
</p>
<p>A two-sided <code class="reqn">(1-\alpha)100\%</code> confidence interval for the median (see equation 
(34) above) is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\gamma} + \hat{\beta} - t_{n-2, 1-\alpha/2} \hat{\sigma}_{\hat{\gamma} + \hat{\beta}}, \, \hat{\gamma} + \hat{\beta} + t_{n-2, 1-\alpha/2} \hat{\sigma}_{\hat{\gamma} + \hat{\beta}} \;\;\;\; (40)</code>
</p>

<p>where 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}^2_{\hat{\gamma} + \hat{\beta}} = \hat{\sigma}^2_{\hat{\gamma}} + \hat{\sigma}^2_{\hat{\beta}} + \hat{\sigma}_{\hat{\gamma}, \hat{\beta}} \;\;\;\; (41)</code>
</p>

<p>is computed using equations (35)-(38) and substituting estimated values of 
<code class="reqn">\beta</code>, <code class="reqn">\omega</code>, and <code class="reqn">\sigma</code>.  One-sided confidence intervals are 
computed in a similar manner.
</p>
<p>This method of constructing confidence intervals is analogous to using the Wald test 
(e.g., Silvey, 1975, pp.115-118) to test hypotheses on the parameters.
</p>
<p>Because of the regularity problems associated with the global maximum likelihood 
estimators, it is questionble whether the asymptotic variances and covariances shown 
above apply to local maximum likelihood estimators.  Simulation studies, however, 
have shown that these estimates of variance and covariance perform reasonably well 
(Harter and Moore, 1966; Cohen and Whitten, 1980).
</p>
<p>Note that this method of constructing confidence intervals can be used with 
estimators other than the lmle's.  Cohen and Whitten (1980) and Cohen et al. (1985) 
found that the asymptotic variances and covariances are reasonably close to 
corresponding simulated variances and covariances for the modified method of moments 
estimators (<code>method="mmme"</code>).
<br></p>
<p><em>Likelihood Profile</em> (<code>ci.method="likelihood.profile"</code>) <br>
Griffiths (1980) suggested constructing confidence intervals for the threshold 
parameter <code class="reqn">\gamma</code> based on the profile likelihood function given in equations 
(9) and (10).  Royston (1992b) further elaborated upon this procedure.  A 
two-sided <code class="reqn">(1-\alpha)100\%</code> confidence interval for <code class="reqn">\eta</code> is constructed as:
</p>
<p style="text-align: center;"><code class="reqn">[\eta_{LCL}, \eta_{UCL}] \;\;\;\; (42)</code>
</p>

<p>by finding the two values of <code class="reqn">\eta</code> (one larger than the lmle of <code class="reqn">\eta</code> and 
one smaller than the lmle of <code class="reqn">\eta</code>) that satisfy:
</p>
<p style="text-align: center;"><code class="reqn">log[L(\eta)] = log[L(\hat{\eta}_{lmle})] - \frac{1}{2} \chi^2_{1, \alpha/2} \;\;\;\; (43)</code>
</p>

<p>where <code class="reqn">\chi^2_{\nu, p}</code> denotes the <code class="reqn">p</code>'th quantile of the 
chi-square distribution with <code class="reqn">\nu</code> degrees of freedom.  
Once these values are found, the two-sided confidence for <code class="reqn">\gamma</code> is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\gamma_{LCL}, \gamma_{UCL}] \;\;\;\; (44)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\gamma_{LCL} = x_{(1)} - exp(-\eta_{LCL}) \;\;\;\; (45)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma_{UCL} = x_{(1)} - exp(-\eta_{UCL}) \;\;\;\; (46)</code>
</p>

<p>One-sided intervals are construced in a similar manner.
</p>
<p>This method of constructing confidence intervals is analogous to using the 
likelihood-ratio test (e.g., Silvey, 1975, pp.108-115) to test hypotheses on the 
parameters.
</p>
<p>To construct a two-sided <code class="reqn">(1-\alpha)100\%</code> confidence interval for the median 
(see equation (34)), Royston (1992b) suggested the following procedure:
</p>

<ol>
<li>
<p> Construct a confidence interval for <code class="reqn">\gamma</code> using the likelihood 
profile procedure.
</p>
</li>
<li>
<p> Construct a confidence interval for <code class="reqn">\beta</code> as: 
</p>
<p style="text-align: center;"><code class="reqn">[\beta_{LCL}, \beta_{UCL}] = [exp(\hat{\mu} - t_{n-2, 1-\alpha/2} \frac{\hat{\sigma}}{n}), \, exp(\hat{\mu} + t_{n-2, 1-\alpha/2} \frac{\hat{\sigma}}{n})] \;\;\;\; (47)</code>
</p>

</li>
<li>
<p> Construct the confidence interval for the median as: 
</p>
<p style="text-align: center;"><code class="reqn">[\gamma_{LCL} + \beta_{LCL}, \gamma_{UCL} + \beta_{UCL}] \;\;\;\; (48)</code>
</p>

</li>
</ol>
<p>Royston (1992b) actually suggested using the quantile from the standard normal 
distribution instead of Student's t-distribution in step 2 above.  The function 
<code>elnorm3</code>, however, uses the Student's t quantile.
</p>
<p>Note that this method of constructing confidence intervals can be used with 
estimators other than the lmle's.
<br></p>
<p><em>Royston's Confidence Interval Based on Significant Skewness</em> (<code>ci.method="skewness"</code>) <br>
Royston (1992b) suggested constructing confidence intervals for the threshold 
parameter <code class="reqn">\gamma</code> based on the idea behind the zero-skewness estimator 
(<code>method="zero.skew"</code>).  A two-sided <code class="reqn">(1-\alpha)100\%</code> confidence interval 
for <code class="reqn">\gamma</code> is constructed by finding the two values of <code class="reqn">\gamma</code> that yield 
a p-value of <code class="reqn">\alpha/2</code> for the test of zero-skewness on the observations 
<code class="reqn">\underline{y}</code> defined in equation (6) (see <code>gofTest</code>).  One-sided 
confidence intervals are constructed in a similar manner.
</p>
<p>To construct <code class="reqn">(1-\alpha)100\%</code> confidence intervals for the median 
(see equation (34)), the exact same procedure is used as for 
<code>ci.method="likelihood.profile"</code>, except that the confidence interval for 
<code class="reqn">\gamma</code> is based on the zero-skewness method just described instead of the 
likelihood profile method.
</p>


<h3>Value</h3>

<p>a list of class <code>"estimate"</code> containing the estimated parameters and other information.  
See <br><code>estimate.object</code> for details.
</p>


<h3>Note</h3>

<p>The problem of estimating the parameters of a three-parameter lognormal distribution 
has been extensively discussed by Aitchison and Brown (1957, Chapter 6), 
Calitz (1973), Cohen (1951), Cohen (1988), Cohen and Whitten (1980), 
Cohen et al. (1985), Griffiths (1980), Harter and Moore (1966), Hill (1963), and 
Royston (1992b).  Stedinger (1980) and Hoshi et al. (1984) discuss fitting the 
three-parameter lognormal distribution to hydrologic data.
</p>
<p>The global maximum likelihood estimates are inadmissible.  In the past, several 
researchers have found that the local maximum likelihood estimates (lmle's) 
occasionally fail because of convergence problems, but they were not using the 
likelihood profile and reparameterization of Griffiths (1980).  Cohen (1988) 
recommends the modified methods of moments estimators over lmle's because they are 
easy to compute, they are unbiased with respect to <code class="reqn">\mu</code> and <code class="reqn">\sigma^2</code> (the 
mean and standard deviation on the log-scale), their variances are minimal or near 
minimal, and they do not suffer from regularity problems.
</p>
<p>Because the distribution of the lmle of the threshold parameter <code class="reqn">\gamma</code> is far 
from normal for moderate sample sizes (Griffiths, 1980), it is questionable whether 
confidence intervals for <code class="reqn">\gamma</code> or the median based on asymptotic variances 
and covariances will perform well.  Cohen and Whitten (1980) and Cohen et al. (1985), 
however, found that the asymptotic variances and covariances are reasonably close to 
corresponding simulated variances and covariances for the modified method of moments 
estimators (<code>method="mmme"</code>).  In a simulation study (5000 monte carlo trials), 
Royston (1992b) found that the coverage of confidence intervals for <code class="reqn">\gamma</code> 
based on the likelihood profile (<code>ci.method="likelihood.profile"</code>) was very 
close the nominal level (94.1% for a nominal level of 95%), although not 
symmetric.  Royston (1992b) also found that the coverage of confidence intervals 
for <code class="reqn">\gamma</code> based on the skewness method (<code>ci.method="skewness"</code>) was also 
very close (95.4%) and symmetric.
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Aitchison, J., and J.A.C. Brown (1957).  <em>The Lognormal Distribution 
(with special references to its uses in economics)</em>.  Cambridge University Press, 
London, Chapter 5.
</p>
<p>Calitz, F. (1973).  Maximum Likelihood Estimation of the Parameters of the 
Three-Parameter Lognormal Distribution–a Reconsideration.  <em>Australian 
Journal of Statistics</em> <b>15</b>(3), 185–190.
</p>
<p>Cohen, A.C. (1951).  Estimating Parameters of Logarithmic-Normal Distributions by 
Maximum Likelihood.  <em>Journal of the American Statistical Association</em> 
<b>46</b>, 206–212.
</p>
<p>Cohen, A.C. (1988).  Three-Parameter Estimation.  In Crow, E.L., and K. Shimizu, eds. 
<em>Lognormal Distributions: Theory and Applications</em>.  Marcel Dekker, New York, 
Chapter 4.
</p>
<p>Cohen, A.C., and B.J. Whitten. (1980).  Estimation in the Three-Parameter Lognormal 
Distribution.  <em>Journal of the American Statistical Association</em> <b>75</b>, 
399–404.
</p>
<p>Cohen, A.C., B.J. Whitten, and Y. Ding. (1985).  Modified Moment Estimation for the 
Three-Parameter Lognormal Distribution.  <em>Journal of Quality Technology</em> 
<b>17</b>, 92–99.
</p>
<p>Crow, E.L., and K. Shimizu. (1988).  <em>Lognormal Distributions: Theory and 
Applications</em>.  Marcel Dekker, New York, Chapter 2.
</p>
<p>Griffiths, D.A. (1980).  Interval Estimation for the Three-Parameter Lognormal 
Distribution via the Likelihood Function.  <em>Applied Statistics</em> <b>29</b>, 
58–68.
</p>
<p>Harter, H.L., and A.H. Moore. (1966).  Local-Maximum-Likelihood Estimation of the 
Parameters of Three-Parameter Lognormal Populations from Complete and Censored 
Samples.  <em>Journal of the American Statistical Association</em> <b>61</b>, 842–851.
</p>
<p>Heyde, C.C. (1963).  On a Property of the Lognormal Distribution.  <em>Journal of 
the Royal Statistical Society, Series B</em> <b>25</b>, 392–393.
</p>
<p>Hill, .B.M. (1963).  The Three-Parameter Lognormal Distribution and Bayesian 
Analysis of a Point-Source Epidemic.  <em>Journal of the American Statistical 
Association</em> <b>58</b>, 72–84.
</p>
<p>Hoshi, K., J.R. Stedinger, and J. Burges. (1984).  Estimation of Log-Normal 
Quantiles: Monte Carlo Results and First-Order Approximations.  <em>Journal of 
Hydrology</em> <b>71</b>, 1–30.
</p>
<p>Johnson, N. L., S. Kotz, and N. Balakrishnan. (1994). 
<em>Continuous Univariate Distributions, Volume 1</em>. 
Second Edition. John Wiley and Sons, New York.
</p>
<p>Royston, J.P. (1992b).  Estimation, Reference Ranges and Goodness of Fit for the 
Three-Parameter Log-Normal Distribution.  <em>Statistics in Medicine</em> <b>11</b>, 
897–912.
</p>
<p>Stedinger, J.R. (1980).  Fitting Lognormal Distributions to Hydrologic Data. 
<em>Water Resources Research</em> <b>16</b>(3), 481–490.
</p>


<h3>See Also</h3>

<p>Lognormal3, Lognormal, LognormalAlt, 
Normal.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Generate 20 observations from a 3-parameter lognormal distribution 
  # with parameters meanlog=1.5, sdlog=1, and threshold=10, then use 
  # Cohen and Whitten's (1980) modified moments estimators to estimate 
  # the parameters, and construct a confidence interval for the 
  # threshold based on the estimated asymptotic variance. 
  # (Note: the call to set.seed simply allows you to reproduce this example.)

  set.seed(250) 
  dat &lt;- rlnorm3(20, meanlog = 1.5, sdlog = 1, threshold = 10) 
  elnorm3(dat, method = "mmme", ci = TRUE)

  #Results of Distribution Parameter Estimation
  #--------------------------------------------
  #
  #Assumed Distribution:            3-Parameter Lognormal
  #
  #Estimated Parameter(s):          meanlog   = 1.5206664
  #                                 sdlog     = 0.5330974
  #                                 threshold = 9.6620403
  #
  #Estimation Method:               mmme
  #
  #Data:                            dat
  #
  #Sample Size:                     20
  #
  #Confidence Interval for:         threshold
  #
  #Confidence Interval Method:      Normal Approximation
  #                                 Based on Asymptotic Variance
  #
  #Confidence Interval Type:        two-sided
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             LCL =  6.985258
  #                                 UCL = 12.338823

  #----------

  # Repeat the above example using the other methods of estimation 
  # and compare. 

  round(elnorm3(dat, "lmle")$parameters, 1) 
  #meanlog     sdlog threshold 
  #    1.3       0.7      10.5 
 
  round(elnorm3(dat, "mme")$parameters, 1) 
  #meanlog     sdlog threshold 
  #    2.1       0.3       6.0 
 
  round(elnorm3(dat, "mmue")$parameters, 1) 
  #meanlog     sdlog threshold 
  #    2.2       0.3       5.8 
  
  round(elnorm3(dat, "mmme")$parameters, 1) 
  #meanlog     sdlog threshold 
  #    1.5       0.5       9.7 
  
  round(elnorm3(dat, "zero.skew")$parameters, 1) 
  #meanlog     sdlog threshold 
  #    1.3       0.6      10.3 
 
  round(elnorm3(dat, "royston")$parameters, 1)
  #meanlog     sdlog threshold 
  #    1.4       0.6      10.1 

  #----------

  # Compare methods for computing a two-sided 95% confidence interval 
  # for the threshold: 
  # modified method of moments estimator using asymptotic variance, 
  # lmle using asymptotic variance, 
  # lmle using likelihood profile, and 
  # zero-skewness estimator using the skewness method.

  elnorm3(dat, method = "mmme", ci = TRUE, 
    ci.method = "avar")$interval$limits 
  #      LCL       UCL 
  # 6.985258 12.338823 
 
  elnorm3(dat, method = "lmle", ci = TRUE, 
    ci.method = "avar")$interval$limits 
  #       LCL       UCL 
  #  9.017223 11.980107 
 
  elnorm3(dat, method = "lmle", ci = TRUE, 
    ci.method="likelihood.profile")$interval$limits 
  #      LCL       UCL 
  # 3.699989 11.266029 
 

  elnorm3(dat, method = "zero.skew", ci = TRUE, 
    ci.method = "skewness")$interval$limits 
  #      LCL       UCL 
  #-25.18851  11.18652

  #----------

  # Now construct a confidence interval for the median of the distribution 
  # based on using the modified method of moments estimator for threshold 
  # and the asymptotic variances and covariances.  Note that the true median 
  # is given by threshold + exp(meanlog) = 10 + exp(1.5) = 14.48169.

  elnorm3(dat, method = "mmme", ci = TRUE, ci.parameter = "median") 

  #Results of Distribution Parameter Estimation
  #--------------------------------------------
  #
  #Assumed Distribution:            3-Parameter Lognormal
  #
  #Estimated Parameter(s):          meanlog   = 1.5206664
  #                                 sdlog     = 0.5330974
  #                                 threshold = 9.6620403
  #
  #Estimation Method:               mmme
  #
  #Data:                            dat
  #
  #Sample Size:                     20
  #
  #Confidence Interval for:         median
  #
  #Confidence Interval Method:      Normal Approximation
  #                                 Based on Asymptotic Variance
  #
  #Confidence Interval Type:        two-sided
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             LCL = 11.20541
  #                                 UCL = 17.26922

  #----------

  # Compare methods for computing a two-sided 95% confidence interval 
  # for the median: 
  # modified method of moments estimator using asymptotic variance, 
  # lmle using asymptotic variance, 
  # lmle using likelihood profile, and 
  # zero-skewness estimator using the skewness method.

  elnorm3(dat, method = "mmme", ci = TRUE, ci.parameter = "median", 
    ci.method = "avar")$interval$limits 
  #     LCL      UCL 
  #11.20541 17.26922 
 
  elnorm3(dat, method = "lmle", ci = TRUE, ci.parameter = "median", 
    ci.method = "avar")$interval$limits 
  #     LCL      UCL 
  #12.28326 15.87233 

  elnorm3(dat, method = "lmle", ci = TRUE, ci.parameter = "median", 
    ci.method = "likelihood.profile")$interval$limits 
  #      LCL       UCL 
  # 6.314583 16.165525 

  elnorm3(dat, method = "zero.skew", ci = TRUE, ci.parameter = "median", 
    ci.method = "skewness")$interval$limits 
  #      LCL       UCL 
  #-22.38322  16.33569

  #----------

  # Clean up
  #---------

  rm(dat)

</code></pre>


</div>