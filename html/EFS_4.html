<div class="container">

<table style="width: 100%;"><tr>
<td>ensemble_fs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Ensemble Feature Selection</h2>

<h3>Description</h3>

<p>Uses an ensemble of feature selection methods
to create a normalized quantitative
score of all relevant features. Irrelevant features
(e.g. features with too many missing values or variance = 1) will be deleted. See
Details for a list of tests used in this function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ensemble_fs(data, classnumber, NA_threshold = 0.2, cor_threshold = 0.7,
  runs = 100, selection = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE,
  FALSE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an object of class data.frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classnumber</code></td>
<td>
<p>a number indicating the index of variable for binary classification</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NA_threshold</code></td>
<td>
<p>a number in range of [0,1]. Threshold for deletion
of features with a greater proportion of NAs than <code>NA_threshold</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cor_threshold</code></td>
<td>
<p>a number used only for Spearman and Pearson correlation. Correlation threshold within features.
If the correlation of 2 features is greater than <code>cor_threshold</code> the dependent feature is deleted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runs</code></td>
<td>
<p>a number used only for randomForest and cforest. Amount of runs to gain higher robustness.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selection</code></td>
<td>
<p>a vector of length eight with TRUE or FALSE values. Selection of feature selection methods to be conducted.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Following methods are provided in the <code>ensemble_fs</code>:
</p>

<ul>
<li>
<p> Median: p-values from Wilcoxon signed-rank
test (wilcox.test)
</p>
</li>
<li>
<p> Spearman: Spearman's rank correlation test
arccording to Yu et al. (2004) (cor)
</p>
</li>
<li>
<p> Pearson: Pearson's product moment correlation
test arccording to Yu et al. (2004) (cor)
</p>
</li>
<li>
<p> LogReg: beta-Values of logistic regression
(glm)
</p>
</li>
<li>
<p> Accuracy//Error-rate randomForest: Error-rate-based
variable importance measure embedded in randomForest
according to Breiman (2001) (randomForest)
</p>
</li>
<li>
<p> Gini randomForest: Gini-index-based variable
importance measure embedded in randomForest according
to Breiman (2001) (randomForest)
</p>
</li>
<li>
<p> Error-rate cforest: Error-rate-based variable
importance measure embedded in cforest according
Strobl et al. (2009) (cforest)
</p>
</li>
<li>
<p> AUC cforest: AUC-based variable importance measure
embedded in cforest according to Janitza et al. (2013)
(cforest)</p>
</li>
</ul>
<p>By the argument <code>selection</code> the user decides which feature selection methods are used in <code>ensemble_fs</code>. 
Default value is <code>selection = c(TRUE, TRUE, TRUE,TRUE, TRUE, TRUE, FALSE, FALSE)</code>, 
i.e., the function does not use either of the cforest variable importance measures.
The maximum score for features depends on the input of <code>selection</code>.
The scores are always divided through the amount of selected feature selection, respectively the amount of TRUEs.
</p>


<h3>Value</h3>

<p>table of normalized importance values of class matrix
(used methods as rows and features of the imported file as columns).
</p>


<h3>Author(s)</h3>

<p>Ursula Neumann
</p>


<h3>References</h3>


<ul>
<li>
<p> Yu, L. and Liu H.: Efficient feature selection via
analysis of relevance and redundancy. J. Mach. Learn.
Res. 2004, 5:1205-1224. <br></p>
</li>
<li>
<p> Breiman, L.: Random Forests, Machine Learning.
2001, 45(1): 5-32. <br></p>
</li>
<li>
<p> Strobl, C., Malley, J. anpercentaged Tutz, G.: An
Introduction to Recursive Partitioning: Rationale,
Application, and Characteristics of Classification and
Regression Trees, Bagging, and Random forests.
Psychological Methods. 2009, 14(4), 323â€“348. <br></p>
</li>
<li>
<p>	Janitza, S., Strobl, C. and Boulesteix AL.: An
AUC-based Permutation Variable Importance Measure for
Random Forests. BMC Bioinformatics.2013, 14, 119. <br></p>
</li>
</ul>
<h3>See Also</h3>

<p>wilcox.test,
randomForest,
cforest,
cor,
glm
</p>


<h3>Examples</h3>

<pre><code class="language-R"> ## Loading dataset in environment
 data(efsdata)
 ## Generate a ranking based on importance (with default NA_threshold = 0.2,
 ## cor_threshold = 0.7, selection = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE))
 efs &lt;- ensemble_fs(efsdata, 5, runs=2)
</code></pre>


</div>