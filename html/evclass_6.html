<div class="container">

<table style="width: 100%;"><tr>
<td>EkNNval</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Classification of a test set by the EkNN classifier</h2>

<h3>Description</h3>

<p><code>EkNNval</code> classifies instances in a test set using the EkNN classifier.
</p>


<h3>Usage</h3>

<pre><code class="language-R">EkNNval(xtrain, ytrain, xtst, K, ytst = NULL, param = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xtrain</code></td>
<td>
<p>Matrix of size ntrain x d, containing the values of the d attributes for the
training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ytrain</code></td>
<td>
<p>Vector of class labels for the training data (of length ntrain). May
be a factor, or a vector of integers from 1 to M (number of classes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xtst</code></td>
<td>
<p>Matrix of size ntst x d, containing the values of the d attributes for the
test data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of neighbors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ytst</code></td>
<td>
<p>Vector of class labels for the test data (optional). May
be a factor, or a vector of integers from 1 to M (number of classes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param</code></td>
<td>
<p>Parameters, as returned by <code>EkNNfit</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If class labels for the test set are provided, the test error rate is also returned.
If parameters are not supplied, they are given default values by <code>EkNNinit</code>.
</p>


<h3>Value</h3>

<p>A list with three elements:
</p>

<dl>
<dt>m</dt>
<dd>
<p>Predicted mass functions for the test data. The first M columns correspond
to the mass assigned to each class. The last column corresponds to the mass
assigned to the whole set of classes.</p>
</dd>
<dt>ypred</dt>
<dd>
<p>Predicted class labels for the test data (coded as integers from 1 to M).</p>
</dd>
<dt>err</dt>
<dd>
<p>Test error rate.</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux. A k-nearest neighbor classification rule based on Dempster-Shafer
theory. IEEE Transactions on Systems, Man and Cybernetics, 25(05):804–813, 1995.
</p>
<p>L. M. Zouhal and T. Denoeux. An evidence-theoretic k-NN rule with parameter
optimization. IEEE Transactions on Systems, Man and Cybernetics Part C,
28(2):263–271,1998.
</p>


<h3>See Also</h3>

<p><code>EkNNinit</code>, <code>EkNNfit</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Iris dataset
data(iris)
train&lt;-sample(150,100)
xtrain&lt;-iris[train,1:4]
ytrain&lt;-iris[train,5]
xtst&lt;-iris[-train,1:4]
ytst&lt;-iris[-train,5]
K&lt;-5
fit&lt;-EkNNfit(xtrain,ytrain,K)
test&lt;-EkNNval(xtrain,ytrain,xtst,K,ytst,fit$param)
</code></pre>


</div>