<div class="container">

<table style="width: 100%;"><tr>
<td>simulateMvMatrix</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Simulate a Multivariate Matrix Based on a Specified Rank Correlation Mat
</h2>

<h3>Description</h3>

<p>Simulate a multivariate matrix of random numbers from specified theoretical
probability distributions and/or empirical probability distributions based on
a specified rank correlation matrix, using either Latin Hypercube sampling or
simple random sampling.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  simulateMvMatrix(n, distributions = c(Var.1 = "norm", Var.2 = "norm"),
    param.list = list(Var.1 = list(mean = 0, sd = 1), Var.2 = list(mean = 0, sd = 1)),
    cor.mat = diag(length(distributions)), sample.method = "SRS", seed = NULL,
    left.tail.cutoff = ifelse(is.finite(supp.min), 0, .Machine$double.eps),
    right.tail.cutoff = ifelse(is.finite(supp.max), 0, .Machine$double.eps),
    tol.1 = .Machine$double.eps, tol.symmetry = .Machine$double.eps,
    tol.recip.cond.num = .Machine$double.eps, max.iter = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>

<p>a positive integer indicating the number of random vectors (i.e., the number of
rows of the matrix) to generate.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distributions</code></td>
<td>

<p>a character vector of length <code class="reqn">k</code> denoting the distribution abbreviations for
each of the <code class="reqn">k</code> distributions.  If there is a <code>names</code> attribute associated
with this character vector, these names will be the column names of the resulting
matrix.  The default value of <code>distributions</code> is
<code>c(Var.1="norm", Var.2="norm")</code>, indicating that <code class="reqn">k=2</code>, both
distributions are the normal distribution, and the column names of the
resulting <code class="reqn">n \times k</code> matrix will be <code>"Var.1"</code> and <code>"Var.2"</code>.
See the help file for <code>Distribution.df</code> for a list of possible
distribution abbreviations.
</p>
<p>Alternatively, the character string <code>"emp"</code> may be used to denote sampling
from an empirical distribution based on a set of observations.  The vector
containing the observations is specified in the argument <code>param.list</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param.list</code></td>
<td>

<p>a list containing <code class="reqn">k</code> lists that specify the values for the parameters of
the <code class="reqn">k</code> distributions.  If <code>param.list</code> has a <code>names</code> attribute
(not necessary), the <code>names</code> attribute should be exactly the same as the
<code>names</code> attribute of the argument <code>distributions</code>.  The default value
of <code>param.list</code> is <br><code>list(Var.1=list(mean=0, sd=1), Var.2=list(mean=0, sd=1))</code>.
See the help file for <code>Distribution.df</code> for the names and
possible values of the parameters associated with each distribution.
</p>
<p>Alternatively, if you specify an empirical distribution for the <code class="reqn">j</code>'th
distribution by setting the <code class="reqn">j</code>'th element of <code>distribution</code> to
<code>"emp"</code>, then the <code class="reqn">j</code>'th component of <code>param.list</code> must be a
list of the form <code>list(obs=</code><em>name</em><code>)</code>, where <em>name</em> denotes the
name of the vector containing the observations to use for the empirical
distribution.  In this case, you may also supply arguments to the
<code>qemp</code> function through the <code class="reqn">j</code>'th component of <code>param.list</code>.
For example, you may set this component to
<code>list(obs=</code><em>name</em><code>, discrete=T)</code> to
specify an empirical distribution based on a discrete random variable.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cor.mat</code></td>
<td>

<p>a <code class="reqn">k \times k</code> matrix specifying the rank correlations between the
<code class="reqn">k</code> distributions.  This argument must be a positive definite symmetric
matrix, with all 1's on the diagonal.  All elements on the off-diagonal must be
between -1 and 1. The default value is the <code class="reqn">k \times k</code> identity matrix,
specifying no rank correlation between any of the variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample.method</code></td>
<td>

<p>a character vector of length 1 or <code class="reqn">k</code> indicating, for each distribution,
whether to use Latin Hypercube sampling or simple random sampling.  If
<code>sample.method</code> is of length 1, it is replicated to length <code class="reqn">k</code>.
Each element of <code>sample.method</code> must be the character string
<code>"LHS"</code> (Latin Hypercube sampling) or <code>"SRS"</code> (simple random sampling),
or an abbreviation of one of these strings. The default value is <code>"SRS"</code>,
indicating simple random sampling for each distribution.  Note that by specifying
<code>sample.method</code> as a vector of length <code class="reqn">k</code>, you may use different sampling
methods for different distributions.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>integer to supply to the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> function <code>set.seed</code>.
The default value is <code>seed=NULL</code>, in which case the random seed is
not set but instead based on the current value of <code>.Random.seed</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>left.tail.cutoff</code></td>
<td>

<p>a numeric vector of length <code class="reqn">k</code> indicating, for each distribution,
what proportion of the left-tail of the probability distribution to omit
for Latin Hypercube sampling.  All elements of <code>left.tail.cutoff</code>
must be between 0 and 1.
For densities with a finite support minimum (e.g., Lognormal or
Empirical) the default value is <code>left.tail.cutoff=0</code>;
for densities with a support minimum of <code class="reqn">-\infty</code>, the default value is
<code>left.tail.cutoff=.Machine$double.eps</code>.
The <code class="reqn">j</code>'th element of this argument is ignored if
the <code class="reqn">j</code>'th element of <code>sample.method</code> is equal to <code>"SRS"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>right.tail.cutoff</code></td>
<td>

<p>a numeric vector of length <code class="reqn">k</code> indicating, for each distribution,
what proportion of the right-tail of the probability distribution to omit
for Latin Hypercube sampling.  All elements of <code>right.tail.cutoff</code>
must be between 0 and 1.
For densities with a finite support maximum (e.g., Beta or
Empirical) the default value is <code>right.tail.cutoff=0</code>;
for densities with a support maximum of <code class="reqn">\infty</code>, the default value
is <code>right.tail.cutoff=.Machine$double.eps</code>.
The <code class="reqn">j</code>'th element of this argument is ignored if
the <code class="reqn">j</code>'th element of <code>sample.method</code> is equal to <code>"SRS"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol.1</code></td>
<td>

<p>a positive numeric scalar indicating the allowable absolute deviation
from 1 for the diagonal elements of <code>cor.mat</code>.  The default value
is <code>.Machine$double.eps</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol.symmetry</code></td>
<td>

<p>a positive numeric scalar indicating the allowable absolute deviation from
0 for the difference between symmetric elements of <code>cor.mat</code>
(e.g., <br><code>abs(cor.mat[3,2]-cor.mat[2,3])</code>. The default value is <br><code>.Machine$double.eps</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol.recip.cond.num</code></td>
<td>

<p>a positive numeric scalar indicating the allowable minimum value of the
reciprocal of the condition number for <code>cor.mat</code>.  The condition number
is defined to be the largest eigen value divided by the smallest eigen value.
The reciprocal of the condition number is some number between 0 and 1.
This value must be sufficiently large for <code>cor.mat</code> to be of full rank
(i.e., to not be singular).  The default value of <code>tol.recip.cond.num</code>
is <code>.Machine$double.eps</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>

<p>a positive integer indicating the maximum number of iterations to use to
produce the <code class="reqn">R</code> matrix in the algorithm to create the output matrix.
The sample correlation matrix of <code class="reqn">R</code> must be positive definite.
The number of iterations will rarely be more than 2 for moderate to
large sample sizes (e.g., <code class="reqn">n &gt; 2k</code>).  The default value is
<code>max.iter=10</code>.  See the DETAILS section below for more information on
the <code class="reqn">R</code> matrix.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>Motivation</b> <br>
In risk assessment and Monte Carlo simulation, the outcome variable of interest,
say <code class="reqn">Y</code>, is usually some function of one or more other random variables:
</p>
<p style="text-align: center;"><code class="reqn">Y = h(\underline{X}) = h(X_1, X_2, \ldots, X_k) \;\;\;\;\;\; (1)</code>
</p>

<p>For example, <code class="reqn">Y</code> may be the incremental lifetime cancer risk due to
ingestion of soil contaminated with benzene (Thompson et al., 1992;
Hamed and Bedient, 1997).  In this case the random vector <code class="reqn">\underline{X}</code>
may represent observations from several kinds of distributions that characterize
exposure and dose-response, such as benzene concentration in the soil,
soil ingestion rate, average body weight, the cancer potency factor for benzene,
etc.  These distributions may or may not be assumed to be independent of one
another (Smith et al., 1992; Bukowski et al., 1995).  Often, input variables in a
Monte Carlo simulation are in fact known to be correlated, such as body weight
and dermal area.
</p>
<p>Characterizing the joint distribution of a random vector <code class="reqn">\underline{X}</code>,
where different elements of <code class="reqn">\underline{X}</code> come from different distributions,
is usually mathematically complex or impossible unless the elements
(random variables) of <code class="reqn">\underline{X}</code> are independent.
Iman and Conover (1982) present an algorithm for creating a set of <code class="reqn">n</code>
multivariate observations with a rank correlation matrix that is approximately
equal to a specified rank correlation matrix.  This method allows for different
probability distributions for each element of the multivariate vector.  The
details of this algorithm are as follows.
<br></p>
<p><b>Algorithm</b> <br></p>

<ol>
<li>
<p> Specify <code class="reqn">n</code>, the desired number of random vectors (i.e., number of
rows of the <code class="reqn">n \times k</code> output matrix).  This is specified by the
argument <code>n</code> for the function <code>simulateMvMatrix</code>.
</p>
</li>
<li>
<p> Create <code class="reqn">C</code>, the desired <code class="reqn">k \times k</code> correlation matrix.  This is
specified by the argument <code>cor.mat</code>.
</p>
</li>
<li>
<p> Compute <code class="reqn">P</code>, where <code class="reqn">P</code> is a lower triangular <code class="reqn">k \times k</code>
matrix and
</p>
<p style="text-align: center;"><code class="reqn">PP^{'} = C \;\;\;\;\;\; (2)</code>
</p>

<p>where <code class="reqn">P^{'}</code> denotes the transpose of <code class="reqn">P</code>.  The function
<code>simulateMvMatrix</code> uses the Cholesky decomposition to compute P
(see the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> help file for <code>chol</code>).
</p>
</li>
<li>
<p> Create <code class="reqn">R</code>, an <code class="reqn">n \times k</code> matrix, whose columns represent
<code class="reqn">k</code> independent permutations of van der Waerden scores.  That is, each
column of <code class="reqn">R</code> is a random permutation of the scores
</p>
<p style="text-align: center;"><code class="reqn">\Phi^{-1}(\frac{i}{n+1}), \; i = 1, 2, \ldots, n \;\;\;\;\;\; (3)</code>
</p>

<p>where <code class="reqn">\Phi</code> denotes the cumulative distribution function of the standard
normal distribution.
</p>
</li>
<li>
<p> Compute <code class="reqn">T</code>, the <code class="reqn">k \times k</code> Pearson sample correlation matrix
of <code class="reqn">R</code>.
Make sure <code class="reqn">T</code> is positive definite; if it is not, then repeat step 4.
</p>
</li>
<li>
<p> Compute <code class="reqn">Q</code>, where <code class="reqn">Q</code> is a lower triangular <code class="reqn">k \times k</code>
matrix and
</p>
<p style="text-align: center;"><code class="reqn">QQ^{'} = T \;\;\;\;\;\; (4)</code>
</p>

<p>The function <code>simulateMvMatrix</code> uses the Cholesky decomposition to compute
<code class="reqn">Q</code> (see the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> help file for <code>chol</code>).
</p>
</li>
<li>
<p> Compute the lower triangular <code class="reqn">k \times k</code> matrix <code class="reqn">S</code>, where
</p>
<p style="text-align: center;"><code class="reqn">S = PQ^{-1} \;\;\;\;\;\; (5)</code>
</p>

</li>
<li>
<p> Compute the matrix <code class="reqn">R^{*}</code>, where
</p>
<p style="text-align: center;"><code class="reqn">R^{*} = RS^{'} \;\;\;\;\;\; (6)</code>
</p>

</li>
<li>
<p> Generate an <code class="reqn">n \times k</code> matrix of random numbers <code class="reqn">\underline{X}</code>,
where each column of <code class="reqn">\underline{X}</code> comes from the distribution specified
by the arguments <code>distributions</code> and <code>param.list</code>.  Generate each
column of random numbers independently of the other columns.  If the <code class="reqn">j</code>'th
element of <code>sample.method</code> equals <code>"SRS"</code>, use simple random sampling
to generate the random numbers for the <code class="reqn">j</code>'th column of <code class="reqn">\underline{X}</code>.
If the <code class="reqn">j</code>'th element of <code>sample.method</code> equals <code>"LHS"</code>, use
Latin Hypercube sampling to generate the random numbers for the <code class="reqn">j</code>'th column
of <code class="reqn">\underline{X}</code>.  At this stage in the algorithm, the function
<code>simulateMvMatrix</code> calls the function <code>simulateVector</code> to
create each column of <code class="reqn">\underline{X}</code>.
</p>
</li>
<li>
<p> Order the observations within each column of <code class="reqn">\underline{X}</code> so that
the order of the ranks within each column of <code class="reqn">\underline{X}</code> matches the
order of the ranks within each column of <code class="reqn">R^{*}</code>.  This way, <code class="reqn">\underline{X}</code>
and <code class="reqn">R^{*}</code> have exactly the same sample rank correlation matrix.
</p>
</li>
</ol>
<p><b>Explanation</b> <br>
Iman and Conover (1982) present two algorithms for computing an <code class="reqn">n \times k</code>
output matrix with a specified rank correlation.  The algorithm presented above is
the second, more complicated one.  In order to explain the reasoning behind this
algorithm, we need to explain the simple algorithm first.
<br></p>
<p><em>Simple Algorithm</em> <br>
Let <code class="reqn">R_i</code> denote the <code class="reqn">i</code>'th row vector of the matrix <code class="reqn">R</code>, the
matrix of scores.  This row vector has a population correlation matrix of <code class="reqn">I</code>,
where <code class="reqn">I</code> denotes the <code class="reqn">k \times k</code> identity matrix.  Thus, the
<code class="reqn">1 \times k</code> vector <code class="reqn">R_i P^{'}</code> has a population correlation matrix equal to
<code class="reqn">C</code>. Therefore, if we define <code class="reqn">R^{*}</code> by
</p>
<p style="text-align: center;"><code class="reqn">R^{*} = RP^{'} \;\;\;\;\;\; (7)</code>
</p>

<p>each row of <code class="reqn">R^{*}</code> has the same multivariate distribution with population
correlation matrix <code class="reqn">C</code>.  The rank correlation matrix of <code class="reqn">R^{*}</code> should
therefore be close to <code class="reqn">C</code>.  Ordering the columns of <code class="reqn">\underline{X}</code> as
described in Step 10 above will yield a matrix of observations with the
specified distributions and the exact same rank correlation matrix as the
rank correlation matrix of <code class="reqn">R^{*}</code>.
</p>
<p>Iman and Conover (1982) use van der Waerden scores instead of raw ranks to create
<code class="reqn">R</code> because van der Waerden scores yield more "natural-looking" pairwise
scatterplots.
</p>
<p>If the Pearson sample correlation matrix of <code class="reqn">R</code>, denoted <code class="reqn">T</code> in Step 5
above, is exactly equal to the true population correlation matrix <code class="reqn">I</code>,
then the sample correlation matrix of <code class="reqn">R^{*}</code> is exactly equal to <code class="reqn">C</code>,
and the rank correlation matrix of <code class="reqn">R^{*}</code> is approximately equal to <code class="reqn">C</code>.
The Pearson sample correlation matrix of <code class="reqn">R</code>, however, is an estimate of the
true population correlation matrix <code class="reqn">I</code>, and is therefore
“bouncing around” <code class="reqn">I</code>.  Likewise, the Pearson sample correlation matrix
of <code class="reqn">R^{*}</code> is an estimate of the true population correlation matrix <code class="reqn">C</code>,
and is therefore bouncing around <code class="reqn">C</code>.  Using this simple algorithm, the
Pearson sample correlation matrix of <code class="reqn">R^{*}</code>, as <code class="reqn">R^{*}</code> is defined in
Equation (7) above, may not be “close” enough to the desired rank
correlation matrix <code class="reqn">C</code>, and thus the rank correlation of <code class="reqn">R^{*}</code> will not
be close enough to <code class="reqn">C</code>.  Iman and Conover (1982), therefore present a more
complicated algorithm.
<br></p>
<p><em>More Complicated Algorithm</em> <br>
To get around the problem mentioned above, Iman and Conover (1982) find a
<code class="reqn">k \times k</code> lower triangular matrix <code class="reqn">S</code> such that the matrix <code class="reqn">R^{*}</code>
as defined in Equation (6) above has a correlation matrix exactly equal to <code class="reqn">C</code>.
The formula for <code class="reqn">S</code> is given in Steps 6 and 7 of the algorithm above.
</p>
<p>Iman and Conover (1982, p.330) note that even if the desired rank correlation matrix
<code class="reqn">C</code> is in fact the identity matrix <code class="reqn">I</code>, this method of generating the
matrix will produce a matrix with an associated rank correlation that more closely
resembles <code class="reqn">I</code> than you would get by simply generating random numbers within
each column of <code class="reqn">\underline{X}</code>.
</p>


<h3>Value</h3>

<p>A numeric matrix of dimension <code class="reqn">n \times k</code> of random numbers,
where the <code class="reqn">j</code>'th column of numbers comes from the distribution
specified by the <code class="reqn">j</code>'th elements of the arguments <code>distributions</code>
and <code>param.list</code>, and the rank correlation of this matrix is
approximately equal to the argument <code>cor.mat</code>.  The value of <code class="reqn">n</code>
is determined by the argument <code>n</code>, and the value of <code class="reqn">k</code> is
determined by the length of the argument <code>distributions</code>.
</p>


<h3>Note</h3>

<p>Monte Carlo simulation and risk assessment often involve looking at the
distribution or characteristics of the distribution of some outcome variable
that depends upon several input variables (see Equation (1) above).  Usually
these input variables can be considered random variables.  An important part
of both sensitivity analysis and uncertainty analysis involves looking at how
the distribution of the outcome variable changes with changing assumptions on
the input variables.  One important assumption is the correlation between the
input random variables.
</p>
<p>Often, the input random variables are assumed to be independent when in fact they
are know to be correlated (Smith et al., 1992; Bukowski et al., 1995).  It is
therefore important to assess the effect of the assumption of independence on the
distribution of the outcome variable.  One way to assess the effect of this
assumption is to run the Monte Carlo simulation assuming independence and then
also run it assuming certain forms of correlations among the input variables.
</p>
<p>Iman and Davenport (1982) present a series of scatterplots showing “typical”
scatterplots with various distributions on the <code class="reqn">x</code>- and <code class="reqn">y</code>-axes and
various assumed rank correlations.  These plots are meant to aid in developing
reasonable estimates of rank correlation between input variables.  These plots can
easily be produced using the <code>simulateMvMatrix</code> and <code>plot</code> functions.
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Bukowski, J., L. Korn, and D. Wartenberg. (1995).
Correlated Inputs in Quantitative Risk Assessment: The Effects of Distributional
Shape.  <em>Risk Analysis</em> <b>15</b>(2), 215–219.
</p>
<p>Hamed, M., and P.B. Bedient. (1997).  On the Effect of Probability Distributions
of Input Variables in Public Health Risk Assessment.  <em>Risk Analysis</em>
<b>17</b>(1), 97–105.
</p>
<p>Iman, R.L., and W.J. Conover. (1980).  Small Sample Sensitivity Analysis
Techniques for Computer Models, With an Application to Risk Assessment
(with Comments).  <em>Communications in Statistics–Volume A, Theory and Methods</em>,
<b>9</b>(17), 1749–1874.
</p>
<p>Iman, R.L., and W.J. Conover. (1982).  A Distribution-Free Approach to Inducing
Rank Correlation Among Input Variables.
<em>Communications in Statistics–Volume B, Simulation and Computation</em>,
<b>11</b>(3), 311–334.
</p>
<p>Iman, R.L., and J.M. Davenport. (1982).  Rank Correlation Plots For Use With
Correlated Input Variables.
<em>Communications in Statistics–Volume B, Simulation and Computation</em>,
<b>11</b>(3), 335–360.
</p>
<p>Iman, R.L., and J.C. Helton. (1988).  An Investigation of Uncertainty and
Sensitivity Analysis Techniques for Computer Models.  <em>Risk Analysis</em>
<b>8</b>(1), 71–90.
</p>
<p>Iman, R.L. and J.C. Helton. (1991).  The Repeatability of Uncertainty and
Sensitivity Analyses for Complex Probabilistic Risk Assessments.
<em>Risk Analysis</em> <b>11</b>(4), 591–606.
</p>
<p>McKay, M.D., R.J. Beckman., and W.J. Conover. (1979).  A Comparison of Three
Methods for Selecting Values of Input Variables in the Analysis of Output
From a Computer Code.  <em>Technometrics</em> <b>21</b>(2), 239–245.
</p>
<p>Millard, S.P. (2013).  <em>EnvStats: an R Package for Environmental Statistics</em>.
Springer, New York.  <a href="https://link.springer.com/book/10.1007/978-1-4614-8456-1">https://link.springer.com/book/10.1007/978-1-4614-8456-1</a>.
</p>
<p>Smith, A.E., P.B. Ryan, and J.S. Evans. (1992).  The Effect of Neglecting
Correlations When Propagating Uncertainty and Estimating the Population
Distribution of Risk.  <em>Risk Analysis</em> <b>12</b>(4), 467–474.
</p>
<p>Thompson, K.M., D.E. Burmaster, and E.A.C. Crouch. (1992).  Monte Carlo Techniques
for Quantitative Uncertainty Analysis in Public Health Risk Assessments.
<em>Risk Analysis</em> <b>12</b>(1), 53–63.
</p>
<p>Vose, D. (2008).  <em>Risk Analysis:  A Quantitative Guide</em>.  Third Edition.
John Wiley &amp; Sons, West Sussex, UK, 752 pp.
</p>


<h3>See Also</h3>

<p>Probability Distributions and Random Numbers, Empirical,
<code>simulateVector</code>, <code>cor</code>, <code>set.seed</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Generate 5 observations from a standard bivariate normal distribution
  # with a rank correlation matrix (approximately) equal to the 2 x 2
  # identity matrix, using simple random sampling for each
  # marginal distribution.

  simulateMvMatrix(5, seed = 47)
  #           Var.1       Var.2
  #[1,]  0.01513086  0.03960243
  #[2,] -1.08573747  0.09147291
  #[3,] -0.98548216  0.49382018
  #[4,] -0.25204590 -0.92245624
  #[5,] -1.46575030 -1.82822917

  #==========

  # Look at the observed rank correlation matrix for 100 observations
  # from a standard bivariate normal distribution with a rank correlation matrix
  # (approximately) equal to the 2 x 2 identity matrix. Compare this observed
  # rank correlation matrix with the observed rank correlation matrix based on
  # generating two independent sets of standard normal random numbers.
  # Note that the cross-correlation is closer to 0 for the matrix created with
  # simulateMvMatrix.

  cor(simulateMvMatrix(100, seed = 47), method = "spearman")
  #             Var.1        Var.2
  #Var.1  1.000000000 -0.005976598
  #Var.2 -0.005976598  1.000000000

  cor(matrix(simulateVector(200, seed = 47), 100 , 2), method = "spearman")
  #            [,1]        [,2]
  #[1,]  1.00000000 -0.05374137
  #[2,] -0.05374137  1.00000000

  #==========

  # Generate 1000 observations from a bivariate distribution, where the first
  # distribution is a normal distribution with parameters mean=10 and sd=2,
  # the second distribution is a lognormal distribution with parameters
  # mean=10 and cv=1, and the desired rank correlation between the two
  # distributions is 0.8.  Look at the observed rank correlation matrix, and
  # plot the results.

  mat &lt;- simulateMvMatrix(1000,
    distributions = c(N.10.2 = "norm", LN.10.1 = "lnormAlt"),
    param.list = list(N.10.2  = list(mean=10, sd=2),
                      LN.10.1 = list(mean=10, cv=1)),
    cor.mat = matrix(c(1, .8, .8, 1), 2, 2), seed = 47)

  round(cor(mat, method = "spearman"), 2)
  #        N.10.2 LN.10.1
  #N.10.2    1.00    0.78
  #LN.10.1   0.78    1.00

  dev.new()
  plot(mat, xlab = "Observations from N(10, 2)",
    ylab = "Observations from LN(mean=10, cv=1)",
    main = "Lognormal vs. Normal Deviates with Rank Correlation 0.8")

  #----------

  # Repeat the last example, but use Latin Hypercube sampling for both
  # distributions. Note the wider range on the y-axis.

  mat.LHS &lt;- simulateMvMatrix(1000,
    distributions = c(N.10.2 = "norm", LN.10.1 = "lnormAlt"),
    param.list = list(N.10.2  = list(mean=10, sd=2),
                      LN.10.1 = list(mean=10, cv=1)),
    cor.mat = matrix(c(1, .8, .8, 1), 2, 2),
    sample.method = "LHS", seed = 298)

  round(cor(mat.LHS, method = "spearman"), 2)
  #        N.10.2 LN.10.1
  #N.10.2    1.00    0.79
  #LN.10.1   0.79    1.00

  dev.new()
  plot(mat.LHS, xlab = "Observations from N(10, 2)",
    ylab = "Observations from LN(mean=10, cv=1)",
    main = paste("Lognormal vs. Normal Deviates with Rank Correlation 0.8",
      "(Latin Hypercube Sampling)", sep = "\n"))

  #==========

  # Generate 1000 observations from a multivariate distribution, where the
  # first distribution is a normal distribution with parameters
  # mean=10 and sd=2, the second distribution is a lognormal distribution
  # with parameters mean=10 and cv=1, the third distribution is a beta
  # distribution with parameters shape1=2 and shape2=3, and the fourth
  # distribution is an empirical distribution of 100 observations that
  # we'll generate from a Pareto distribution with parameters
  # location=10 and shape=2. Set the desired rank correlation matrix to:

  cor.mat &lt;- matrix(c(1, .8, 0, .5, .8, 1, 0, .7,
    0, 0, 1, .2, .5, .7, .2, 1), 4, 4)

  cor.mat
  #     [,1] [,2] [,3] [,4]
  #[1,]  1.0  0.8  0.0  0.5
  #[2,]  0.8  1.0  0.0  0.7
  #[3,]  0.0  0.0  1.0  0.2
  #[4,]  0.5  0.7  0.2  1.0

  # Use Latin Hypercube sampling for each variable, look at the observed
  # rank correlation matrix, and plot the results.

  pareto.rns &lt;- simulateVector(100, "pareto",
    list(location = 10, shape = 2), sample.method = "LHS",
    seed = 56)

  mat &lt;- simulateMvMatrix(1000,
    distributions = c(Normal = "norm", Lognormal = "lnormAlt",
      Beta = "beta", Empirical = "emp"),
    param.list = list(Normal = list(mean=10, sd=2),
                      Lognormal = list(mean=10, cv=1),
                      Beta = list(shape1 = 2, shape2 = 3),
                      Empirical = list(obs = pareto.rns)),
    cor.mat = cor.mat, seed = 47, sample.method = "LHS")

  round(cor(mat, method = "spearman"), 2)
  #          Normal Lognormal  Beta Empirical
  #Normal      1.00      0.78 -0.01      0.47
  #Lognormal   0.78      1.00 -0.01      0.67
  #Beta       -0.01     -0.01  1.00      0.19
  #Empirical   0.47      0.67  0.19      1.00

  dev.new()
  pairs(mat)

  #==========

  # Clean up
  #---------
  rm(mat, mat.LHS, pareto.rns)
  graphics.off()
</code></pre>


</div>