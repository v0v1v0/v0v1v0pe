<div class="container">

<table style="width: 100%;"><tr>
<td>plot_Kblist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Plot sequences of Kullback distance estimates for comparison of several MCMC algorithms for a same target density
</h2>

<h3>Description</h3>

<p>This  function draws on a same plot several sequences of estimates of 
Kullback distances <code class="reqn">K(p^t,f)</code>, i.e. the convergence criterion vs. time (iteration <code class="reqn">t</code>), 
for each MCMC algorithm for which the convergence criterion has been computed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">plot_Kblist(Kb, which = 1, lim = NULL, ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Kb</code></td>
<td>
<p>A list of objects of class <code>"KbMCMC"</code>, such as the ones returned by
<code>EntropyMCMC</code> or <code>EntropyParallel</code>, or their HPC versions. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which</code></td>
<td>
<p>Controls the level of details in the legend  added to the plot (see details)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lim</code></td>
<td>
<p>for zooming over <code>1:lim</code> iterations only. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylim</code></td>
<td>
<p>limits on the <code class="reqn">y</code> axis for zooming, passed to <code>plot</code>. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The purpose of this plot if to compare <code class="reqn">K</code> MCMC algorithms (typically based on <code class="reqn">K</code> different 
simulation strategies or kernels) for convergence or efficiency in estimating a same target density <code class="reqn">f</code>. 
For the <code class="reqn">k</code>th algorithm, the user has to generate the convergence criterion,
i.e. the sequence  <code class="reqn">K(p^t(_k)k), f)</code> for <code class="reqn">t=1</code> up to the number of iterations 
that has been chosen, and where <code class="reqn">p^t(k)</code> is  the estimated pdf of the algorithm at time <code class="reqn">t</code>.
</p>
<p>For the legend, <code>which=1</code> displays the MCMC's names together with some technical information depending on the algorithms definition (e.g. the proposal variance for the <code>RWHM</code> algorithm) and the 
method used for entropy estimation. The legend for
<code>which=2</code> is shorter, only displaying the MCMC's names together with the number of parallel chains used for each, 
typically to compare the effect of that number for a single MCMC algorithm.
</p>


<h3>Value</h3>

<p>The graphic to plot.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li>
<p> Chauveau, D. and Vandekerkhove, P. (2012), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, (2013) 419–431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816–2827.
</p>
</li>
<li>
<p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>EntropyMCMC</code>, <code>EntropyMCMC.mc</code></p>


<h3>Examples</h3>

<pre><code class="language-R">
## Toy example using the bivariate centered gaussian target
## with default parameters value, see target_norm_param
d = 2           # state space dimension
n=300; nmc=100  # number of iterations and iid Markov chains
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 

## MCMC 1: Random-Walk Hasting-Metropolis
varq=0.05 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))

## using Method 1: simulation with storage, and *then* entropy estimation
# simulation of the nmc iid chains, single core here
s1 &lt;- MCMCcopies(RWHM, n, nmc, Ptheta0, target_norm,
                 target_norm_param, q_param)
summary(s1) # method for "plMCMC" object
e1 &lt;- EntropyMCMC(s1) # computes Entropy and Kullback divergence

## MCMC 2: Independence Sampler with large enough gaussian proposal
varq=1; q_param &lt;- list(mean=rep(0,d),v=varq*diag(d))

## using Method 2: simulation &amp; estimation for each t, forgetting the past
## HPC with 2 cores here (using parallel socket cluser, not available on Windows machines)
e2 &lt;- EntropyParallel.cl(HMIS_norm, n, nmc, Ptheta0, target_norm,
                      target_norm_param, q_param, 
                      cltype="PAR_SOCK", nbnodes=2)

## Compare these two MCMC algorithms
plot_Kblist(list(e1,e2)) # MCMC 2 (HMIS, red plot) converges faster.
  
</code></pre>


</div>