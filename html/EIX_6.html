<div class="container">

<table style="width: 100%;"><tr>
<td>lollipop</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tables needed for lollipop plot</h2>

<h3>Description</h3>

<p>This function calculates two tables needed to generate lollipop plot, which visualise the model.
The first table contains information about all nodes in the trees forming a model.
It includes gain value, depth and ID of each nodes.
The second table contains similarly information about roots in the trees.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lollipop(xgb_model, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xgb_model</code></td>
<td>
<p>a xgboost or lightgbm model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data table with data used to train the model.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>an object of the lollipop class
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("EIX")
library("Matrix")
sm &lt;- sparse.model.matrix(left ~ . - 1,  data = HR_data)

library("xgboost")
param &lt;- list(objective = "binary:logistic", max_depth = 2)
xgb_model &lt;- xgboost(sm, params = param, label = HR_data[, left] == 1, nrounds = 25, verbose = 0)

lolli &lt;- lollipop(xgb_model, sm)
plot(lolli, labels = "topAll", log_scale = TRUE)


library(lightgbm)
train_data &lt;- lgb.Dataset(sm, label =  HR_data[, left] == 1)
params &lt;- list(objective = "binary", max_depth = 2)
lgb_model &lt;- lgb.train(params, train_data, 25)

lolli &lt;- lollipop(lgb_model, sm)
plot(lolli, labels = "topAll", log_scale = TRUE)



</code></pre>


</div>