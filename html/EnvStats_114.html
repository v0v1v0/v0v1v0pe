<div class="container">

<table style="width: 100%;"><tr>
<td>enparCensored</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimate Mean, Standard Deviation, and Standard Error Nonparametrically Based on Censored Data
</h2>

<h3>Description</h3>

<p>Estimate the mean, standard deviation, and standard error of the mean
nonparametrically given a sample of data from a positive-valued distribution
that has been subjected to left- or right-censoring, and optionally construct
a confidence interval for the mean.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  enparCensored(x, censored, censoring.side = "left", correct.se = TRUE, 
    restricted = FALSE, left.censored.min = "Censoring Level", 
    right.censored.max = "Censoring Level", ci = FALSE, 
    ci.method = "normal.approx", ci.type = "two-sided", conf.level = 0.95, 
    pivot.statistic = "t", ci.sample.size = "Total", n.bootstraps = 1000, 
    seed = NULL, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>numeric vector of positive-valued observations.
Missing (<code>NA</code>), undefined (<code>NaN</code>), and
infinite (<code>Inf</code>, <code>-Inf</code>) values are allowed but will be removed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>censored</code></td>
<td>

<p>numeric or logical vector indicating which values of <code>x</code> are censored.
This must be the same length as <code>x</code>.  If the mode of <code>censored</code> is
<code>"logical"</code>, <code>TRUE</code> values correspond to elements of <code>x</code> that
are censored, and <code>FALSE</code> values correspond to elements of <code>x</code> that
are not censored.  If the mode of <code>censored</code> is <code>"numeric"</code>,
it must contain only <code>1</code>'s and <code>0</code>'s; <code>1</code> corresponds to
<code>TRUE</code> and <code>0</code> corresponds to <code>FALSE</code>.  Missing (<code>NA</code>)
values are allowed but will be removed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>censoring.side</code></td>
<td>

<p>character string indicating on which side the censoring occurs.  The possible
values are <code>"left"</code> (the default) and <code>"right"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>correct.se</code></td>
<td>

<p>logical scalar indicating whether to multiply the estimated standard error
by a factor to correct for bias.  The default value is <code>correct.se=TRUE</code>.
See the DETAILS section below.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>restricted</code></td>
<td>

<p>logical scalar indicating whether to compute the restricted mean in the case when 
the smallest censored value is less than or equal to the smallest uncensored value 
(left-censored data) or the largest censored value is greater than or equal to the 
largest uncensored value (right-censored data).  The default value is 
<code>restricted=FALSE</code>.  See the DETAILS section for more information.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>left.censored.min</code></td>
<td>

<p>Only relevant for the case when <code>censoring.side="left"</code>, the smallest
censored value is less than or equal to the smallest uncensored value, and <br><code>restricted=TRUE</code>.  In this case, <code>left.censored.min</code> must be the 
character string <code>"Censoring Level"</code>, or else a numeric scalar between 
0 and the smallest censored value.  The default value is 
<code>left.censored.min="Censoring Level"</code>.
See the DETAILS section for more information.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>right.censored.max</code></td>
<td>

<p>Only relevant for the case when <code>censoring.side="right"</code>, the largest
censored value is greater than or equal to the largest uncensored value, and <br><code>restricted=TRUE</code>.  In this case, <code>right.censored.max</code> must be the 
character string <code>"Censoring Level"</code>, or else a numeric scalar greater 
than or equal to the largest censored value. The default value is 
<code>right.censored.max="Censoring Level"</code>. 
See the DETAILS section for more information.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>

<p>logical scalar indicating whether to compute a confidence interval for the
mean or variance.  The default value is <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.method</code></td>
<td>

<p>character string indicating what method to use to construct the confidence interval
for the mean.  The possible values are
<code>"normal.approx"</code> (normal approximation; the default), and
<code>"bootstrap"</code> (based on bootstrapping).
See the <b>DETAILS</b> section for more information.
This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.type</code></td>
<td>

<p>character string indicating what kind of confidence interval to compute.  The
possible values are <code>"two-sided"</code> (the default), <code>"lower"</code>, and
<code>"upper"</code>.  This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>

<p>a scalar between 0 and 1 indicating the confidence level of the confidence interval.
The default value is <code>conf.level=0.95</code>. This argument is ignored if
<code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pivot.statistic</code></td>
<td>

<p>character string indicating which statistic to use for the confidence interval
for the mean when <code>ci.method="normal.approx"</code>.  Possible values are
<code>"t"</code> (confidence interval based on the t-statistic; the default), and 
<code>"z"</code> (confidence interval based on the z-statistic).  When 
<code>pivot.statistic="t"</code> you may supply the argument <code>ci.sample size</code> 
(see below).  This argument is ignored if <code>ci=FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci.sample.size</code></td>
<td>

<p>character string indicating what sample size to assume when
computing the confidence interval for the mean when <code>ci.method="normal.approx"</code> <br>
and <code>pivot.statistic="t"</code>.  Possible values are <code>ci.sample.size="Total"</code> 
(the total number of observations; the default), and <br><code>ci.sample.size="Uncensored"</code> (the number of uncensored observations). 
This argument is ignored if <code>ci=FALSE</code>, <code>ci.method="bootstrap"</code>, 
or <code>pivot.statistic="z"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.bootstraps</code></td>
<td>

<p>numeric scalar indicating how many bootstraps to use to construct the
confidence interval for the mean when <code>ci.type="bootstrap"</code>.  This
argument is ignored if <code>ci=FALSE</code> or <code>ci.method="normal.approx"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>integer supplied to the function <code>set.seed</code> and used when 
<code>ci=TRUE</code> and <br><code>ci.method="bootstrap"</code>.  The default value is
<code>seed=NULL</code>, in which case the current value of <code>.Random.seed</code> is used.
This argument is ignored if <code>ci=FALSE</code> or <code>ci.method="normal.approx"</code>.  
The <code>seed</code> argument is necessary in order to create reproducible results for 
the bootstrapped confidence intervals (see the <b>EXAMPLES</b> section).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>

<p>logical scalar indicating whether to issue a notification in the case when a 
restricted mean will be estimated, but setting the smallest censored value(s) 
to an uncensored value (left-censored data) or setting the largest censored 
value(s) to an uncensored value (right-censored data) results in no censored 
values in the data.  In this case, the function <code>enpar</code> 
is called.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Let <code class="reqn">\underline{x} = (x_1, x_2, \ldots, x_N)</code> denote a vector of <code class="reqn">N</code>
observations from some positive-valued distribution with mean
<code class="reqn">\mu</code> and standard deviation <code class="reqn">\sigma</code>.
Assume <code class="reqn">n</code> (<code class="reqn">0 &lt; n &lt; N</code>) of these
observations are known and <code class="reqn">c</code> (<code class="reqn">c=N-n</code>) of these observations are
all censored below (left-censored) or all censored above (right-censored) at
<code class="reqn">k</code> censoring levels
</p>
<p style="text-align: center;"><code class="reqn">T_1, T_2, \ldots, T_k; \; k \ge 1 \;\;\;\;\;\; (1)</code>
</p>

<p>Let <code class="reqn">y_1, y_2, \ldots, y_n</code> denote the <code class="reqn">n</code> ordered uncensored
observations, and let <code class="reqn">r_1, r_2, \ldots, r_n</code> denote the order of these 
uncensored observations within the context of all the observations (censored and 
uncensored).  For example, if the left-censored data are {&lt;10, 14, 14, &lt;15, 20}, then 
<code class="reqn">y_1 = 14, y_2 = 14, y_3 = 20</code>, and <code class="reqn">r_1 = 2, r_2 = 3, r_3 = 5</code>.  
</p>
<p>Let <code class="reqn">y_1', y_2', \ldots, y_p'</code> denote the <code class="reqn">p</code> ordered <em>distinct</em> 
uncensored observations, let <code class="reqn">m_j</code> denote the number of detects at 
<code class="reqn">y_j'</code> (<code class="reqn">j = 1, 2, \ldots, p</code>), and let <code class="reqn">r_j'</code> denote the number of 
<code class="reqn">x_i \le y_j'</code>, i.e., the number of observations (censored and uncensored) 
less than or equal to <code class="reqn">y_j'</code> (<code class="reqn">j = 1, 2, \ldots, p</code>).  For example, 
if the left-censored data are {&lt;10, 14, 14, &lt;15, 20}, then 
<code class="reqn">y_1' = 14, y_2' = 20</code>, <code class="reqn">m_1 = 2, m_2 = 1</code>, and <code class="reqn">r_1' = 3, r_2' = 5</code>.
<br></p>
<p><b>Estimation</b> <br>
This section explains how the mean <code class="reqn">\mu</code>, standard deviation <code class="reqn">\sigma</code>, 
and standard error of the mean <code class="reqn">\hat{\sigma}_{\hat{\mu}}</code> are estimated, as well as 
the restricted mean.
<br></p>
<p><em>Estimating the Mean</em> <br>
It can be shown that the mean of a positive-valued distribution is equal to the
area under the survival curve (Klein and Moeschberger, 2003, p.33):
</p>
<p style="text-align: center;"><code class="reqn">\mu = \int_0^\infty [1 - F(t)] dt = \int_0^\infty S(t) dt \;\;\;\;\;\; (2)</code>
</p>

<p>where <code class="reqn">F(t)</code> denotes the cumulative distribution function evaluated at <code class="reqn">t</code>
and <code class="reqn">S(t) = 1 - F(t)</code> denotes the survival function evaluated at <code class="reqn">t</code>.
When the Kaplan-Meier estimator is used to construct the survival function,
you can use the area under this curve to estimate the mean of the distribution,
and the estimator can be as efficient or more efficient than
parametric estimators of the mean (Meier, 2004; Helsel, 2012; Lee and Wang, 2003).
Let <code class="reqn">\hat{F}(t)</code> denote the Kaplan-Meier estimator of the empirical
cumulative distribution function (ecdf) evaluated at <code class="reqn">t</code>, and let
<code class="reqn">\hat{S}(t) = 1 - \hat{F}(t)</code> denote the estimated survival function evaluated
at <code class="reqn">t</code>.  (See the help files for <code>ecdfPlotCensored</code> and
<code>qqPlotCensored</code> for an explanation of how the Kaplan-Meier
estimator of the ecdf is computed.)
</p>
<p>The formula for the estimated mean is given by (Lee and Wang, 2003, p. 74):
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu} = \sum_{i=1}^{n} \hat{S}(y_{i-1}) (y_{i} - y_{i-1}) \;\;\;\;\;\; (3)</code>
</p>

<p>where <code class="reqn">y_{0} = 0</code> and <code class="reqn">\hat{S}(y_{0}) = 1</code> by definition.  It can be
shown that this formula is eqivalent to:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu} = \sum_{i=1}^n y_{i} [\hat{F}(y_{i}) - \hat{F}(y_{i-1})] \;\;\;\;\;\; (4)</code>
</p>

<p>where <code class="reqn">\hat{F}(y_{0}) = \hat{F}(0) = 0</code> by definition, and this is equivalent to:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu} = \sum_{i=1}^p y_i' [\hat{F}(y_i') - \hat{F}(y_{i-1}')] \;\;\;\;\;\; (5)</code>
</p>

<p>(USEPA, 2009, pp. 15–7 to 15–12; Beal, 2010; USEPA, 2022, pp. 128–129).
<br></p>
<p><em>Estimating the Standard Deviation</em> <br>
The formula for the estimated standard deviation is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma} = \{\sum_{i=1}^n (y_{i} - \hat{\mu})^2 [\hat{F}(y_{i}) - \hat{F}(y_{i-1})]\}^{1/2} \;\;\;\;\; (6)</code>
</p>

<p>which is equivalent to:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma} = \{\sum_{i=1}^p (y_i' - \hat{\mu})^2 [\hat{F}(y_i') - \hat{F}(y_{i-1}')]\}^{1/2} \;\;\;\;\; (7)</code>
</p>

<p>(USEPA, 2009, p. 15-10; Beal, 2010).
<br></p>
<p><em>Estimating the Standard Error of the Mean</em> <br>
For left-censored data, the formula for the estimated standard error of the
mean is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}_{\hat{\mu}} = [\sum_{i=j}^{p-1} A_j^2 \frac{m_{j+1}}{r_{j+1}'(r_{j+1}' - m_{j+1})}]^{1/2} \;\;\;\;\;\; (8)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">A_j = \sum_{i=1}^{j} (y_{i+1}' - y_i') \hat{F}(y_i') \;\;\;\;\;\; (9)</code>
</p>

<p>(Beal, 2010; USEPA, 2022, pp. 128–129).
</p>
<p>For rigth-censored data, the formula for the estimated standard error of the
mean is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}_{\hat{\mu}} = [\sum_{r=1}^{n-1} \frac{A_r^2}{(N-r)(N-r+1)}]^{1/2} \;\;\;\;\;\; (10)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">A_r = \sum_{i=r}^{n-1} (y_{i+1} - y_{i}) \hat{S}(y_{i}) \;\;\;\;\;\; (11)</code>
</p>

<p>(Lee and Wang, 2003, p. 74).  
</p>
<p>Kaplan and Meier suggest using a bias correction of
<code class="reqn">n/(n-1)</code> for the estimated variance of the mean (Lee and Wang, 2003, p.75):
</p>
<p style="text-align: center;"><code class="reqn">\hat{\sigma}_{\hat{\mu}, BC} = \sqrt{\frac{n}{n-1}} \;\; \hat{\sigma}_{\hat{\mu}} \;\;\;\;\;\; (12)</code>
</p>

<p>When <code>correct.se=TRUE</code> (the default), Equation (12) is used.  Beal (2010), 
ProUCL 5.2.0 (USEPA, 2022), and the <code>kmms</code> function in the <b>STAND</b> package 
(Frome and Frome, 2015) all compute the bias-corrected estimate of the standard 
error of the mean as well.
<br></p>
<p><em>Estimating the Restricted Mean</em> <br>
If the smallest value for left-censored data is censored and less than or equal to 
the smallest uncensored value, then the estimated mean will be biased high, and
if the largest value for right-censored data is censored and greater than or equal to
the largest uncensored value, then the estimated mean will be biased low.  One solution 
to this problem is to instead estimate what is called the <b><em>restricted mean</em></b> 
(Miller, 1981; Lee and Wang, 2003, p. 74; Meier, 2004; Barker, 2009).
</p>
<p>To compute the restricted mean (<code>restricted=TRUE</code>), for left-censored data, 
the smallest censored observation(s) are treated as observed, and set to the 
smallest censoring level <br>
(<code>left.censored.min="Censoring Level"</code>) or some other
value less than the smallest censoring level and greater than 0, and then applying 
the above formulas.  To compute the restricted mean for right-censored data, 
the largest censored observation(s) are treated as observed and set to the 
censoring level (<code>right.censored.max="Censoring Level"</code>) or some value 
greater than the largest censoring level.
</p>
<p>ProUCL 5.2.0 (USEPA, 2022, pp. 128–129) and Beal (2010) do not compute the restricted 
mean in cases where it could be applied, whereas USEPA (2009, pp. 15–7 to 15–12) and 
the <code>kmms</code> function in Version 2.0 of the R package <b>STAND</b> 
(Frome and Frome, 2015) do compute the restricted mean and set the smallest 
censored observation(s) equal to the censoring level (i.e., what 
<code>enparCensored</code> does when <code>restricted=TRUE</code> and 
<code>left.censored.min="Censoring Level"</code>). 
</p>
<p>To be consistent with ProUCL 5.2.0, by default the function <code>enparCensored</code> 
does not compute the restricted mean (i.e., <code>restricted=FALSE</code>).  It should 
be noted that when the restricted mean is computed, the number of uncensored 
observations increases because the smallest (left-censored) or largest 
(right-censored) censored observation(s) is/are set to a specified value and 
treated as uncensored.  The <code>kmms</code> function in Version 2.0 of the 
<b>STAND</b> package (Frome and Frome, 2015) is inconsistent in how it treats the 
number of uncensored observations when computing estimates associated with the 
restricted mean.  Although <code>kmms</code> sets the smallest censored observations to the 
observed censoring level and treats them as not censored, when it computes 
the bias correction factor for the standard error of the mean, it assumes those 
observations are still censored (see the EXAMPLES section below).
</p>
<p>In the unusual case when a restricted mean will be estimated and setting the 
smallest censored value(s) to an uncensored value (left-censored data), or 
setting the largest censored value(s) to an uncensored value 
(right-censored data), results in no censored values in the data, the Kaplan-Meier 
estimate of the mean reduces to the sample mean, so the function 
<code>enpar</code> is called and, if <code>warn=TRUE</code>, a warning is returned.
<br></p>
<p><b>Confidence Intervals</b> <br>
This section explains how confidence intervals for the mean <code class="reqn">\mu</code> are
computed.
<br></p>
<p><em>Normal Approximation</em> (<code>ci.method="normal.approx"</code>) <br>
This method constructs approximate <code class="reqn">(1-\alpha)100\%</code> confidence intervals for
<code class="reqn">\mu</code> based on the assumption that the estimator of <code class="reqn">\mu</code> is
approximately normally distributed.  That is, a two-sided <code class="reqn">(1-\alpha)100\%</code>
confidence interval for <code class="reqn">\mu</code> is constructed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{\mu} - t_{1-\alpha/2, v-1}\hat{\sigma}_{\hat{\mu}}, \; \hat{\mu} + t_{1-\alpha/2, v-1}\hat{\sigma}_{\hat{\mu}}] \;\;\;\; (13)</code>
</p>

<p>where <code class="reqn">\hat{\mu}</code> denotes the estimate of <code class="reqn">\mu</code>,
<code class="reqn">\hat{\sigma}_{\hat{\mu}}</code> denotes the estimated asymptotic standard
deviation of the estimator of <code class="reqn">\mu</code>, <code class="reqn">v</code> denotes the assumed sample
size for the confidence interval, and <code class="reqn">t_{p,\nu}</code> denotes the <code class="reqn">p</code>'th
quantile of Student's t-distribuiton with <code class="reqn">\nu</code>
degrees of freedom.  One-sided confidence intervals are computed in a
similar fashion.
</p>
<p>The argument <code>ci.sample.size</code> determines the value of <code class="reqn">v</code>.  
The possible values are the total number of observations, <code class="reqn">N</code> 
(<code>ci.sample.size="Total"</code>), or the number of uncensored observations, 
<code class="reqn">n</code> (<code>ci.sample.size="Uncensored"</code>).  To be consistent with ProUCL 5.2.0, 
in <code>enparCensored</code> the default value is the total number of observations.  
The <code>kmms</code> function in the <b>STAND</b> package, on the other hand, 
uses the number of uncensored observations.
</p>
<p>When <code>pivot.statistic="z"</code>, the <code class="reqn">p</code>'th quantile from the
standard normal distribution is used in place of the
<code class="reqn">p</code>'th quantile from Student's t-distribution.
<br></p>
<p><em>Bootstrap and Bias-Corrected Bootstrap Approximation</em> (<code>ci.method="bootstrap"</code>) <br>
The bootstrap is a nonparametric method of estimating the distribution
(and associated distribution parameters and quantiles) of a sample statistic,
regardless of the distribution of the population from which the sample was drawn.
The bootstrap was introduced by Efron (1979) and a general reference is
Efron and Tibshirani (1993).
</p>
<p>In the context of deriving an approximate <code class="reqn">(1-\alpha)100\%</code> confidence interval
for the population mean <code class="reqn">\mu</code>, the bootstrap can be broken down into the
following steps:
</p>

<ol>
<li>
<p> Create a bootstrap sample by taking a random sample of size <code class="reqn">N</code> from
the observations in <code class="reqn">\underline{x}</code>, where sampling is done with
replacement.  Note that because sampling is done with replacement, the same
element of <code class="reqn">\underline{x}</code> can appear more than once in the bootstrap
sample.  Thus, the bootstrap sample will usually not look exactly like the
original sample (e.g., the number of censored observations in the bootstrap
sample will often differ from the number of censored observations in the
original sample).
</p>
</li>
<li>
<p> Estimate <code class="reqn">\mu</code> based on the bootstrap sample created in Step 1, using
the same method that was used to estimate <code class="reqn">\mu</code> using the original
observations in <code class="reqn">\underline{x}</code>. Because the bootstrap sample usually
does not match the original sample, the estimate of <code class="reqn">\mu</code> based on the
bootstrap sample will usually differ from the original estimate based on
<code class="reqn">\underline{x}</code>.  For the bootstrap-t method (see below), this step also
involves estimating the standard error of the estimate of the mean and
computing the statistic <code class="reqn">T = (\hat{\mu}_B - \hat{\mu}) / \hat{\sigma}_{\hat{\mu}_B}</code>
where <code class="reqn">\hat{\mu}</code> denotes the estimate of the mean based on the original sample,
and <code class="reqn">\hat{\mu}_B</code> and <code class="reqn">\hat{\sigma}_{\hat{\mu}_B}</code> denote the estimate of
the mean and estimate of the standard error of the estimate of the mean based on
the bootstrap sample.
</p>
</li>
<li>
<p> Repeat Steps 1 and 2 <code class="reqn">B</code> times, where <code class="reqn">B</code> is some large number.
For the function <code>enparCensored</code>, the number of bootstraps <code class="reqn">B</code> is
determined by the argument <code>n.bootstraps</code> (see the section <b>ARGUMENTS</b> 
above).
The default value of <code>n.bootstraps</code> is <code>1000</code>.
</p>
</li>
<li>
<p> Use the <code class="reqn">B</code> estimated values of <code class="reqn">\mu</code> to compute the empirical
cumulative distribution function of the estimator of <code class="reqn">\mu</code> or to compute
the empirical cumulative distribution function of the statistic <code class="reqn">T</code>
(see <code>ecdfPlot</code>), and then create a confidence interval for <code class="reqn">\mu</code>
based on this estimated cdf.
</p>
</li>
</ol>
<p>The two-sided percentile interval (Efron and Tibshirani, 1993, p.170) is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{G}^{-1}(\frac{\alpha}{2}), \; \hat{G}^{-1}(1-\frac{\alpha}{2})] \;\;\;\;\;\; (14)</code>
</p>

<p>where <code class="reqn">\hat{G}(t)</code> denotes the empirical cdf of <code class="reqn">\hat{\mu}_B</code> evaluated at <code class="reqn">t</code>
and thus <code class="reqn">\hat{G}^{-1}(p)</code> denotes the <code class="reqn">p</code>'th empirical quantile of the
distribution of <code class="reqn">\hat{\mu}_B</code>, that is, the <code class="reqn">p</code>'th quantile associated with the
empirical cdf.  Similarly, a one-sided lower
confidence interval is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{G}^{-1}(\alpha), \; \infty] \;\;\;\;\;\; (15)</code>
</p>

<p>and a one-sided upper confidence interval is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[-\infty, \; \hat{G}^{-1}(1-\alpha)] \;\;\;\;\;\; (16)</code>
</p>

<p>The function <code>enparCensored</code> calls the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> function <code>quantile</code>
to compute the empirical quantiles used in Equations (14)-(16).
</p>
<p>The percentile method bootstrap confidence interval is only first-order
accurate (Efron and Tibshirani, 1993, pp.187-188), meaning that the probability
that the confidence interval will contain the true value of <code class="reqn">\mu</code> can be
off by <code class="reqn">k/\sqrt{N}</code>, where <code class="reqn">k</code> is some constant.  Efron and Tibshirani
(1993, pp.184–188) proposed a bias-corrected and accelerated interval that is
second-order accurate, meaning that the probability that the confidence interval
will contain the true value of <code class="reqn">\mu</code> may be off by <code class="reqn">k/N</code> instead of
<code class="reqn">k/\sqrt{N}</code>.  The two-sided bias-corrected and accelerated confidence interval is
computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{G}^{-1}(\alpha_1), \; \hat{G}^{-1}(\alpha_2)] \;\;\;\;\;\; (17)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\alpha_1 = \Phi[\hat{z}_0 + \frac{\hat{z}_0 + z_{\alpha/2}}{1 - \hat{a}(z_0 + z_{\alpha/2})}] \;\;\;\;\;\; (18)</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha_2 = \Phi[\hat{z}_0 + \frac{\hat{z}_0 + z_{1-\alpha/2}}{1 - \hat{a}(z_0 + z_{1-\alpha/2})}] \;\;\;\;\;\; (19)</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{z}_0 = \Phi^{-1}[\hat{G}(\hat{\mu})] \;\;\;\;\;\; (20)</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{a} = \frac{\sum_{i=1}^N (\hat{\mu}_{(\cdot)} - \hat{\mu}_{(i)})^3}{6[\sum_{i=1}^N (\hat{\mu}_{(\cdot)} - \hat{\mu}_{(i)})^2]^{3/2}} \;\;\;\;\;\; (21)</code>
</p>

<p>where the quantity <code class="reqn">\hat{\mu}_{(i)}</code> denotes the estimate of <code class="reqn">\mu</code> using
all the values in <code class="reqn">\underline{x}</code> except the <code class="reqn">i</code>'th one, and
</p>
<p style="text-align: center;"><code class="reqn">\hat{\mu}{(\cdot)} = \frac{1}{N} \sum_{i=1}^N \hat{\mu_{(i)}} \;\;\;\;\;\; (22)</code>
</p>

<p>A one-sided lower confidence interval is given by:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{G}^{-1}(\alpha_1), \; \infty] \;\;\;\;\;\; (23)</code>
</p>

<p>and a one-sided upper confidence interval is given by:
</p>
<p style="text-align: center;"><code class="reqn">[-\infty, \; \hat{G}^{-1}(\alpha_2)] \;\;\;\;\;\; (24)</code>
</p>

<p>where <code class="reqn">\alpha_1</code> and <code class="reqn">\alpha_2</code> are computed as for a two-sided confidence
interval, except <code class="reqn">\alpha/2</code> is replaced with <code class="reqn">\alpha</code> in Equations (18) and (19).
</p>
<p>The constant <code class="reqn">\hat{z}_0</code> incorporates the bias correction, and the constant
<code class="reqn">\hat{a}</code> is the acceleration constant.  The term “acceleration” refers
to the rate of change of the standard error of the estimate of <code class="reqn">\mu</code> with
respect to the true value of <code class="reqn">\mu</code> (Efron and Tibshirani, 1993, p.186).  For a
normal (Gaussian) distribution, the standard error of the estimate of <code class="reqn">\mu</code>
does not depend on the value of <code class="reqn">\mu</code>, hence the acceleration constant is not
really necessary.
</p>
<p>For the bootstrap-t method, the two-sided confidence interval
(Efron and Tibshirani, 1993, p.160) is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{\mu} - t_{1-\alpha/2}\hat{\sigma}_{\hat{\mu}}, \; \hat{\mu} - t_{\alpha/2}\hat{\sigma}_{\hat{\mu}}] \;\;\;\;\;\; (25)</code>
</p>

<p>where <code class="reqn">\hat{\mu}</code> and <code class="reqn">\hat{\sigma}_{\hat{\mu}}</code> denote the estimate of the mean
and standard error of the estimate of the mean based on the original sample, and
<code class="reqn">t_p</code> denotes the <code class="reqn">p</code>'th empirical quantile of the bootstrap distribution of
the statistic <code class="reqn">T</code>.  Similarly, a one-sided lower confidence interval is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[\hat{\mu} - t_{1-\alpha}\hat{\sigma}_{\hat{\mu}}, \; \infty] \;\;\;\;\;\; (26)</code>
</p>

<p>and a one-sided upper confidence interval is computed as:
</p>
<p style="text-align: center;"><code class="reqn">[-\infty, \; \hat{\mu} - t_{\alpha}\hat{\sigma}_{\hat{\mu}}] \;\;\;\;\;\; (27)</code>
</p>

<p>When <code>ci.method="bootstrap"</code>, the function <code>enparCensored</code> computes
the percentile method, bias-corrected and accelerated method, and bootstrap-t
bootstrap confidence intervals.  The percentile method is transformation respecting,
but not second-order accurate.  The bootstrap-t method is second-order accurate, but not
transformation respecting.  The bias-corrected and accelerated method is both
transformation respecting and second-order accurate (Efron and Tibshirani, 1993, p.188).
</p>


<h3>Value</h3>

<p>a list of class <code>"estimateCensored"</code> containing the estimated parameters
and other information.  See <code>estimateCensored.object</code> for details.
</p>


<h3>Note</h3>

<p>A sample of data contains censored observations if some of the observations are
reported only as being below or above some censoring level.  In environmental
data analysis, Type I left-censored data sets are common, with values being
reported as “less than the detection limit” (e.g., Helsel, 2012).  Data
sets with only one censoring level are called <em>singly censored</em>; data sets with
multiple censoring levels are called <em>multiply</em> or <em>progressively censored</em>.
</p>
<p>Statistical methods for dealing with censored data sets have a long history in the
field of survival analysis and life testing.  More recently, researchers in the
environmental field have proposed alternative methods of computing estimates and
confidence intervals in addition to the classical ones such as maximum likelihood
estimation.
</p>
<p>Helsel (2012, Chapter 6) gives an excellent review of past studies of the
properties of various estimators based on censored environmental data.
</p>
<p>In practice, it is better to use a confidence interval for the mean or a
joint confidence region for the mean and standard deviation, rather than rely on a
single point-estimate of the mean.  Since confidence intervals and regions depend
on the properties of the estimators for both the mean and standard deviation, the
results of studies that simply evaluated the performance of the mean and standard
deviation separately cannot be readily extrapolated to predict the performance of
various methods of constructing confidence intervals and regions.  Furthermore,
for several of the methods that have been proposed to estimate the mean based on
type I left-censored data, standard errors of the estimates are not available,
hence it is not possible to construct confidence intervals
(El-Shaarawi and Dolan, 1989).
</p>
<p>Few studies have been done to evaluate the performance of methods for constructing
confidence intervals for the mean or joint confidence regions for the mean and
standard deviation when data are subjected to single or multiple censoring.
See, for example, Singh et al. (2006).
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Barker, C. (2009).  The Mean, Median, and Confidence Intervals of the
Kaplan-Meier Survival Estimate – Computations and Applications.
<em>The American Statistician</em> <b>63</b>(1), 78–80.
</p>
<p>Beal, D. (2010).  <em>A Macro for Calculating Summary Statistics on
Left Censored Environmental Data Using the Kaplan-Meier Method</em>.
Paper SDA-09, presented at Southeast SAS Users Group 2010, September 26-28,
Savannah, GA.  <a href="https://analytics.ncsu.edu/sesug/2010/SDA09.Beal.pdf">https://analytics.ncsu.edu/sesug/2010/SDA09.Beal.pdf</a>.
</p>
<p>Efron, B. (1979).  Bootstrap Methods: Another Look at the Jackknife.
<em>The Annals of Statistics</em> <b>7</b>, 1–26.
</p>
<p>Efron, B., and R.J. Tibshirani. (1993).  <em>An Introduction to the Bootstrap</em>.
Chapman and Hall, New York, 436pp.
</p>
<p>El-Shaarawi, A.H., and D.M. Dolan. (1989).  Maximum Likelihood Estimation of
Water Quality Concentrations from Censored Data.
<em>Canadian Journal of Fisheries and Aquatic Sciences</em> <b>46</b>, 1033–1039.
</p>
<p>Frome E.L., and D.P. Frome (2015). <em>STAND: Statistical Analysis of
Non-Detects</em>. R package version 2.0, <a href="https://CRAN.R-project.org/package=STAND">https://CRAN.R-project.org/package=STAND</a>.
</p>
<p>Gillespie, B.W., Q. Chen, H. Reichert, A. Franzblau, E. Hedgeman, J. Lepkowski,
P. Adriaens, A. Demond, W. Luksemburg, and D.H. Garabrant. (2010).  Estimating Population
Distributions When Some Data Are Below a Limit of Detection by Using a Reverse
Kaplan-Meier Estimator.  <em>Epidemiology</em> <b>21</b>(4), S64–S70.
</p>
<p>Helsel, D.R. (2012). <em>Statistics for Censored Environmental Data Using Minitab and R,
Second Edition</em>.  John Wiley &amp; Sons, Hoboken, New Jersey.
</p>
<p>Irwin, J.O. (1949).  The Standard Error of an Estimate of Expectation of Life,
with Special Reference to Expectation of Tumourless Life in Experiments with Mice.
<em>Journal of Hygiene</em> <b>47</b>, 188–189.
</p>
<p>Kaplan, E.L., and P. Meier. (1958). Nonparametric Estimation From Incomplete Observations.
<em>Journal of the American Statistical Association</em> <b>53</b>, 457-481.
</p>
<p>Klein, J.P., and M.L. Moeschberger. (2003).  <em>Survival Analysis:
Techniques for Censored and Truncated Data, Second Edition</em>.  Springer, New York,
537pp.
</p>
<p>Lee, E.T., and J.W. Wang. (2003).
<em>Statistical Methods for Survival Data Analysis, Third Edition</em>.
John Wiley &amp; Sons, Hoboken, New Jersey, 513pp.
</p>
<p>Meier, P., T. Karrison, R. Chappell, and H. Xie. (2004).  The Price of Kaplan-Meier.
<em>Journal of the American Statistical Association</em> <b>99</b>(467), 890–896.
</p>
<p>Miller, R.G. (1981).  <em>Survival Analysis</em>. John Wiley and Sons, New York.
</p>
<p>Nelson, W. (1982).  <em>Applied Life Data Analysis</em>.
John Wiley and Sons, New York, 634pp.
</p>
<p>Singh, A., R. Maichle, and S. Lee. (2006).  <em>On the Computation of a 95%
Upper Confidence Limit of the Unknown Population Mean Based Upon Data Sets
with Below Detection Limit Observations</em>.  EPA/600/R-06/022, March 2006.
Office of Research and Development, U.S. Environmental Protection Agency,
Washington, D.C.
</p>
<p>Singh, A., N. Armbya, and A. Singh. (2010).
<em>ProUCL Version 4.1.00 Technical Guide (Draft)</em>. EPA/600/R-07/041, May 2010.
Office of Research and Development, U.S. Environmental Protection Agency,
Washington, D.C.
</p>
<p>USEPA. (2009).  <em>Statistical Analysis of Groundwater Monitoring Data at 
RCRA Facilities, Unified Guidance</em>.  EPA 530/R-09-007, March 2009.  Office of 
Resource Conservation and Recovery Program Implementation and Information Division.
U.S. Environmental Protection Agency, Washington, D.C.
</p>
<p>USEPA. (2010).  <em>Errata Sheet - March 2009 Unified Guidance</em>.
EPA 530/R-09-007a, August 9, 2010.  Office of Resource Conservation and Recovery, 
Program Information and Implementation Division.  U.S. Environmental 
Protection Agency, Washington, D.C.
</p>
<p>USEPA. (2022).  <em>ProUCL Version 5.2.0 Technical Guide: 
Statistical Software for Environmental Applications for Data Sets with and 
without Nondetect Observations</em>.  Prepared by:  Neptune and Company, Inc., 
1435 Garrison Street, Suite 201, Lakewood, CO 80215.  pp. 128–129, 143.  
<a href="https://www.epa.gov/land-research/proucl-software">https://www.epa.gov/land-research/proucl-software</a>.
</p>


<h3>See Also</h3>

<p><code>ppointsCensored</code>, <code>ecdfPlotCensored</code>, 
<code>qqPlotCensored</code>,<code>estimateCensored.object</code>, 
<code>enpar</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Using the lead concentration data from soil samples shown in 
  # Beal (2010), compute the Kaplan-Meier estimators of the mean, 
  # standard deviation, and standard error of the mean, as well as 
  # a 95% upper confidence limit for the mean.  Compare these 
  # results to those given in Beal (2010), and also to the results 
  # produced by ProUCL 5.2.0.

  # First look at the data:
  #-----------------------

  head(Beal.2010.Pb.df)
  #  Pb.char  Pb Censored
  #1      &lt;1 1.0     TRUE
  #2      &lt;1 1.0     TRUE
  #3       2 2.0    FALSE
  #4     2.5 2.5    FALSE
  #5     2.8 2.8    FALSE
  #6      &lt;3 3.0     TRUE

  tail(Beal.2010.Pb.df)
  #   Pb.char   Pb Censored
  #24     &lt;10   10     TRUE
  #25      10   10    FALSE
  #26      15   15    FALSE
  #27      49   49    FALSE
  #28     200  200    FALSE
  #29    9060 9060    FALSE

  # enparCensored Results:
  #-----------------------
  Beal.unrestricted &lt;- with(Beal.2010.Pb.df, 
    enparCensored(x = Pb, censored = Censored, ci = TRUE, 
      ci.type = "upper"))

  Beal.unrestricted

  #Results of Distribution Parameter Estimation
  #Based on Type I Censored Data
  #--------------------------------------------
  #
  #Assumed Distribution:            None
  #
  #Censoring Side:                  left
  #
  #Censoring Level(s):               1  3  4  6  9 10 
  #
  #Estimated Parameter(s):          mean    =  325.3396
  #                                 sd      = 1651.0950
  #                                 se.mean =  315.0023
  #
  #Estimation Method:               Kaplan-Meier
  #                                 (Bias-corrected se.mean)
  #
  #Data:                            Pb
  #
  #Censoring Variable:              Censored
  #
  #Sample Size:                     29
  #
  #Percent Censored:                34.48276%
  #
  #Confidence Interval for:         mean
  #
  #Assumed Sample Size:             29
  #
  #Confidence Interval Method:      Normal Approximation
  #                                 (t Distribution)
  #
  #Confidence Interval Type:        upper
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             LCL =   0.0000
  #                                 UCL = 861.1996

  c(Beal.unrestricted$parameters, Beal.unrestricted$interval$limits)
  #     mean        sd   se.mean       LCL       UCL 
  # 325.3396 1651.0950  315.0023    0.0000  861.1996

  # Beal (2010) published results:
  #-------------------------------
  #   Mean   Std. Dev.  SE of Mean
  # 325.34     1651.09      315.00

  # ProUCL 5.2.0 results:
  #----------------------
  #   Mean   Std. Dev.  SE of Mean  95% UCL
  # 325.2      1651         315       861.1

  #----------

  # Now compute the restricted mean and associated quantities, 
  # and compare these results with those produced by the 
  # kmms() function in the STAND package.
  #----------------------------------------------------------- 

  Beal.restricted &lt;- with(Beal.2010.Pb.df, 
    enparCensored(x = Pb, censored = Censored, restricted = TRUE, 
      ci = TRUE, ci.type = "upper"))

  Beal.restricted 

  #Results of Distribution Parameter Estimation
  #Based on Type I Censored Data
  #--------------------------------------------
  #
  #Assumed Distribution:            None
  #
  #Censoring Side:                  left
  #
  #Censoring Level(s):               1  3  4  6  9 10 
  #
  #Estimated Parameter(s):          mean    =  325.2011
  #                                 sd      = 1651.1221
  #                                 se.mean =  314.1774
  #
  #Estimation Method:               Kaplan-Meier (Restricted Mean)
  #                                 Smallest censored value(s)
  #                                   set to Censoring Level
  #                                 (Bias-corrected se.mean)
  #
  #Data:                            Pb
  #
  #Censoring Variable:              Censored
  #
  #Sample Size:                     29
  #
  #Percent Censored:                34.48276%
  #
  #Confidence Interval for:         mean
  #
  #Assumed Sample Size:             29
  #
  #Confidence Interval Method:      Normal Approximation
  #                                 (t Distribution)
  #
  #Confidence Interval Type:        upper
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             LCL =   0.000
  #                                 UCL = 859.658

  c(Beal.restricted$parameters, Beal.restricted$interval$limits)
  #     mean        sd   se.mean       LCL       UCL 
  # 325.2011 1651.1221  314.1774    0.0000  859.6580

  # kmms() results:
  #----------------
  #  KM.mean    KM.LCL    KM.UCL     KM.se     gamma 
  # 325.2011 -221.0419  871.4440  315.0075    0.9500 
  
  # NOTE: as pointed out above, the kmms() function treats the 
  #       smallest censored observations (&lt;1 and &lt;1) as NOT 
  #       censored when computing the mean and uncorrected 
  #       standard error of the mean, but assumes these 
  #       observations ARE censored when computing the corrected 
  #       standard error of the mean.
  #--------------------------------------------------------------

  Beal.restricted$parameters["se.mean"] * sqrt((20/21)) * sqrt((19/18))
  #  se.mean 
  # 315.0075

  #==========

  # Repeat the above example, estimating the unrestricted mean and 
  # computing an upper confidence limit based on the bootstrap 
  # instead of on the normal approximation with a t pivot statistic.
  # Compare results to those from ProUCL 5.2.0.
  # Note:  Setting the seed argument lets you reproduce this example.
  #------------------------------------------------------------------

  Beal.unrestricted.boot &lt;- with(Beal.2010.Pb.df, 
    enparCensored(x = Pb, censored = Censored, ci = TRUE, 
      ci.type = "upper", ci.method = "bootstrap", seed = 923))

  Beal.unrestricted.boot

  #Results of Distribution Parameter Estimation
  #Based on Type I Censored Data
  #--------------------------------------------
  #
  #Assumed Distribution:            None
  #
  #Censoring Side:                  left
  #
  #Censoring Level(s):               1  3  4  6  9 10 
  #
  #Estimated Parameter(s):          mean    =  325.3396
  #                                 sd      = 1651.0950
  #                                 se.mean =  315.0023
  #
  #Estimation Method:               Kaplan-Meier
  #                                 (Bias-corrected se.mean)
  #
  #Data:                            Pb
  #
  #Censoring Variable:              Censored
  #
  #Sample Size:                     29
  #
  #Percent Censored:                34.48276%
  #
  #Confidence Interval for:         mean
  #
  #Assumed Sample Size:             29
  #
  #Confidence Interval Method:      Bootstrap
  #
  #Number of Bootstraps:            1000
  #
  #Number of Bootstrap Samples
  #With No Censored Values:         0
  #
  #Number of Times Bootstrap
  #Repeated Because Too Few
  #Uncensored Observations:         0
  #
  #Confidence Interval Type:        upper
  #
  #Confidence Level:                95%
  #
  #Confidence Interval:             Pct.LCL =     0.0000
  #                                 Pct.UCL =   948.7342
  #                                 BCa.LCL =     0.0000
  #                                 BCa.UCL =   942.6596
  #                                 t.LCL   =     0.0000
  #                                 t.UCL   = 62121.8909

  c(Beal.unrestricted.boot$interval$limits)
  #   Pct.LCL    Pct.UCL    BCa.LCL    BCa.UCL      t.LCL      t.UCL 
  #    0.0000   948.7342     0.0000   942.6596     0.0000 62121.8909

  # ProUCL 5.2.0 results:
  #----------------------
  #   Pct.LCL    Pct.UCL    BCa.LCL    BCa.UCL      t.LCL      t.UCL 
  #    0.0000   944.3        0.0000   947.8        0.0000 62169

  #==========

  # Clean up
  #---------
  rm(Beal.unrestricted, Beal.restricted, Beal.unrestricted.boot)
</code></pre>


</div>