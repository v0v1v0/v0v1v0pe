<div class="container">

<table style="width: 100%;"><tr>
<td>distance correlation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Distance Correlation and Covariance Statistics</h2>

<h3>Description</h3>

<p>Computes distance covariance and distance correlation statistics,
which are multivariate measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dcov(x, y, index = 1.0)
dcor(x, y, index = 1.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> data or distances of first sample</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> data or distances of second sample</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>dcov</code> and <code>dcor</code> compute distance
covariance and distance correlation statistics.
</p>
<p>The sample sizes (number of rows) of the two samples must
agree, and samples must not contain missing values. 
</p>
<p>The <code>index</code> is an optional exponent on Euclidean distance.
Valid exponents for energy are in (0, 2) excluding 2. 
</p>
<p>Argument types supported are 
numeric data matrix, data.frame, or tibble, with observations in rows;
numeric vector; ordered or unordered factors. In case of unordered factors
a 0-1 distance matrix is computed.
</p>
<p>Optionally pre-computed distances can be input as class "dist" objects or as distance matrices. 
For data types of arguments, distance matrices are computed internally. 
</p>
<p>Distance correlation is a new measure of dependence between random
vectors introduced by Szekely, Rizzo, and Bakirov (2007).
For all distributions with finite first moments, distance
correlation <code class="reqn">\mathcal R</code> generalizes the idea of correlation in two
fundamental ways:
(1) <code class="reqn">\mathcal R(X,Y)</code> is defined for <code class="reqn">X</code> and <code class="reqn">Y</code> in arbitrary dimension.
(2) <code class="reqn">\mathcal R(X,Y)=0</code> characterizes independence of <code class="reqn">X</code> and
<code class="reqn">Y</code>.
</p>
<p>Distance correlation satisfies <code class="reqn">0 \le \mathcal R \le 1</code>, and
<code class="reqn">\mathcal R = 0</code> only if <code class="reqn">X</code> and <code class="reqn">Y</code> are independent. Distance
covariance <code class="reqn">\mathcal V</code> provides a new approach to the problem of
testing the joint independence of random vectors. The formal
definitions of the population coefficients <code class="reqn">\mathcal V</code> and
<code class="reqn">\mathcal R</code> are given in (SRB 2007). The definitions of the
empirical coefficients are as follows.
</p>
<p>The empirical distance covariance <code class="reqn">\mathcal{V}_n(\mathbf{X,Y})</code>
with index 1 is
the nonnegative number defined by
</p>
<p style="text-align: center;"><code class="reqn">
 \mathcal{V}^2_n (\mathbf{X,Y}) = \frac{1}{n^2} \sum_{k,\,l=1}^n
 A_{kl}B_{kl}
 </code>
</p>

<p>where <code class="reqn">A_{kl}</code> and <code class="reqn">B_{kl}</code> are
</p>
<p style="text-align: center;"><code class="reqn">
A_{kl} = a_{kl}-\bar a_{k.}- \bar a_{.l} + \bar a_{..}
</code>
</p>

<p style="text-align: center;"><code class="reqn">
 B_{kl} = b_{kl}-\bar b_{k.}- \bar b_{.l} + \bar b_{..}.
 </code>
</p>

<p>Here
</p>
<p style="text-align: center;"><code class="reqn">
a_{kl} = \|X_k - X_l\|_p, \quad b_{kl} = \|Y_k - Y_l\|_q, \quad
k,l=1,\dots,n,
</code>
</p>

<p>and the subscript <code>.</code> denotes that the mean is computed for the
index that it replaces.  Similarly,
<code class="reqn">\mathcal{V}_n(\mathbf{X})</code> is the nonnegative number defined by
</p>
<p style="text-align: center;"><code class="reqn">
 \mathcal{V}^2_n (\mathbf{X}) = \mathcal{V}^2_n (\mathbf{X,X}) =
 \frac{1}{n^2} \sum_{k,\,l=1}^n
 A_{kl}^2.
 </code>
</p>

<p>The empirical distance correlation <code class="reqn">\mathcal{R}_n(\mathbf{X,Y})</code> is
the square root of
</p>
<p style="text-align: center;"><code class="reqn">
  \mathcal{R}^2_n(\mathbf{X,Y})=
 \frac {\mathcal{V}^2_n(\mathbf{X,Y})}
 {\sqrt{ \mathcal{V}^2_n (\mathbf{X}) \mathcal{V}^2_n(\mathbf{Y})}}.
</code>
</p>

<p>See <code>dcov.test</code> for a test of multivariate independence
based on the distance covariance statistic. 
</p>


<h3>Value</h3>

<p><code>dcov</code> returns the sample distance covariance and
<code>dcor</code> returns the sample distance correlation.
</p>


<h3>Note</h3>

<p>Note that it is inefficient to compute dCor by:
</p>
<p>square root of
<code>dcov(x,y)/sqrt(dcov(x,x)*dcov(y,y))</code>
</p>
<p>because the individual
calls to <code>dcov</code> involve unnecessary repetition of calculations.
</p>


<h3>Author(s)</h3>

<p> Maria L. Rizzo <a href="mailto:mrizzo@bgsu.edu">mrizzo@bgsu.edu</a> and
Gabor J. Szekely
</p>


<h3>References</h3>

<p>Szekely, G.J., Rizzo, M.L., and Bakirov, N.K. (2007),
Measuring and Testing Dependence by Correlation of Distances,
<em>Annals of Statistics</em>, Vol. 35 No. 6, pp. 2769-2794.
<br><a href="https://doi.org/10.1214/009053607000000505">doi:10.1214/009053607000000505</a>
</p>
<p>Szekely, G.J. and Rizzo, M.L. (2009),
Brownian Distance Covariance,
<em>Annals of Applied Statistics</em>,
Vol. 3, No. 4, 1236-1265.
<br><a href="https://doi.org/10.1214/09-AOAS312">doi:10.1214/09-AOAS312</a>
</p>
<p>Szekely, G.J. and Rizzo, M.L. (2009),
Rejoinder: Brownian Distance Covariance,
<em>Annals of Applied Statistics</em>, Vol. 3, No. 4, 1303-1308.
</p>


<h3>See Also</h3>

<p><code>dcov2d</code> <code>dcor2d</code> 
<code>bcdcor</code>  <code>dcovU</code>  <code>pdcor</code>
<code>dcov.test</code> <code>dcor.test</code>  <code>pdcor.test</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"> x &lt;- iris[1:50, 1:4]
 y &lt;- iris[51:100, 1:4]
 dcov(x, y)
 dcov(dist(x), dist(y))  #same thing
</code></pre>


</div>