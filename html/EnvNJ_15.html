<div class="container">

<table style="width: 100%;"><tr>
<td>metrics</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pairwise Vector Dissimilarities</h2>

<h3>Description</h3>

<p>Computes the dissimilarity between n-dimensional vectors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">metrics(vset, method = 'euclidean', p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>vset</code></td>
<td>
<p>matrix (n x m) where each column is a n-dimensional vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character string indicating the distance/dissimilarity method to be used (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>power of the Minkowski distance. This parameter is only relevant if the method 'minkowski' has been selected.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Although many of the offered methods compute a proper distance, that is not always the case. For instance, for a non null vector, v, the 'cosine' method gives d(v, 2v) = 0, violating the coincidence axiom. For that reason we prefer to use the term dissimilarity instead of distance. The methods offered can be grouped into families.
</p>


<h4>L_p family:</h4>

<p>('euclidean', 'manhattan', 'minkowski', 'chebyshev')
</p>
<p>Euclidean = sqrt( sum | P_i - Q_i |^2)
</p>
<p>Manhattan = sum | P_i - Q_i |
</p>
<p>Minkowski = ( sum| P_i - Q_i |^p)^1/p
</p>
<p>Chebyshev = max | P_i - Q_i |
</p>



<h4>L_1 family:</h4>

<p>('sorensen', 'soergel', 'lorentzian', 'kulczynski', 'canberra')
</p>
<p>Sorensen = sum | P_i - Q_i | / sum (P_i + Q_i)
</p>
<p>Soergel = sum | P_i - Q_i | / sum max(P_i , Q_i)
</p>
<p>Lorentzian = sum ln(1 + | P_i - Q_i |)
</p>
<p>Kulczynski = sum | P_i - Q_i | / sum min(P_i , Q_i)
</p>
<p>Canberra = sum | P_i - Q_i | / (P_i + Q_i)
</p>



<h4>Intersection family:</h4>

<p>('non-intersection', 'wavehedges', 'czekanowski', 'motyka')
</p>
<p>Non-intersection = 1 - sum min(P_i , Q_i)
</p>
<p>Wave-Hedges = sum | P_i - Q_i | / max(P_i , Q_i)
</p>
<p>Czekanowski = sum | P_i - Q_i | / sum | P_i + Q_i |
</p>
<p>Motyka = sum max(P_i , Q_i) / sum (P_i , Q_i)
</p>



<h4>Inner product family:</h4>

<p>('cosine', 'jaccard')
</p>
<p>Cosine = - ln(0.5 (1 +  (P_i Q_i) / sqrt(sum P_i^2) sqrt(sum Q_i^2)))
</p>
<p>Jaccard = 1 - sum (P_i Q_i) / (sum P_i^2 + sum Q_i^2 - sum (P_i Q_i))
</p>



<h4>Squared-chord family:</h4>

<p>('bhattacharyya', 'squared_chord')
</p>
<p>Bhattacharyya = - ln sum sqrt(P_i Q_i)
</p>
<p>Squared-chord = sum ( sqrt(P_i) - sqrt(Q_i) )^2
</p>



<h4>Squared Chi family:</h4>

<p>('squared_chi')
</p>
<p>Squared-Chi = sum ( (P_i - Q_i )^2 / (P_i + Q_i) )
</p>



<h4>Shannon's entropy family:</h4>

<p>('kullback-leibler', 'jeffreys', 'jensen-shannon', 'jensen_difference')
</p>
<p>Kullback-Leibler = sum P_i * log(P_i / Q_i)
</p>
<p>Jeffreys = sum (P_i - Q_i) * log(P_i / Q_i)
</p>
<p>Jensen-Shannon = 0.5(sum P_i ln(2P_i / (P_i + Q_i)) + sum Q_i ln(2Q_i / (P_i + Q_i)))
</p>
<p>Jensen difference = sum (0.5(P_i log(P_i) + Q_i log(Q_i)) - 0.5(P_i + Q_i) ln(0.5(P_i + Q_i))
</p>



<h4>Mismatch family:</h4>

<p>('hamming', 'mismatch', 'mismatchZero', 'binary')
</p>
<p>Hamming = (# coordinates where P_i != Q_i) / n
</p>
<p>Mismatch = # coordinates where that P_i != Q_i
</p>
<p>MismatchZero = Same as mismatch but after removing the coordinates where both vectors have zero.
</p>
<p>Binary = (# coordinates where a vector has 0 and the other has a non-zero value) / n.
</p>



<h4>Combinations family:</h4>

<p>('taneja', 'kumar-johnson', 'avg')
</p>
<p>Taneja = sum ( P_i + Q_i / 2) log( P_i + Q_i / ( 2 sqrt( P_i * Q_i)) )
</p>
<p>Kumar-Johnson = sum (P_i^2 - Q_i^2)^2 / 2 (P_i Q_i)^1.5
</p>
<p>Avg = 0.5 (sum | P_i - Q_i| + max | P_i - Q_i |)
</p>



<h3>Value</h3>

<p>A matrix with the computed dissimilarity values.
</p>


<h3>References</h3>

<p>Sung-Hyuk Cha (2007). International Journal of Mathematical Models and Methods in Applied Sciences. Issue 4, vol. 1
</p>
<p>Luczac et al. (2019). Briefings in Bioinformatics 20: 1222-1237.
</p>
<p>https://r-snippets.readthedocs.io/en/latest/real_analysis/metrics.html
</p>


<h3>See Also</h3>

<p>vcos(), vdis()
</p>


<h3>Examples</h3>

<pre><code class="language-R">metrics(matrix(1:9, ncol =3), 'cosine')
</code></pre>


</div>