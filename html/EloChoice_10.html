<div class="container">

<table style="width: 100%;"><tr>
<td>reliability</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>calculate reliability-index</h2>

<h3>Description</h3>

<p>calculate reliability-index of Elo-ratings
</p>


<h3>Usage</h3>

<pre><code class="language-R">reliability(x)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>elochoice-object, the result of <code>elochoice</code></p>
</td>
</tr></table>
<h3>Value</h3>

<p>a data.frame with as many rows as randomizations were run in the original call to <code>elochoice()</code>. The first column represents the unweighted and the second the weighted reliability index (<em>R</em> and <em>R'</em>), which is followed by the total number of trials that contributed to the calculation of the index. Note that this number cannot reach the total number of trials in the data set because at least for the very first trial we did not have an expectation for the outcome of that trial (and such trials do not contribute to the calculation of the reliability index).
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>References</h3>

<p>Clark AP, Howard KL, Woods AT, Penton-Voak IS, Neumann C (2018).
“Why rate when you could compare? Using the 'EloChoice' package to assess pairwise comparisons of perceived physical strength.”
<em>PloS one</em>, <b>13</b>(1), e0190393.
doi: <a href="https://doi.org/10.1371/journal.pone.0190393">10.1371/journal.pone.0190393</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># create data set and calculate ratings (with five randomizations)
xdata &lt;- randompairs(12, 500)
x &lt;- elochoice(xdata$winner, xdata$loser, runs=5)
# extract the reliability values
(u &lt;- reliability(x))
# calculate average reliability index
mean(u$upset)
# and in its weighted form
mean(u$upset.wgt)
</code></pre>


</div>