<div class="container">

<table style="width: 100%;"><tr>
<td>eespcaForK</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multi-PC version of Eigenvectors from Eigenvalues Sparse Principal Component Analysis (EESPCA)</h2>

<h3>Description</h3>

<p>Computes multiple sparse principal components of the specified data matrix via sequential application of
the Eigenvectors from Eigenvalues Sparse Principal Component Analysis (EESPCA) algorithm.
After computing the first sparse PC via the <code>eespca</code> function, 
subsequent sparse PCs are computing by repeatedly applying <code>eespca</code> to the residual matrix formed
by subtracting the reconstruction of <code>X</code> from the original <code>X</code>. 
Multiple sparse PCs are not guaranteed to be orthogonal. 
</p>
<p>Note that the accuracy of the sparse approximation declines substantially for PCs with very small
variances. To avoid this issue, <code>k</code> should not be set higher than the number of statistically 
significant PCs according to a Tracey-Widom test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">    eespcaForK(X, k=2, max.iter=20, sparse.threshold, lambda.diff.threshold=1e-6, 
        compute.sparse.lambda=FALSE, sub.mat.max.iter=5, trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>An n-by-p data matrix for which the first <code>k</code> sparse PCs will be computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>The number of sparse PCs to compute. The specified k must be 2 or greater (for k=1, use
the <code>eespca</code> method). A check is made that k is not greater than the maximum theoretical
rank of X but, for performance reasons, a check is NOT made that
k is less than or equal to the actual rank of X. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparse.threshold</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.diff.threshold</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compute.sparse.lambda</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sub.mat.max.iter</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>See description for <code>eespca</code></p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>list</code> with the following elements:
</p>

<ul>
<li>
<p> "V": Matrix of sparse loadings for the first k PCs. 
</p>
</li>
<li>
<p> "lambdas": Vector of variances of the first k sparse PCs.
</p>
</li>
</ul>
<h3>References</h3>


<ul><li>
<p> Frost, H. R. (2021). Eigenvectors from Eigenvalues Sparse Principal Component Analysis (EESPCA). arXiv e-prints. https://arxiv.org/abs/2006.01924  
</p>
</li></ul>
<h3>See Also</h3>

<p><code>eespca</code></p>


<h3>Examples</h3>

<pre><code class="language-R">    set.seed(1)
    # Simulate 10x5 MVN data matrix
    X=matrix(rnorm(50), nrow=10)
    # Get first two sparse PCs
    eespcaForK(X=X, sparse.threshold=1/sqrt(5), k=2)
</code></pre>


</div>