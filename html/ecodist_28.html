<div class="container">

<table style="width: 100%;"><tr>
<td>pco</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Principal coordinates analysis </h2>

<h3>Description</h3>

<p>Principal coordinates analysis (classical scaling).
</p>


<h3>Usage</h3>

<pre><code class="language-R">pco(x, negvals = "zero", dround = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> a lower-triangular dissimilarity matrix. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>negvals</code></td>
<td>
<p> if = "zero" sets all negative eigenvalues to zero;
if = "rm" corrects for negative eigenvalues using method
1 of Legendre and Anderson 1999. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dround</code></td>
<td>
<p> if greater than 0, attempts to correct for round-off error by
rounding to that number of places. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>PCO (classical scaling, metric multidimensional scaling) is very similar to principal components analysis, but allows the use of any dissimilarity metric.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>values </code></td>
<td>
<p>eigenvalue for each component. This is a measure of the variance explained by each dimension.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vectors </code></td>
<td>
<p>eigenvectors. data frame with columns containing the scores for that dimension.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Sarah Goslee </p>


<h3>See Also</h3>

 <p><code>princomp</code>, <code>nmds</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">data(iris)
iris.d &lt;- dist(iris[,1:4])
iris.pco &lt;- pco(iris.d)

# scatterplot of the first two dimensions
plot(iris.pco$vectors[,1:2], col=as.numeric(iris$Species),
  pch=as.numeric(iris$Species), main="PCO", xlab="PCO 1", ylab="PCO 2")
</code></pre>


</div>