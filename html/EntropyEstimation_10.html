<div class="container">

<table style="width: 100%;"><tr>
<td>KL.sd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>KL.sd</h2>

<h3>Description</h3>

<p>Returns the estimated asymptotic standard deviation for the Z estimator of Kullback-Leibler's divergence. Note that this is also the asymptotic standard deviation of the plug-in estimator. See Zhang and Grabchak (2014b) for details.</p>


<h3>Usage</h3>

<pre><code class="language-R">KL.sd(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Vector of counts from the first distribution. Must be integer valued. Each entry represents the number of observations of a distinct letter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Vector of counts from the second distribution. Must be integer valued. Each entry represents the number of observations of a distinct letter.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Lijuan Cao and Michael Grabchak</p>


<h3>References</h3>

<p>Z. Zhang and M. Grabchak (2014b). Nonparametric Estimation of Kullback-Leibler Divergence. Neural Computation, 26(11): 2570-2593.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> x = c(1,3,7,4,8) # first vector of counts
 y = c(2,5,1,3,6) # second vector of counts
 KL.sd(x,y)  # Estimated standard deviation
 KL.sd(y,x)  # Estimated standard deviation
</code></pre>


</div>