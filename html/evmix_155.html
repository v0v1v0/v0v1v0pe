<div class="container">

<table style="width: 100%;"><tr>
<td>fbckdengpdcon</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MLE Fitting of Boundary Corrected Kernel Density Estimate for Bulk and GPD Tail Extreme Value Mixture Model
with Single Continuity Constraint</h2>

<h3>Description</h3>

<p>Maximum likelihood estimation for fitting the extreme value 
mixture model with boundary corrected kernel density estimate for bulk distribution upto the threshold and conditional
GPD above thresholdwith continuity at threshold. With options for profile likelihood estimation for threshold and
fixed threshold approach.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fbckdengpdcon(x, phiu = TRUE, useq = NULL, fixedu = FALSE,
  pvector = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  add.jitter = FALSE, factor = 0.1, amount = NULL, std.err = TRUE,
  method = "BFGS", control = list(maxit = 10000), finitelik = TRUE,
  ...)

lbckdengpdcon(x, lambda = NULL, u = 0, xi = 0, phiu = TRUE,
  bw = NULL, kernel = "gaussian", bcmethod = "simple",
  proper = TRUE, nn = "jf96", offset = NULL, xmax = NULL,
  log = TRUE)

nlbckdengpdcon(pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)

proflubckdengpdcon(u, pvector, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, method = "BFGS", control = list(maxit = 10000),
  finitelik = TRUE, ...)

nlubckdengpdcon(pvector, u, x, phiu = TRUE, kernel = "gaussian",
  bcmethod = "simple", proper = TRUE, nn = "jf96", offset = NULL,
  xmax = NULL, finitelik = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of sample data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phiu</code></td>
<td>
<p>probability of being above threshold <code class="reqn">(0, 1)</code> or logical, see Details in 
help for <code>fnormgpd</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>useq</code></td>
<td>
<p>vector of thresholds (or scalar) to be considered in profile likelihood or
<code>NULL</code> for no profile likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedu</code></td>
<td>
<p>logical, should threshold be fixed (at either scalar value in <code>useq</code>,
or estimated from maximum of profile likelihood evaluated at
sequence of thresholds in <code>useq</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvector</code></td>
<td>
<p>vector of initial values of parameters or <code>NULL</code> for default
values, see below</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>kernel name (<code>default = "gaussian"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bcmethod</code></td>
<td>
<p>boundary correction method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>proper</code></td>
<td>
<p>logical, whether density is renormalised to integrate to unity (where needed)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nn</code></td>
<td>
<p>non-negativity correction method (simple boundary correction only)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>offset added to kernel centres (logtrans only) or <code>NULL</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xmax</code></td>
<td>
<p>upper bound on support (copula and beta kernels only) or <code>NULL</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add.jitter</code></td>
<td>
<p>logical, whether jitter is needed for rounded kernel centres</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor</code></td>
<td>
<p>see <code>jitter</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>amount</code></td>
<td>
<p>see <code>jitter</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>std.err</code></td>
<td>
<p>logical, should standard errors be calculated</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>optimisation method (see <code>optim</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>optimisation control list (see <code>optim</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>finitelik</code></td>
<td>
<p>logical, should log-likelihood return finite value for invalid parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>optional inputs passed to <code>optim</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>bandwidth for kernel (as half-width of kernel) or <code>NULL</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>scalar threshold value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xi</code></td>
<td>
<p>scalar shape parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw</code></td>
<td>
<p>bandwidth for kernel (as standard deviations of kernel) or <code>NULL</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>logical, if <code>TRUE</code> then log-likelihood rather than likelihood is output</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The extreme value mixture model with boundary corrected kernel density
estimate (BCKDE) for bulk and GPD tail with continuity at threshold is 
fitted to the entire dataset using maximum likelihood estimation. The estimated
parameters, variance-covariance matrix and their standard errors are automatically
output.
</p>
<p>See help for <code>fnormgpd</code> for details, type <code>help fnormgpd</code>. 
Only the different features are outlined below for brevity.
</p>
<p>The GPD <code>sigmau</code> parameter is now specified as function of other parameters, see 
help for <code>dbckdengpdcon</code> for details, type <code>help bckdengpdcon</code>.
Therefore, <code>sigmau</code> should not be included in the parameter vector if initial values
are provided, making the full parameter vector 
(<code>lambda</code>, <code>u</code>, <code>xi</code>) if threshold is also estimated and
(<code>lambda</code>, <code>xi</code>) for profile likelihood or fixed threshold approach.
</p>
<p>Negative data are ignored.
</p>
<p>Cross-validation likelihood is used for BCKDE, but standard likelihood is used
for GPD component. See help for <code>fkden</code> for details,
type <code>help fkden</code>.
</p>
<p>The alternate bandwidth definitions are discussed in the 
<code>kernels</code>, with the <code>lambda</code> as the default
used in the likelihood fitting. The <code>bw</code> specification is the same as
used in the <code>density</code> function.
</p>
<p>The possible kernels are also defined in <code>kernels</code>
with the <code>"gaussian"</code> as the default choice.
</p>
<p>Unlike the standard KDE, there is no general rule-of-thumb bandwidth for all these
estimators, with only certain methods having a guideline in the literature, so none
have been implemented. Hence, a bandwidth must always be specified.
</p>
<p>The <code>simple</code>, <code>renorm</code>, <code>beta1</code>, <code>beta2</code> <code>gamma1</code> and <code>gamma2</code>
boundary corrected kernel density estimates require renormalisation, achieved
by numerical integration, so are very time consuming.
</p>


<h3>Value</h3>

<p><code>lbckdengpdcon</code>, <code>nlbckdengpdcon</code>,
and <code>nlubckdengpdcon</code> give the log-likelihood,
negative log-likelihood and profile likelihood for threshold. Profile likelihood
for single threshold is given by <code>proflubckdengpdcon</code>.
<code>fbckdengpdcon</code> returns a simple list with the following elements
</p>

<table>
<tr>
<td style="text-align: left;">
 <code>call</code>:      </td>
<td style="text-align: left;"> <code>optim</code> call</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>x</code>:         </td>
<td style="text-align: left;"> data vector <code>x</code>
</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>init</code>:      </td>
<td style="text-align: left;"> <code>pvector</code>
</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>fixedu</code>:    </td>
<td style="text-align: left;"> fixed threshold, logical</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>useq</code>:      </td>
<td style="text-align: left;"> threshold vector for profile likelihood or scalar for fixed threshold</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>nllhuseq</code>:  </td>
<td style="text-align: left;"> profile negative log-likelihood at each threshold in useq</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>optim</code>:     </td>
<td style="text-align: left;"> complete <code>optim</code> output</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>mle</code>:       </td>
<td style="text-align: left;"> vector of MLE of parameters</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>cov</code>:       </td>
<td style="text-align: left;"> variance-covariance matrix of MLE of parameters</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>se</code>:        </td>
<td style="text-align: left;"> vector of standard errors of MLE of parameters</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>rate</code>:      </td>
<td style="text-align: left;"> <code>phiu</code> to be consistent with <code>evd</code>
</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>nllh</code>:      </td>
<td style="text-align: left;"> minimum negative log-likelihood</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>n</code>:         </td>
<td style="text-align: left;"> total sample size</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>lambda</code>:    </td>
<td style="text-align: left;"> MLE of lambda (kernel half-width)</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>u</code>:         </td>
<td style="text-align: left;"> threshold (fixed or MLE)</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>sigmau</code>:    </td>
<td style="text-align: left;"> MLE of GPD scale(estimated from other parameters)</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>xi</code>:        </td>
<td style="text-align: left;"> MLE of GPD shape</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>phiu</code>:      </td>
<td style="text-align: left;"> MLE of tail fraction (bulk model or parameterised approach)</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>se.phiu</code>:   </td>
<td style="text-align: left;"> standard error of MLE of tail fraction</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>bw</code>:        </td>
<td style="text-align: left;"> MLE of bw (kernel standard deviations)</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>kernel</code>:    </td>
<td style="text-align: left;"> kernel name</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>bcmethod</code>:  </td>
<td style="text-align: left;"> boundary correction method</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>proper</code>:    </td>
<td style="text-align: left;"> logical, whether renormalisation is requested</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>nn</code>:        </td>
<td style="text-align: left;"> non-negative correction method</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>offset</code>:    </td>
<td style="text-align: left;"> offset for log transformation method</td>
</tr>
<tr>
<td style="text-align: left;">
 <code>xmax</code>:      </td>
<td style="text-align: left;"> maximum value of scaled beta or copula
</td>
</tr>
</table>
<h3>Boundary Correction Methods</h3>

<p>See <code>dbckden</code> for details of BCKDE methods.
</p>


<h3>Warning</h3>

<p>See important warnings about cross-validation likelihood estimation in 
<code>fkden</code>, type <code>help fkden</code>.
</p>
<p>See important warnings about boundary correction approaches in 
<code>dbckden</code>, type <code>help bckden</code>.
</p>


<h3>Acknowledgments</h3>

<p>See Acknowledgments in
<code>fnormgpd</code>, type <code>help fnormgpd</code>. Based on code
by Anna MacDonald produced for MATLAB.
</p>


<h3>Note</h3>

<p>See notes in <code>fnormgpd</code> for details, type <code>help fnormgpd</code>.
Only the different features are outlined below for brevity.
</p>
<p>No default initial values for parameter vector are provided, so will stop evaluation if
<code>pvector</code> is left as <code>NULL</code>. Avoid setting the starting value for the shape parameter to
<code>xi=0</code> as depending on the optimisation method it may be get stuck.
</p>
<p>The data and kernel centres are both vectors. Infinite, missing and negative sample values
(and kernel centres) are dropped.
</p>


<h3>Author(s)</h3>

<p>Yang Hu and Carl Scarrott <a href="mailto:carl.scarrott@canterbury.ac.nz">carl.scarrott@canterbury.ac.nz</a>
</p>


<h3>References</h3>

<p><a href="http://www.math.canterbury.ac.nz/~c.scarrott/evmix">http://www.math.canterbury.ac.nz/~c.scarrott/evmix</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">http://en.wikipedia.org/wiki/Kernel_density_estimation</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
<p><a href="http://en.wikipedia.org/wiki/Generalized_Pareto_distribution">http://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>
</p>
<p>Scarrott, C.J. and MacDonald, A. (2012). A review of extreme value
threshold estimation and uncertainty quantification. REVSTAT - Statistical
Journal 10(1), 33-59. Available from <a href="http://www.ine.pt/revstat/pdf/rs120102.pdf">http://www.ine.pt/revstat/pdf/rs120102.pdf</a>
</p>
<p>Hu, Y. (2013). Extreme value mixture modelling: An R package and simulation study.
MSc (Hons) thesis, University of Canterbury, New Zealand.
<a href="http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go">http://ir.canterbury.ac.nz/simple-search?query=extreme&amp;submit=Go</a>
</p>
<p>Bowman, A.W. (1984). An alternative method of cross-validation for the smoothing of
density estimates. Biometrika 71(2), 353-360.
</p>
<p>Duin, R.P.W. (1976). On the choice of smoothing parameters for Parzen estimators of
probability density functions. IEEE Transactions on Computers C25(11), 1175-1179.
</p>
<p>MacDonald, A., Scarrott, C.J., Lee, D., Darlow, B., Reale, M. and Russell, G. (2011).
A flexible extreme value mixture model. Computational Statistics and Data Analysis
55(6), 2137-2157.
</p>
<p>MacDonald, A., C. J. Scarrott, and D. S. Lee (2011). Boundary correction, consistency
and robustness of kernel densities using extreme value theory. Submitted.
Available from: <a href="http://www.math.canterbury.ac.nz/~c.scarrott">http://www.math.canterbury.ac.nz/~c.scarrott</a>.
</p>
<p>Wand, M. and Jones, M.C. (1995). Kernel Smoothing. Chapman &amp;&amp; Hall.
</p>


<h3>See Also</h3>

<p><code>kernels</code>, <code>kfun</code>,
<code>density</code>, <code>bw.nrd0</code>
and <code>dkde</code> in <code>ks</code> package.
<code>fgpd</code> and <code>gpd</code>.
</p>
<p>Other kdengpdcon: <code>bckdengpdcon</code>,
<code>fgkgcon</code>, <code>fkdengpdcon</code>,
<code>fkdengpd</code>, <code>gkgcon</code>,
<code>kdengpdcon</code>, <code>kdengpd</code>
</p>
<p>Other bckden: <code>bckdengpdcon</code>,
<code>bckdengpd</code>, <code>bckden</code>,
<code>fbckdengpd</code>, <code>fbckden</code>,
<code>fkden</code>, <code>kden</code>
</p>
<p>Other bckdengpd: <code>bckdengpdcon</code>,
<code>bckdengpd</code>, <code>bckden</code>,
<code>fbckdengpd</code>, <code>fbckden</code>,
<code>fkdengpd</code>, <code>gkg</code>,
<code>kdengpd</code>, <code>kden</code>
</p>
<p>Other bckdengpdcon: <code>bckdengpdcon</code>,
<code>bckdengpd</code>, <code>bckden</code>,
<code>fbckdengpd</code>, <code>fbckden</code>,
<code>fkdengpdcon</code>, <code>gkgcon</code>,
<code>kdengpdcon</code>
</p>
<p>Other fbckdengpdcon: <code>bckdengpdcon</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
set.seed(1)
par(mfrow = c(2, 1))

x = rgamma(500, 2, 1)
xx = seq(-0.1, 10, 0.01)
y = dgamma(xx, 2, 1)

# Continuity constraint
pinit = c(0.1, quantile(x, 0.9), 0.1) # initial values required for BCKDE
fit = fbckdengpdcon(x, pvector = pinit, bcmethod = "cutnorm")
hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bcmethod = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
  
# No continuity constraint
pinit = c(0.1, quantile(x, 0.9), 1, 0.1) # initial values required for BCKDE
fit2 = fbckdengpd(x, pvector = pinit, bcmethod = "cutnorm")
with(fit2, lines(xx, dbckdengpd(xx, x, lambda, u, sigmau, xi, bc = "cutnorm"), col="blue"))
abline(v = fit2$u, col = "blue")
legend("topright", c("True Density","No continuity constraint","With continuty constraint"),
  col=c("black", "blue", "red"), lty = 1)
  
# Profile likelihood for initial value of threshold and fixed threshold approach
pinit = c(0.1, 0.1) # notice threshold dropped from initial values
fitu = fbckdengpdcon(x, useq = seq(1, 6, length = 20), pvector = pinit, bcmethod = "cutnorm")
fitfix = fbckdengpdcon(x, useq = seq(1, 6, length = 20), fixedu = TRUE, pv = pinit, bc = "cutnorm")

hist(x, breaks = 100, freq = FALSE, xlim = c(-0.1, 10))
lines(xx, y)
with(fit, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="red"))
abline(v = fit$u, col = "red")
with(fitu, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="purple"))
abline(v = fitu$u, col = "purple")
with(fitfix, lines(xx, dbckdengpdcon(xx, x, lambda, u, xi, bc = "cutnorm"), col="darkgreen"))
abline(v = fitfix$u, col = "darkgreen")
legend("topright", c("True Density","Default initial value (90% quantile)",
 "Prof. lik. for initial value", "Prof. lik. for fixed threshold"),
 col=c("black", "red", "purple", "darkgreen"), lty = 1)

## End(Not run)

</code></pre>


</div>