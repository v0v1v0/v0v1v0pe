<div class="container">

<table style="width: 100%;"><tr>
<td>t_to_d</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Convert <em>t</em>, <em>z</em>, and <em>F</em> to Cohen's <em>d</em> or <strong>partial</strong>-<em>r</em>
</h2>

<h3>Description</h3>

<p>These functions are convenience functions to convert t, z and F test
statistics to Cohen's d and <strong>partial</strong> r. These are useful in cases where
the data required to compute these are not easily available or their
computation is not straightforward (e.g., in liner mixed models, contrasts,
etc.).
<br>
See <a href="https://easystats.github.io/effectsize/articles/from_test_statistics.html">Effect Size from Test Statistics vignette.</a>
</p>


<h3>Usage</h3>

<pre><code class="language-R">t_to_d(t, df_error, paired = FALSE, ci = 0.95, alternative = "two.sided", ...)

z_to_d(z, n, paired = FALSE, ci = 0.95, alternative = "two.sided", ...)

F_to_d(
  f,
  df,
  df_error,
  paired = FALSE,
  ci = 0.95,
  alternative = "two.sided",
  ...
)

t_to_r(t, df_error, ci = 0.95, alternative = "two.sided", ...)

z_to_r(z, n, ci = 0.95, alternative = "two.sided", ...)

F_to_r(f, df, df_error, ci = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>t, f, z</code></td>
<td>
<p>The t, the F or the z statistics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paired</code></td>
<td>
<p>Should the estimate account for the t-value being testing the
difference between dependent means?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed (e.g.,
<code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in effectsize_CIs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The number of observations (the sample size).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df, df_error</code></td>
<td>
<p>Degrees of freedom of numerator or of the error estimate
(i.e., the residuals).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>These functions use the following formulae to approximate <em>r</em> and <em>d</em>:
<br><br></p>
<p style="text-align: center;"><code class="reqn">r_{partial} = t / \sqrt{t^2 + df_{error}}</code>
</p>

<p><br><br></p>
<p style="text-align: center;"><code class="reqn">r_{partial} = z / \sqrt{z^2 + N}</code>
</p>

<p><br><br></p>
<p style="text-align: center;"><code class="reqn">d = 2 * t / \sqrt{df_{error}}</code>
</p>

<p><br><br></p>
<p style="text-align: center;"><code class="reqn">d_z = t / \sqrt{df_{error}}</code>
</p>

<p><br><br></p>
<p style="text-align: center;"><code class="reqn">d = 2 * z / \sqrt{N}</code>
</p>

<p>The resulting <code>d</code> effect size is an <em>approximation</em> to Cohen's <em>d</em>, and
assumes two equal group sizes. When possible, it is advised to directly
estimate Cohen's <em>d</em>, with <code>cohens_d()</code>, <code>emmeans::eff_size()</code>, or similar
functions.
</p>


<h3>Value</h3>

<p>A data frame with the effect size(s)(<code>r</code> or <code>d</code>), and their CIs
(<code>CI_low</code> and <code>CI_high</code>).
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the "pivot
method"). This method finds the noncentrality parameter ("<em>ncp</em>") of a
noncentral <em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> distribution that places the observed
<em>t</em>, <em>F</em>, or <code class="reqn">\chi^2</code> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br><br>
For additional details on estimation and troubleshooting, see effectsize_CIs.
</p>


<h3>CIs and Significance Tests</h3>

<p>"Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more." (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <code class="reqn">\alpha</code>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <code class="reqn">\alpha</code>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br><br>
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <code class="reqn">\alpha</code> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are "close enough"
to 0 to be negligible are needed ("equivalence testing"; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code>
</h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li>
<p> Friedman, H. (1982). Simplified determinations of statistical power,
magnitude of effect and research sample sizes. Educational and Psychological
Measurement, 42(2), 521-526. <a href="https://doi.org/10.1177/001316448204200214">doi:10.1177/001316448204200214</a>
</p>
</li>
<li>
<p> Wolf, F. M. (1986). Meta-analysis: Quantitative methods for research
synthesis (Vol. 59). Sage.
</p>
</li>
<li>
<p> Rosenthal, R. (1994) Parametric measures of effect size. In H. Cooper and
L.V. Hedges (Eds.). The handbook of research synthesis. New York: Russell
Sage Foundation.
</p>
</li>
<li>
<p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li>
<li>
<p> Cumming, G., &amp; Finch, S. (2001). A primer on the understanding, use, and
calculation of confidence intervals that are based on central and noncentral
distributions. Educational and Psychological Measurement, 61(4), 532-574.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>cohens_d()</code>
</p>
<p>Other effect size from test statistic: 
<code>F_to_eta2()</code>,
<code>chisq_to_phi()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## t Tests
res &lt;- t.test(1:10, y = c(7:20), var.equal = TRUE)
t_to_d(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter, alternative = "less")

res &lt;- with(sleep, t.test(extra[group == 1], extra[group == 2], paired = TRUE))
t_to_d(t = res$statistic, res$parameter, paired = TRUE)
t_to_r(t = res$statistic, res$parameter)
t_to_r(t = res$statistic, res$parameter, alternative = "greater")


## Linear Regression
model &lt;- lm(rating ~ complaints + critical, data = attitude)
(param_tab &lt;- parameters::model_parameters(model))

(rs &lt;- t_to_r(param_tab$t[2:3], param_tab$df_error[2:3]))

# How does this compare to actual partial correlations?
correlation::correlation(attitude,
  select = "rating",
  select2 = c("complaints", "critical"),
  partial = TRUE
)

</code></pre>


</div>